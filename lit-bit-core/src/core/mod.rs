// src/core/mod.rs
// This module will house core state machine logic and types.
// For now, it's a placeholder.

#[allow(unused_imports)]
// Allow as it's needed for type resolution even if clippy thinks it's unused directly
use heapless::Vec;

// Re-export the StateMachine trait for easier use if core types implement it.
// Potentially, the macro-generated machine would be in a submodule of `core` or a user module.
pub use crate::StateMachine;

// --- Basic Type Placeholders (will be generic/generated by macro later) ---

// Using simple u8 for IDs as placeholders. Macro would generate enums.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateId(pub u8);

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EventId(pub u8);

// Placeholder for context data. Macro would use the user-defined struct.
#[derive(Debug, Clone, Default)]
pub struct DefaultContext {/* ... fields ... */}

// Define function pointer types for actions and guards
pub type ActionFn<ContextType> = fn(&mut ContextType);
pub type GuardFn<ContextType, EventType> = fn(context: &ContextType, event: EventType) -> bool;

// --- Flat State Machine Definition ---

/// Represents a simple transition for a flat state machine.
#[derive(Debug, Copy, Clone)]
pub struct Transition<StateType, EventType, ContextType> {
    pub from_state: StateType,
    pub event: EventType,
    pub to_state: StateType,
    pub action: Option<ActionFn<ContextType>>,
    pub guard: Option<GuardFn<ContextType, EventType>>,
}

/// Defines the structure of a simple, flat state machine.
/// This would be largely generated by the `statechart!` macro.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateNode<StateType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    pub id: StateType, // The unique ID of this state (a variant of the generated StateId enum)
    pub parent: Option<StateType>, // ID of the parent state, if any
    pub initial_child: Option<StateType>, // ID of the initial child state, if this is a composite state
    pub entry_action: Option<ActionFn<ContextType>>,
    pub exit_action: Option<ActionFn<ContextType>>,
    pub is_parallel: bool, // New field
}

#[derive(Clone)]
pub struct MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static, // This will be the generated StateId enum
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    pub states: &'static [StateNode<StateType, ContextType>],
    pub transitions: &'static [Transition<StateType, EventType, ContextType>],
    pub initial_leaf_state: StateType,
}

// Manual Debug impl to avoid requiring StateType, EventType, ContextType to be Debug for MachineDefinition itself to be Debug
impl<StateType, EventType, ContextType> core::fmt::Debug
    for MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    ContextType: Clone + core::fmt::Debug + 'static,
{
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        f.debug_struct("MachineDefinition")
            .field("states", &self.states) // StateNode needs Debug for this to be useful
            .field("transitions", &self.transitions)
            .field("initial_leaf_state", &self.initial_leaf_state)
            .finish()
    }
}

impl<StateType, EventType, ContextType> MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    pub const fn new(
        states: &'static [StateNode<StateType, ContextType>],
        transitions: &'static [Transition<StateType, EventType, ContextType>],
        initial_leaf_state: StateType,
    ) -> Self {
        MachineDefinition {
            states,
            transitions,
            initial_leaf_state,
        }
    }

    // Helper to find a state node by its ID
    pub fn get_state_node(
        &self,
        state_id: StateType,
    ) -> Option<&'static StateNode<StateType, ContextType>> {
        self.states.iter().find(|s_node| s_node.id == state_id)
    }

    // Helper to get the parent of a state, if it exists
    pub fn get_parent_of(&self, state_id: StateType) -> Option<StateType> {
        self.get_state_node(state_id)
            .and_then(|s_node| s_node.parent)
    }
}

// --- Runtime Instance ---

// Placeholder for hierarchy depth, make configurable or detect via macro later.
// const MAX_HIERARCHY_DEPTH: usize = 8; // Will be replaced by const generic M
// Make MAX_ACTIVE_REGIONS public so it can be accessed by lib.rs
pub const MAX_ACTIVE_REGIONS: usize = 4; // Max parallel regions/active states we can track

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct PathTooLongError;

impl core::fmt::Display for PathTooLongError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        write!(
            f,
            "Maximum hierarchy path depth exceeded during path calculation."
        )
    }
}

#[cfg(feature = "std")]
impl std::error::Error for PathTooLongError {}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum EntryErrorKind {
    CycleDetected,
    CapacityExceeded, // For visited_during_entry vector
    StateNotFound,
    // AccumulatorFull, // If we decide to make accumulator push return an error
}

impl core::fmt::Display for EntryErrorKind {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            EntryErrorKind::CycleDetected => write!(f, "State entry cycle detected."),
            EntryErrorKind::CapacityExceeded => write!(
                f,
                "Capacity exceeded during state entry (e.g., visited path too long)."
            ),
            EntryErrorKind::StateNotFound => write!(f, "State not found during entry process."),
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EntryError {
    pub kind: EntryErrorKind,
    // pub state_id: Option<StateType> // Could add this later if specific state context is needed for errors
}

impl core::fmt::Display for EntryError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        write!(f, "Entry Error: {}", self.kind)
    }
}

#[cfg(feature = "std")]
impl std::error::Error for EntryError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        None // No underlying source error for these simple error types
    }
}

/// Runtime instance of a state machine.
///
/// Generic Parameters:
/// - `StateType`: The type representing state IDs (usually an enum).
/// - `EventType`: The type representing event IDs (usually an enum).
/// - `ContextType`: The user-defined context struct.
/// - `M`: Const generic for maximum hierarchy depth of a single state path.
/// - `MAX_NODES_FOR_COMPUTATION`: Const generic for buffer sizes needed for computations involving
///   multiple hierarchy branches, typically `M * MAX_ACTIVE_REGIONS`. This is used for temporary
///   collections during transition processing (e.g. exit sets).
#[derive(Debug)]
pub struct Runtime<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
    active_leaf_states: heapless::Vec<StateType, MAX_ACTIVE_REGIONS>,
    context: ContextType,
}

// Helper function, can be outside impl Runtime or a static method if preferred.
// Making it a free function for now to ensure no `self` issues initially.
fn enter_state_recursive_logic<StateType, EventType, ContextType, const M: usize>(
    machine_def: &MachineDefinition<StateType, EventType, ContextType>,
    context: &mut ContextType,
    state_id_to_enter: StateType,
    accumulator: &mut heapless::Vec<StateType, MAX_ACTIVE_REGIONS>,
    visited_during_entry: &mut heapless::Vec<StateType, M>,
    run_entry_action_for_this_state: bool, // New flag name for clarity
) -> Result<(), EntryError>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    if visited_during_entry.contains(&state_id_to_enter) {
        debug_assert!(false, "Cycle detected for state: {state_id_to_enter:?}");
        return Err(EntryError {
            kind: EntryErrorKind::CycleDetected,
        });
    }
    if visited_during_entry.push(state_id_to_enter).is_err() {
        debug_assert!(
            false,
            "Visited entry path too long for state: {state_id_to_enter:?}"
        );
        return Err(EntryError {
            kind: EntryErrorKind::CapacityExceeded,
        });
    }

    let Some(node) = machine_def.get_state_node(state_id_to_enter) else {
        assert!(
            !cfg!(debug_assertions),
            "State ID ({state_id_to_enter:?}) not found in MachineDefinition."
        );
        let _ = visited_during_entry.pop();
        return Err(EntryError {
            kind: EntryErrorKind::StateNotFound,
        });
    };

    if run_entry_action_for_this_state {
        if let Some(entry_fn) = node.entry_action {
            entry_fn(context);
        }
    }

    if node.is_parallel {
        for s_node_in_def in machine_def.states {
            if s_node_in_def.parent == Some(state_id_to_enter) {
                // s_node_in_def is a region container (e.g., R1, R2)
                // 1. Execute entry action for the region container itself.
                if let Some(region_entry_fn) = s_node_in_def.entry_action {
                    region_entry_fn(context);
                }

                // 2. Find initial child of the region container s_node_in_def
                let initial_child_of_region = s_node_in_def.initial_child.ok_or_else(|| {
                    debug_assert!(
                        false,
                        "Parallel region {:?} is missing an initial child.",
                        s_node_in_def.id
                    );
                    EntryError {
                        kind: EntryErrorKind::StateNotFound,
                    }
                })?;

                // 3. Recursively enter the initial child of the region.
                enter_state_recursive_logic::<_, _, _, M>(
                    machine_def,
                    context,
                    initial_child_of_region,
                    accumulator,
                    visited_during_entry,
                    true, // Always run entry actions for children states during this recursion
                )?;
            }
        }
    } else if let Some(initial_child_id) = node.initial_child {
        enter_state_recursive_logic::<_, _, _, M>(
            machine_def,
            context,
            initial_child_id,
            accumulator,
            visited_during_entry,
            true, // Always run entry actions for children states during this recursion
        )?;
    } else {
        // Atomic state
        assert!(
            accumulator.push(state_id_to_enter).is_ok(),
            "MAX_ACTIVE_REGIONS ({}) exceeded while accumulating leaf states for {:?}.",
            accumulator.capacity(),
            state_id_to_enter
        );
    }

    let _ = visited_during_entry.pop();
    Ok(())
}

// Define PotentialTransition struct at the module level
#[derive(Debug, Clone, Copy)]
struct PotentialTransition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
{
    source_leaf_id: StateType,
    #[allow(dead_code)] // Will be used in full send() logic for arbitration
    transition_from_state_id: StateType,
    target_state_id: StateType,
    transition_ref: &'static Transition<StateType, EventType, ContextType>,
}

impl<StateType, EventType, ContextType, const M: usize, const MAX_NODES_FOR_COMPUTATION: usize>
    Runtime<StateType, EventType, ContextType, M, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    ContextType: Clone + 'static,
{
    // Removed old fn enter_state_recursive(&mut self, ...) here

    /// Creates a new runtime instance for the given machine definition and initial context.
    ///
    /// # Panics
    ///
    /// This function may panic under the following conditions:
    /// - If the `initial_leaf_state` specified in the `MachineDefinition` is not found in the `STATES` array.
    /// - If `MAX_ACTIVE_REGIONS` is exceeded while trying to push initial leaf states (e.g. for a parallel initial state).
    /// - If `M` (formerly `MAX_HIERARCHY_DEPTH`) is exceeded during internal path calculations (via `expect` calls).
    pub fn new(
        machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
        initial_context: ContextType,
    ) -> Self {
        let mut mutable_context = initial_context;
        let mut active_states_vec = heapless::Vec::new();
        let mut visited_for_initial_entry: heapless::Vec<StateType, M> = heapless::Vec::new();

        let top_level_initial_state_id = machine_def.initial_leaf_state;

        // Pass M explicitly if needed, or let it be inferred from the type of visited_for_initial_entry
        if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M>(
            machine_def,
            &mut mutable_context,
            top_level_initial_state_id,
            &mut active_states_vec,
            &mut visited_for_initial_entry,
            true,
        ) {
            panic!("Failed to initialize state machine due to entry error: {entry_error:?}");
        }

        assert!(
            !active_states_vec.is_empty(),
            "Initial state ID specified in MachineDefinition not found in STATES array, or initial state setup resulted in no active states (after successful entry logic completion implies this should not happen)."
        );

        Runtime {
            machine_def, // Assign the reference
            active_leaf_states: active_states_vec,
            context: mutable_context,
        }
    }

    pub fn state(&self) -> heapless::Vec<StateType, MAX_ACTIVE_REGIONS> {
        self.active_leaf_states.clone()
    }
    pub fn context(&self) -> &ContextType {
        &self.context
    }
    pub fn context_mut(&mut self) -> &mut ContextType {
        &mut self.context
    }

    // --- Helper methods for hierarchical transitions ---

    /// Collects the path from a leaf state up to the root, including the leaf itself.
    /// The path is returned with the leaf state at index 0 and ancestors following.
    fn get_path_to_root(
        &self,
        leaf_state_id: StateType,
    ) -> Result<heapless::Vec<StateType, M>, PathTooLongError> {
        // Changed return type
        let mut path: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut current_id = Some(leaf_state_id);
        while let Some(id) = current_id {
            if path.push(id).is_err() {
                // Changed from expect to check Result
                return Err(PathTooLongError);
            }
            current_id = self.machine_def.get_parent_of(id);
        }
        Ok(path)
    }

    /// Finds the Least Common Ancestor (LCA) of two states.
    fn find_lca(
        &self,
        state1_id: StateType,
        state2_id: StateType,
    ) -> Result<Option<StateType>, PathTooLongError> {
        if state1_id == state2_id {
            return Ok(Some(state1_id));
        }

        let path1 = self.get_path_to_root(state1_id)?; // Path from state1 up to root
        let path2 = self.get_path_to_root(state2_id)?; // Path from state2 up to root

        // Iterate through path1 (from state1 towards root).
        // The first element of path1 also found in path2 is the LCA.
        for &id1_ancestor in &path1 {
            if path2.contains(&id1_ancestor) {
                return Ok(Some(id1_ancestor));
            }
        }

        Ok(None) // Should not happen if both states are in the same tree (i.e. have a common root)
        // but as a fallback if they somehow aren't (e.g. disconnected components, though our model assumes one tree).
    }

    fn is_proper_ancestor(
        &self,
        ancestor_candidate_id: StateType,
        descendant_candidate_id: StateType,
    ) -> Result<bool, PathTooLongError> {
        // Changed return type
        if ancestor_candidate_id == descendant_candidate_id {
            return Ok(false);
        }
        match self.get_path_to_root(descendant_candidate_id) {
            Ok(path_from_descendant) => Ok(path_from_descendant
                .iter()
                .skip(1)
                .any(|&p_state| p_state == ancestor_candidate_id)),
            Err(e) => {
                // Propagate PathTooLongError
                Err(e)
            }
        }
    }

    // Helper to find the direct child of parent_id that is currently active or an ancestor of an active leaf.
    fn get_active_child_of(&self, parent_id: StateType) -> Option<StateType> {
        for &leaf_id in &self.active_leaf_states {
            if leaf_id == parent_id {
                continue;
            }

            let path_result = self.get_path_to_root(leaf_id);
            match path_result {
                Ok(path_from_leaf_to_root) => {
                    for i in 1..path_from_leaf_to_root.len() {
                        if path_from_leaf_to_root[i] == parent_id {
                            return Some(path_from_leaf_to_root[i - 1]);
                        }
                    }
                }
                Err(PathTooLongError) => {
                    debug_assert!(
                        false,
                        "PathTooLongError in get_active_child_of for leaf {leaf_id:?}. This may indicate M is too small."
                    );
                    // In release, we can't determine the child via this path, so continue to the next leaf.
                }
            }
        }
        None
    }

    // Helper to compute the ordered list of states to exit.
    fn compute_ordered_exit_set(
        &self,
        leaf_state_id_being_exited: StateType,
        lca_id: Option<StateType>,
    ) -> Result<heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>, PathTooLongError> {
        // Return type uses new name

        let mut states_to_potentially_exit: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut collected_for_exit: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();

        // 1. Collect all states on the direct path from the active leaf up to (but not including) the LCA.
        let mut current_id_on_path = Some(leaf_state_id_being_exited);
        while let Some(id) = current_id_on_path {
            if lca_id == Some(id) {
                break;
            }
            // Check capacity before pushing to states_to_potentially_exit
            if states_to_potentially_exit.push(id).is_err() {
                // This implies M is too small for the hierarchy depth of this branch.
                return Err(PathTooLongError);
            }
            current_id_on_path = self.machine_def.get_parent_of(id);
        }
        // states_to_potentially_exit is now [leaf, p1, p2, ..., child_of_lca]

        // 2. For each state collected, recursively add its active children (for composite/parallel) first, then itself, to ensure post-order.
        //    Use a helper that ensures each state is added to `collected_for_exit` only once.
        let mut already_added_to_final_list: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut recursion_guard_vec: heapless::Vec<StateType, M> = heapless::Vec::new(); // Declare vec for recursion guard

        for &state_to_process_for_exit in states_to_potentially_exit.iter().rev() {
            // Process from child_of_lca down to leaf
            self.collect_states_for_exit_post_order(
                state_to_process_for_exit,
                lca_id,
                &mut collected_for_exit,
                &mut already_added_to_final_list,
                &mut recursion_guard_vec, // Pass the new guard
            )?; // Propagate error
        }
        Ok(collected_for_exit)
    }

    // Recursive helper for compute_ordered_exit_set
    fn collect_states_for_exit_post_order(
        &self,
        current_state_id: StateType,
        lca_id: Option<StateType>,
        ordered_exit_list: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        already_added: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        recursion_guard: &mut heapless::Vec<StateType, M>, // M should be sufficient for path depth
    ) -> Result<(), PathTooLongError> {
        // Changed return type
        if Some(current_state_id) == lca_id || already_added.contains(&current_state_id) {
            return Ok(()); // Changed
        }

        let is_cycle_in_exit = recursion_guard.contains(&current_state_id);
        debug_assert!(
            !is_cycle_in_exit,
            "Cycle detected during collect_states_for_exit_post_order for state: {current_state_id:?}"
        );
        if is_cycle_in_exit {
            return Ok(()); // Changed
        }

        if recursion_guard.push(current_state_id).is_err() {
            // Check push failure
            debug_assert!(
                false, // This assertion will now always fail if the push fails.
                "Recursion depth exceeded in collect_states_for_exit_post_order (capacity {}) for state: {current_state_id:?}",
                recursion_guard.capacity()
            );
            return Err(PathTooLongError); // Return error
        }

        let Some(current_node) = self.machine_def.get_state_node(current_state_id) else {
            let _ = recursion_guard.pop(); // Pop before returning if node not found
            return Ok(()); // Changed
        };

        // Mark as visited for *this specific traversal context* to avoid issues if it's an ancestor of another part of main path.
        // The main `already_added` list prevents adding to `ordered_exit_list` multiple times.

        if current_node.is_parallel {
            for region_node in self
                .machine_def
                .states
                .iter()
                .filter(|n| n.parent == Some(current_state_id))
            {
                // Check if region is active (has a descendant in active_leaf_states)
                let mut region_active_leaf: Option<StateType> = None;
                for &leaf in &self.active_leaf_states {
                    match self.is_descendant_or_self(leaf, region_node.id) {
                        // Handle Result
                        Ok(is_desc) => {
                            if is_desc {
                                region_active_leaf = Some(leaf);
                                break;
                            }
                        }
                        Err(e) => return Err(e), // Propagate PathTooLongError
                    }
                }
                if let Some(active_leaf_in_region) = region_active_leaf {
                    // Recurse from the active leaf of the region, stopping at the region itself (as region will be added later)
                    self.collect_states_for_exit_post_order(
                        active_leaf_in_region,
                        Some(region_node.id),
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
                // After region's children, add region itself (if not already added)
                if !already_added.contains(&region_node.id) {
                    self.collect_states_for_exit_post_order(
                        region_node.id,
                        lca_id,
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
            }
        } else if current_node.initial_child.is_some() {
            // Composite non-parallel
            if let Some(active_direct_child) = self.get_active_child_of(current_state_id) {
                self.collect_states_for_exit_post_order(
                    active_direct_child,
                    lca_id,
                    ordered_exit_list,
                    already_added,
                    recursion_guard,
                )?; // Propagate error
            }
        }

        // Add current_state_id to the list *after* its children have been processed and added.
        if !already_added.contains(&current_state_id) {
            // Ensure it's added only once. If these critical lists overflow, it's a fatal error.
            ordered_exit_list.push(current_state_id).expect(
                "Exit list (ordered_exit_list) overflow due to MAX_NODES_FOR_COMPUTATION too small",
            );

            already_added.push(current_state_id).expect(
                "Exit list (already_added) overflow due to MAX_NODES_FOR_COMPUTATION too small",
            );
        }
        let _ = recursion_guard.pop(); // Pop after processing this node and its children
        Ok(()) // Changed
    }

    // is_descendant_or_self method from before
    fn is_descendant_or_self(
        &self,
        candidate_id: StateType,
        ancestor_id: StateType,
    ) -> Result<bool, PathTooLongError> {
        // Changed return type
        if candidate_id == ancestor_id {
            return Ok(true);
        }
        self.is_proper_ancestor(ancestor_id, candidate_id) // Propagate error
    }

    /// Executes entry actions from a state (typically child of LCA) down to a target leaf state.
    /// This involves entering the `target_state_id` and then drilling down to its own initial leaf if it's composite.
    fn execute_entry_actions_from_lca(
        &mut self,
        target_state_id: StateType,
        lca_id: Option<StateType>,
    ) -> Result<heapless::Vec<StateType, MAX_ACTIVE_REGIONS>, PathTooLongError> {
        let mut new_active_leaf_states = heapless::Vec::new();
        let mut visited_for_final_recursion: heapless::Vec<StateType, M> = heapless::Vec::new();

        let path_from_target_to_root = self.get_path_to_root(target_state_id)?;
        // path_is [Target, P(Target), P(P(Target)), ..., Root]

        let mut entry_path_segment: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut lca_passed = lca_id.is_none();

        for i in (0..path_from_target_to_root.len()).rev() {
            // Iterates [Root, ..., P(LCA), LCA, Child(LCA), ..., Target]
            let state_on_path = path_from_target_to_root[i];
            if lca_passed {
                entry_path_segment
                    .push(state_on_path)
                    .map_err(|_| PathTooLongError)?;
            }
            if Some(state_on_path) == lca_id {
                lca_passed = true;
            }
        }
        // entry_path_segment is now [ChildOfLCA_or_Root, ..., TargetParent, Target]

        for &state_to_enter in &entry_path_segment {
            let node = self
                .machine_def
                .get_state_node(state_to_enter)
                .ok_or(PathTooLongError)?;

            if let Some(entry_fn) = node.entry_action {
                entry_fn(&mut self.context);
            }

            // If an intermediate state on this path is parallel (and not the final target of transition),
            // it must be fully entered, and its leaves become the result of this entry sequence.
            if node.is_parallel && state_to_enter != target_state_id {
                // Its own entry action was just run. Now recursively enter its regions.
                return enter_state_recursive_logic::<_, _, _, M>(
                    self.machine_def,
                    &mut self.context,
                    state_to_enter, // This intermediate parallel state
                    &mut new_active_leaf_states,
                    &mut visited_for_final_recursion,
                    false, // false because its own entry action was just run by this loop
                )
                .map_err(|e| {
                    assert!(
                        !cfg!(debug_assertions),
                        "EntryError from intermediate parallel state {state_to_enter:?}: {e:?}"
                    );
                    PathTooLongError
                })
                .map(|()| new_active_leaf_states);
            }
        }

        // After all ancestors (and target itself if it was on path) have had their entry actions run,
        // call enter_state_recursive_logic for the target_state_id.
        // The `run_entry_action_for_this_state` flag should be `false` if target_state_id was in entry_path_segment (its entry action already ran),
        // and `true` otherwise (e.g., if entry_path_segment was empty because target_state_id was the LCA).
        let target_entry_action_already_run = entry_path_segment.contains(&target_state_id);

        match enter_state_recursive_logic::<_, _, _, M>(
            self.machine_def,
            &mut self.context,
            target_state_id,
            &mut new_active_leaf_states,
            &mut visited_for_final_recursion,
            !target_entry_action_already_run, // Run entry if not already run by loop above
        ) {
            Ok(()) => Ok(new_active_leaf_states),
            Err(entry_error) => {
                assert!(
                    !cfg!(debug_assertions),
                    "EntryError from final enter_state_recursive_logic for {target_state_id:?}: {entry_error:?}"
                );
                Err(PathTooLongError)
            }
        }
    }

    /// Sends an event to the state machine for processing.
    ///
    /// This is a **TEMPORARY IMPLEMENTATION** and will be significantly refactored
    /// to support parallel states.
    ///
    /// # Panics
    /// Contains `expect` and `panic` calls that might trigger if `MAX_ACTIVE_REGIONS` or
    /// `M` (formerly `MAX_HIERARCHY_DEPTH`) are too small, or if internal logic errors occur.
    #[allow(clippy::too_many_lines)]
    pub fn send(&mut self, event: EventType) -> bool {
        let mut potential_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION, // Changed capacity from MAX_ACTIVE_REGIONS
        > = heapless::Vec::new();
        let current_active_leaves_snapshot = self.active_leaf_states.clone();

        let mut potential_transitions_overflow = false; // Flag to break outer loop
        for &active_leaf_id in &current_active_leaves_snapshot {
            let mut check_state_id_opt = Some(active_leaf_id);
            'hierarchy_search: while let Some(check_state_id) = check_state_id_opt {
                if self.machine_def.get_state_node(check_state_id).is_some() {
                    for t_def in self.machine_def.transitions {
                        if t_def.from_state == check_state_id && t_def.event == event {
                            if let Some(guard_fn) = t_def.guard {
                                if !guard_fn(&self.context, event) {
                                    continue;
                                }
                            }
                            let pot_trans = PotentialTransition {
                                source_leaf_id: active_leaf_id, // The leaf that sourced this potential path
                                transition_from_state_id: check_state_id, // The actual state defining the transition
                                target_state_id: t_def.to_state,
                                transition_ref: t_def,
                            };
                            let push_result = potential_transitions.push(pot_trans);
                            #[cfg(debug_assertions)]
                            assert!(
                                push_result.is_ok(),
                                "Exceeded capacity for potential transitions..."
                            );
                            if push_result.is_err() {
                                // In release, if we can't store it, we can't consider it.
                                potential_transitions_overflow = true; // Set flag
                                break 'hierarchy_search; // Break inner loop
                            }
                            // Found a transition for this level, break from hierarchy search for this active_leaf_id
                            break 'hierarchy_search;
                        }
                    }
                }
                check_state_id_opt = self.machine_def.get_parent_of(check_state_id);
            }
            if potential_transitions_overflow {
                break; // Break outer loop if overflow occurred
            }
        }

        if potential_transitions_overflow {
            // If we overflowed the potential_transitions list, it means MAX_NODES_FOR_COMPUTATION might be too small.
            // The safest thing to do is to indicate no transition occurred, as we couldn't consider all possibilities.
            return false;
        }

        if potential_transitions.is_empty() {
            return false;
        }

        let mut arbitrated_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION, // Also update here if it's a subset of potential_transitions. Or keep as MAX_ACTIVE_REGIONS if arbitration reduces it.
                                       // Review suggests potential_transitions is the one needing more cap. Arbitrated is likely smaller or equal.
                                       // For safety, let's make arbitrated_transitions also MAX_NODES_FOR_COMPUTATION, as it stores clones from potential_transitions.
        > = heapless::Vec::new();
        'candidate_loop: for pt_candidate in &potential_transitions {
            for other_pt in &potential_transitions {
                if core::ptr::eq(pt_candidate, other_pt) {
                    continue;
                }

                // Attempt to check ancestry. If error, treat as inconclusive (don't skip pt_candidate on this basis).
                // However, if PathTooLongError occurs, we should probably abort the send.
                if let Ok(is_ancestor) = self.is_proper_ancestor(
                    pt_candidate.transition_from_state_id,
                    other_pt.transition_from_state_id,
                ) {
                    if is_ancestor {
                        // pt_candidate's source is an ancestor of other_pt's source.
                        // This means other_pt is more specific. So, pt_candidate should be skipped.
                        continue 'candidate_loop;
                    }
                } else {
                    // PathTooLongError: Cannot determine ancestry reliably. Abort send.
                    assert!(
                        !cfg!(debug_assertions),
                        "PathTooLongError from is_proper_ancestor during arbitration. Candidate: {:?}, Other: {:?}",
                        pt_candidate.transition_from_state_id,
                        other_pt.transition_from_state_id
                    );
                    return false; // Abort send
                }

                // No need for the other is_proper_ancestor check, as the roles are swapped.
                // The goal is: if pt_candidate is an ancestor of other_pt, pt_candidate is skipped.
                // If other_pt is an ancestor of pt_candidate, pt_candidate is NOT skipped by this check (other_pt would be skipped when it's the candidate).
            }
            let push_result = arbitrated_transitions.push(pt_candidate.clone());
            #[cfg(debug_assertions)]
            assert!(
                push_result.is_ok(),
                "Exceeded capacity for arbitrated_transitions."
            );
            if push_result.is_err() {
                break;
            }
        }

        if arbitrated_transitions.is_empty() {
            return false;
        }

        // --- De-duplicate arbitrated_transitions based on the actual transition definition ---
        let mut final_transitions_to_execute: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();
        // Use a Vec to track seen transition definition pointers for no_std compatibility without extra features.
        let mut processed_transition_pointers: heapless::Vec<
            *const Transition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();

        for trans_to_consider in &arbitrated_transitions {
            // Iterate by reference
            let current_ref_ptr = trans_to_consider.transition_ref as *const _;
            let mut already_processed = false;
            for &seen_ptr in &processed_transition_pointers {
                if seen_ptr == current_ref_ptr {
                    already_processed = true;
                    break;
                }
            }

            if !already_processed {
                if final_transitions_to_execute
                    .push(trans_to_consider.clone())
                    .is_ok()
                {
                    // Clone here
                    if processed_transition_pointers.push(current_ref_ptr).is_err() {
                        // This should not happen if final_transitions_to_execute and processed_transition_pointers have same capacity
                        // and we only push to processed_pointers if push to final_transitions was ok.
                        assert!(
                            !cfg!(debug_assertions),
                            "Overflow in processed_transition_pointers after successful push to final_transitions_to_execute."
                        );
                        return false; // Should be unreachable if capacities match
                    }
                } else {
                    assert!(
                        !cfg!(debug_assertions),
                        "Overflow while de-duplicating arbitrated transitions into final_transitions_to_execute."
                    );
                    return false;
                }
            }
        }

        if final_transitions_to_execute.is_empty() {
            // Should not happen if arbitrated_transitions was not empty
            return false;
        }

        // --- Start of new logic for processing multiple transitions ---
        let mut overall_transition_occurred = false;
        let mut next_active_leaf_states = self.active_leaf_states.clone();
        let mut states_exited_this_step: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut entry_execution_list: heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        > = heapless::Vec::new();

        // Phase 1: Process exits and actions for all transitions first
        for trans_info in &final_transitions_to_execute {
            // Use de-duplicated list
            let source_state_id = trans_info.transition_from_state_id;
            let target_state_id = trans_info.target_state_id;
            let active_leaf_for_this_trans = trans_info.source_leaf_id;

            overall_transition_occurred = true;

            let is_simple_leaf_self_transition = source_state_id == target_state_id
                && match self.is_descendant_or_self(active_leaf_for_this_trans, source_state_id) {
                    Ok(is_desc) => is_desc,
                    Err(_) => return false, // PathTooLongError, abort send
                }
                && self
                    .machine_def
                    .get_state_node(source_state_id)
                    .is_some_and(|n| !n.is_parallel && n.initial_child.is_none());

            if is_simple_leaf_self_transition {
                // True self-transition on an active simple leaf state
                if let Some(node) = self.machine_def.get_state_node(source_state_id) {
                    if !states_exited_this_step.contains(&source_state_id) {
                        if let Some(exit_fn) = node.exit_action {
                            exit_fn(&mut self.context);
                        }
                        states_exited_this_step
                            .push(source_state_id)
                            .expect("states_exited_this_step overflow for simple self-trans");
                    }
                }
                if let Some(action_fn) = trans_info.transition_ref.action {
                    action_fn(&mut self.context);
                }
                entry_execution_list
                    .push((
                        source_state_id,       // Target for entry is the source itself
                        Some(source_state_id), // LCA is the state itself for leaf self-transition re-entry
                        active_leaf_for_this_trans,
                    ))
                    .expect("entry_execution_list overflow for simple self-trans");
            } else if source_state_id == target_state_id {
                // External self-transition on composite/parallel state
                let node_being_self_transitioned =
                    self.machine_def.get_state_node(source_state_id).unwrap(); // Should exist
                // Exit all active children of source_state_id, then source_state_id itself
                // We need a robust way to get all active descendants for exit.
                // compute_ordered_exit_set called with lca_id = parent(source_state_id) would achieve this.
                let parent_of_source = node_being_self_transitioned.parent;
                // Iterate all current active leaves. If they are descendants of source_state_id, compute their exit path up to source_state_id's parent.
                for &current_active_leaf in &current_active_leaves_snapshot {
                    // Use snapshot before any state changes
                    if self
                        .is_descendant_or_self(current_active_leaf, source_state_id)
                        .unwrap_or(false)
                    {
                        let Ok(states_to_exit_for_this_leaf_branch) =
                            self.compute_ordered_exit_set(current_active_leaf, parent_of_source)
                        else {
                            return false;
                        };
                        for &state_to_exit_id in &states_to_exit_for_this_leaf_branch {
                            if !states_exited_this_step.contains(&state_to_exit_id) {
                                if let Some(node) =
                                    self.machine_def.get_state_node(state_to_exit_id)
                                {
                                    if let Some(exit_fn) = node.exit_action {
                                        exit_fn(&mut self.context);
                                    }
                                }
                                states_exited_this_step.push(state_to_exit_id).expect(
                                    "states_exited_this_step overflow for self-trans branch",
                                );
                            }
                        }
                    }
                }
                // Ensure source_state_id itself is exited if not already by compute_ordered_exit_set (it should be if parent_of_source was LCA)
                if !states_exited_this_step.contains(&source_state_id) {
                    if let Some(exit_fn) = node_being_self_transitioned.exit_action {
                        exit_fn(&mut self.context);
                    }
                    states_exited_this_step
                        .push(source_state_id)
                        .expect("states_exited_this_step overflow for self-trans source");
                }

                if let Some(action_fn) = trans_info.transition_ref.action {
                    action_fn(&mut self.context);
                }
                entry_execution_list
                    .push((
                        target_state_id,            // which is source_state_id
                        parent_of_source,           // LCA for re-entry is parent
                        active_leaf_for_this_trans, // This seems okay, it's just context for original trigger path
                    ))
                    .expect("entry_execution_list overflow for self-trans");
            } else {
                // General LCA path (external non-self-transition or self-transition on composite state)
                let lca_id_result = self.find_lca(active_leaf_for_this_trans, target_state_id);
                let lca_id = match lca_id_result {
                    Ok(l) => l,
                    Err(_path_too_long_error) => {
                        assert!(
                            !cfg!(debug_assertions),
                            "PathTooLongError from find_lca for states {active_leaf_for_this_trans:?}, {target_state_id:?}"
                        );
                        // If LCA computation fails, abort the entire send operation for safety.
                        return false;
                    }
                };

                let states_to_exit_for_branch = match self
                    .compute_ordered_exit_set(active_leaf_for_this_trans, lca_id)
                {
                    Ok(s) => s,
                    Err(_path_too_long_error) => {
                        assert!(
                            !cfg!(debug_assertions),
                            "PathTooLongError from compute_ordered_exit_set for leaf {active_leaf_for_this_trans:?}"
                        );
                        // If exit set computation fails, abort the entire send operation for safety.
                        return false;
                    }
                };

                for &state_to_exit_id in &states_to_exit_for_branch {
                    if !states_exited_this_step.contains(&state_to_exit_id) {
                        if let Some(node) = self.machine_def.get_state_node(state_to_exit_id) {
                            if let Some(exit_fn) = node.exit_action {
                                exit_fn(&mut self.context);
                            }
                        }
                        states_exited_this_step
                            .push(state_to_exit_id)
                            .expect("states_exited_this_step overflow for branch");
                    }
                }

                // Collapsed if: It's a self-transition, and its exit action hasn't run yet.
                if source_state_id == target_state_id
                    && !states_exited_this_step.contains(&source_state_id)
                {
                    if let Some(node) = self.machine_def.get_state_node(source_state_id) {
                        if let Some(exit_fn) = node.exit_action {
                            exit_fn(&mut self.context);
                        }
                    }
                    states_exited_this_step
                        .push(source_state_id)
                        .expect("states_exited_this_step overflow for composite self-trans");
                }

                /*
                next_active_leaf_states.retain(|&leaf| {
                    // Retain if NOT part of this branch's exits AND NOT a descendant of a composite self-transition source.
                    !(
                        states_to_exit_for_branch.iter().any(|&exited_ancestor_or_self| {
                            self.is_descendant_or_self(leaf, exited_ancestor_or_self)
                        })
                        || (source_state_id == target_state_id && self.is_descendant_or_self(leaf, source_state_id))
                    )
                });
                */

                if let Some(action_fn) = trans_info.transition_ref.action {
                    action_fn(&mut self.context);
                }

                entry_execution_list
                    .push((target_state_id, lca_id, active_leaf_for_this_trans))
                    .expect("entry_execution_list overflow");
            }
        } // End loop over final_transitions_to_execute

        // Phase 2: Update active leaf states based on global exits collected in states_exited_this_step
        if overall_transition_occurred {
            // Only modify if any transition was processed
            let mut new_next_active_leaf_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
            let mut path_error_during_retain = false;

            for &leaf_candidate in &next_active_leaf_states {
                let mut should_this_leaf_be_retained = true;
                let mut error_for_this_leaf = false;

                for &exited_state_id in &states_exited_this_step {
                    if let Ok(is_descendant) =
                        self.is_descendant_or_self(leaf_candidate, exited_state_id)
                    {
                        if is_descendant {
                            should_this_leaf_be_retained = false;
                            break;
                        }
                    } else {
                        // Err case for is_descendant_or_self
                        error_for_this_leaf = true;
                        should_this_leaf_be_retained = false;
                        break;
                    }
                }

                if error_for_this_leaf {
                    path_error_during_retain = true;
                }

                if should_this_leaf_be_retained
                    && new_next_active_leaf_states.push(leaf_candidate).is_err()
                {
                    assert!(
                        !cfg!(debug_assertions),
                        "new_next_active_leaf_states overflow during retain phase. MAX_ACTIVE_REGIONS possibly too small."
                    );
                    path_error_during_retain = true;
                    break;
                }
            }

            if path_error_during_retain {
                // If any path error occurred or we couldn't store retained leaves, the state is potentially inconsistent.
                // Abort the entire send operation.
                // Assert already happened for debug builds for overflow.
                return false;
            }
            next_active_leaf_states = new_next_active_leaf_states; // Replace with the filtered list
        }

        // Phase 3: Process entries and add new leaves to next_active_leaf_states
        for (target_id, lca_id, _original_leaf_for_context) in entry_execution_list {
            let new_leaves_result = self.execute_entry_actions_from_lca(target_id, lca_id);
            match new_leaves_result {
                Ok(new_leaves_from_this_entry) => {
                    for new_leaf in new_leaves_from_this_entry {
                        if !next_active_leaf_states.contains(&new_leaf) {
                            next_active_leaf_states
                                .push(new_leaf)
                                .expect("next_active_leaf_states overflow during entry");
                        }
                    }
                }
                Err(_path_too_long_error) => {
                    assert!(
                        !cfg!(debug_assertions),
                        "PathTooLongError from execute_entry_actions_from_lca for target {target_id:?}"
                    );
                    // If entry actions fail due to path length, abort and indicate no transition.
                    // Note: Side effects from exits and transition actions have already occurred.
                    // This is a limitation of not having a full rollback mechanism.
                    return false;
                }
            }
        }

        if overall_transition_occurred {
            self.active_leaf_states = next_active_leaf_states;
        }

        overall_transition_occurred
    }
}

impl<StateType, EventType, ContextType, const M: usize, const MAX_NODES_FOR_COMPUTATION: usize>
    StateMachine for Runtime<StateType, EventType, ContextType, M, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    ContextType: Clone + 'static,
{
    type State = StateType;
    type Event = EventType;
    type Context = ContextType;

    fn send(&mut self, event: Self::Event) -> bool {
        Runtime::<StateType, EventType, ContextType, M, MAX_NODES_FOR_COMPUTATION>::send(
            self, event,
        )
    }

    fn state(&self) -> heapless::Vec<Self::State, MAX_ACTIVE_REGIONS> {
        self.active_leaf_states.clone()
    }

    fn context(&self) -> &Self::Context {
        &self.context
    }

    fn context_mut(&mut self) -> &mut Self::Context {
        &mut self.context
    }
}

#[cfg(test)]
mod tests {
    use super::*; //Imports S, E, C types from parent
    use crate::core::DefaultContext; // Ensure DefaultContext is in scope

    // Define const M for tests, e.g., 8, matching old MAX_HIERARCHY_DEPTH for compatibility.
    const TEST_HIERARCHY_DEPTH_M: usize = 8;
    const TEST_MAX_NODES_FOR_COMPUTATION: usize = TEST_HIERARCHY_DEPTH_M * MAX_ACTIVE_REGIONS; // Renamed from TEST_MTMAR

    #[allow(dead_code)] // Allow dead code for S2 variant and potentially others during dev
    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestState {
        S0,
        S1,
        S2,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestEvent {
        E0,
        E1,
    }

    // Using the DefaultContext from the parent module for this alias
    type TestContextForEmpty = DefaultContext;

    // Define CounterContext at the module scope for tests
    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct CounterContext {
        count: i32,
    }

    fn increment_action(context: &mut CounterContext) {
        context.count += 1;
    }
    fn count_is_zero_guard(context: &CounterContext, _event: TestEvent) -> bool {
        context.count == 0
    }

    // Populated StateNode arrays for tests
    const TEST_STATENODES_EMPTY_CTX_POPULATED: &[StateNode<TestState, TestContextForEmpty>] = &[
        StateNode {
            id: TestState::S0,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S1,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S2,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    const TEST_STATENODES_COUNTER_CTX_POPULATED: &[StateNode<TestState, CounterContext>] = &[
        StateNode {
            id: TestState::S0,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S1,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S2,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    // --- New Test Setup for Hierarchical Transitions ---

    const MAX_LOG_ENTRIES: usize = 64; // Increased from 32
    const MAX_LOG_STRING_LEN: usize = 64; // Max length for a logged action string

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct HierarchicalActionLogContext {
        log: Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES>,
    }

    impl HierarchicalActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<MAX_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String");
            self.log
                .push(s) // try_push not strictly necessary if MAX_LOG_ENTRIES is sufficient for tests and we expect it to succeed.
                .expect("Log vec full in HierarchicalActionLogContext");
        }
        fn get_log(&self) -> &Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> {
            &self.log
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestHierarchyState {
        ParentOne,
        ChildOneAlpha,            // Child of ParentOne
        GrandchildOneAlphaXray,   // Child of ChildOneAlpha
        GrandchildOneAlphaYankee, // Child of ChildOneAlpha
        ChildOneBravo,            // Child of ParentOne
        ParentTwo,
        ChildTwoAlpha, // Child of ParentTwo
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestHierarchyEvent {
        EventTriggerP1ToP2,        // ParentOne to ParentTwo
        EventTriggerToSibling,     // ChildOneAlpha to ChildOneBravo
        EventTriggerToParent,      // GrandchildOneAlphaXray to ChildOneAlpha
        EventTriggerToGrandparent, // GrandchildOneAlphaYankee to ParentOne
        EventTriggerToCousinChild, // ChildOneBravo to GrandchildOneAlphaYankee
        EventTriggerParentReentry, // ChildOneBravo to ParentOne (expect re-entry to P1 initial)
        EventTriggerP2ToP1,        // ParentTwo to ParentOne
        EventTriggerP1ToC1B,       // ParentOne to ChildOneBravo (new)
    }

    // Helper action functions for logging
    fn log_enter_parent_one(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterParentOne");
    }
    fn log_exit_parent_one(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitParentOne");
    }
    fn log_enter_child_one_alpha(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterChildOneAlpha");
    }
    fn log_exit_child_one_alpha(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitChildOneAlpha");
    }
    fn log_enter_grandchild_one_alpha_xray(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterGrandchildOneAlphaXray");
    }
    fn log_exit_grandchild_one_alpha_xray(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitGrandchildOneAlphaXray");
    }
    fn log_enter_grandchild_one_alpha_yankee(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterGrandchildOneAlphaYankee");
    }
    fn log_exit_grandchild_one_alpha_yankee(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitGrandchildOneAlphaYankee");
    }
    fn log_enter_child_one_bravo(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterChildOneBravo");
    }
    fn log_exit_child_one_bravo(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitChildOneBravo");
    }
    fn log_enter_parent_two(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterParentTwo");
    }
    fn log_exit_parent_two(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitParentTwo");
    }
    fn log_enter_child_two_alpha(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("EnterChildTwoAlpha");
    }
    fn log_exit_child_two_alpha(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("ExitChildTwoAlpha");
    }
    fn log_transition_action(ctx: &mut HierarchicalActionLogContext) {
        ctx.log_action("TransitionAction");
    }

    const TEST_HIERARCHY_STATENODES: &[StateNode<
        TestHierarchyState,
        HierarchicalActionLogContext,
    >] = &[
        // ParentOne level
        StateNode {
            id: TestHierarchyState::ParentOne,
            parent: None,
            initial_child: Some(TestHierarchyState::ChildOneAlpha),
            entry_action: Some(log_enter_parent_one),
            exit_action: Some(log_exit_parent_one),
            is_parallel: false,
        },
        // Children of ParentOne
        StateNode {
            id: TestHierarchyState::ChildOneAlpha,
            parent: Some(TestHierarchyState::ParentOne),
            initial_child: Some(TestHierarchyState::GrandchildOneAlphaXray),
            entry_action: Some(log_enter_child_one_alpha),
            exit_action: Some(log_exit_child_one_alpha),
            is_parallel: false,
        },
        StateNode {
            id: TestHierarchyState::ChildOneBravo,
            parent: Some(TestHierarchyState::ParentOne),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_child_one_bravo),
            exit_action: Some(log_exit_child_one_bravo),
            is_parallel: false,
        },
        // Grandchildren of ParentOne (children of ChildOneAlpha)
        StateNode {
            id: TestHierarchyState::GrandchildOneAlphaXray,
            parent: Some(TestHierarchyState::ChildOneAlpha),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_grandchild_one_alpha_xray),
            exit_action: Some(log_exit_grandchild_one_alpha_xray),
            is_parallel: false,
        },
        StateNode {
            id: TestHierarchyState::GrandchildOneAlphaYankee,
            parent: Some(TestHierarchyState::ChildOneAlpha),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_grandchild_one_alpha_yankee),
            exit_action: Some(log_exit_grandchild_one_alpha_yankee),
            is_parallel: false,
        },
        // ParentTwo level
        StateNode {
            id: TestHierarchyState::ParentTwo,
            parent: None,
            initial_child: Some(TestHierarchyState::ChildTwoAlpha),
            entry_action: Some(log_enter_parent_two),
            exit_action: Some(log_exit_parent_two),
            is_parallel: false,
        },
        // Children of ParentTwo
        StateNode {
            id: TestHierarchyState::ChildTwoAlpha,
            parent: Some(TestHierarchyState::ParentTwo),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_child_two_alpha),
            exit_action: Some(log_exit_child_two_alpha),
            is_parallel: false,
        },
    ];

    const TEST_HIERARCHY_TRANSITIONS: &[Transition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    >] = &[
        // EventTriggerP1ToP2: ParentOne to ParentTwo
        Transition {
            from_state: TestHierarchyState::ParentOne,
            event: TestHierarchyEvent::EventTriggerP1ToP2,
            to_state: TestHierarchyState::ParentTwo,
            action: Some(log_transition_action),
            guard: None,
        },
        // New transition for ParentOne to ChildOneBravo
        Transition {
            from_state: TestHierarchyState::ParentOne,
            event: TestHierarchyEvent::EventTriggerP1ToC1B,
            to_state: TestHierarchyState::ChildOneBravo,
            action: Some(log_transition_action), // Add a transition action
            guard: None,
        },
        // EventTriggerToSibling: ChildOneAlpha to ChildOneBravo
        Transition {
            from_state: TestHierarchyState::ChildOneAlpha,
            event: TestHierarchyEvent::EventTriggerToSibling,
            to_state: TestHierarchyState::ChildOneBravo,
            action: Some(log_transition_action),
            guard: None,
        },
        // EventTriggerToParent: GrandchildOneAlphaXray to ChildOneAlpha
        Transition {
            from_state: TestHierarchyState::GrandchildOneAlphaXray,
            event: TestHierarchyEvent::EventTriggerToParent,
            to_state: TestHierarchyState::ChildOneAlpha,
            action: Some(log_transition_action),
            guard: None,
        },
        // EventTriggerToGrandparent: GrandchildOneAlphaYankee to ParentOne
        Transition {
            from_state: TestHierarchyState::GrandchildOneAlphaYankee,
            event: TestHierarchyEvent::EventTriggerToGrandparent,
            to_state: TestHierarchyState::ParentOne,
            action: Some(log_transition_action),
            guard: None,
        },
        // EventTriggerToCousinChild: ChildOneBravo to GrandchildOneAlphaYankee
        Transition {
            from_state: TestHierarchyState::ChildOneBravo,
            event: TestHierarchyEvent::EventTriggerToCousinChild,
            to_state: TestHierarchyState::GrandchildOneAlphaYankee,
            action: Some(log_transition_action),
            guard: None,
        },
        // EventTriggerParentReentry: ChildOneBravo to ParentOne (target is composite ParentOne)
        Transition {
            from_state: TestHierarchyState::ChildOneBravo,
            event: TestHierarchyEvent::EventTriggerParentReentry,
            to_state: TestHierarchyState::ParentOne, // Target ParentOne, should re-enter its initial path
            action: Some(log_transition_action),
            guard: None,
        },
        // EventTriggerP2ToP1: ParentTwo to ParentOne
        Transition {
            from_state: TestHierarchyState::ParentTwo,
            event: TestHierarchyEvent::EventTriggerP2ToP1,
            to_state: TestHierarchyState::ParentOne,
            action: Some(log_transition_action),
            guard: None,
        },
    ];

    #[test]
    fn hierarchical_machine_starts_in_correct_initial_leaf_with_entry_actions() {
        static MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne, // Top-level initial state for the machine definition
        );

        let initial_context = HierarchicalActionLogContext::default();
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MACHINE_DEF,
                initial_context,
            );

        // Check final leaf state
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        // Check entry action log
        let mut expected_log_vec: heapless::Vec<
            heapless::String<MAX_LOG_STRING_LEN>,
            MAX_LOG_ENTRIES,
        > = heapless::Vec::new();
        expected_log_vec
            .push(heapless::String::try_from("EnterParentOne").unwrap())
            .expect("Log full");
        expected_log_vec
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log_vec
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log_vec);
    }

    #[test]
    fn test_sibling_transition_with_lca() {
        static SIBLING_LCA_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );

        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &SIBLING_LCA_MACHINE_DEF, // <--- Uses the static definition
                HierarchicalActionLogContext::default(),
            );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        ); // Verify starting state
        runtime.context_mut().log.clear(); // Clear initial entry logs

        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerToSibling);
        assert!(
            event_processed,
            "Event EventTriggerToSibling should have been processed"
        );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildOneBravo]
        );

        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneBravo").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn machine_starts_in_initial_state() {
        const TEST_TRANSITIONS: &[Transition<TestState, TestEvent, TestContextForEmpty>] = &[];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContextForEmpty> =
            MachineDefinition::new(
                TEST_STATENODES_EMPTY_CTX_POPULATED,
                TEST_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = DefaultContext::default();
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
            );
        assert_eq!(runtime.state().as_slice(), &[TestState::S0]);
    }

    #[test]
    fn send_event_triggers_transition_and_action() {
        const ACTION_TRANSITIONS: &[Transition<TestState, TestEvent, CounterContext>] =
            &[Transition {
                from_state: TestState::S0,
                event: TestEvent::E0,
                to_state: TestState::S1,
                action: Some(increment_action),
                guard: None,
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, CounterContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                ACTION_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = CounterContext { count: 0 };
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
            );

        assert!(runtime.send(TestEvent::E0));
        assert_eq!(runtime.state().as_slice(), &[TestState::S1]);
        assert_eq!(runtime.context().count, 1);
    }

    #[test]
    fn send_event_no_transition_if_guard_fails() {
        const GUARDED_TRANSITIONS: &[Transition<TestState, TestEvent, CounterContext>] =
            &[Transition {
                from_state: TestState::S0,
                event: TestEvent::E0,
                to_state: TestState::S1,
                action: Some(increment_action),
                guard: Some(count_is_zero_guard),
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, CounterContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                GUARDED_TRANSITIONS,
                TestState::S0,
            );

        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                CounterContext { count: 1 },
            ); // count is not 0
        assert!(!runtime.send(TestEvent::E0)); // Guard should fail
        assert_eq!(runtime.state().as_slice(), &[TestState::S0]);
        assert_eq!(runtime.context().count, 1); // Action should not run

        let mut runtime_pass =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                CounterContext { count: 0 },
            ); // count is 0
        assert!(runtime_pass.send(TestEvent::E0)); // Guard should pass
        assert_eq!(runtime_pass.state().as_slice(), &[TestState::S1]);
        assert_eq!(runtime_pass.context().count, 1); // Action should run
    }

    #[test]
    fn context_mut_provides_mutable_access() {
        const NO_TRANSITIONS: &[Transition<TestState, TestEvent, CounterContext>] = &[];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, CounterContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                NO_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = CounterContext { count: 42 };
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
            );

        runtime.context_mut().count += 1;
        assert_eq!(runtime.context().count, 43);
    }

    #[test]
    fn no_transition_if_event_does_not_match() {
        const TEST_TRANSITIONS: &[Transition<TestState, TestEvent, TestContextForEmpty>] =
            &[Transition {
                from_state: TestState::S0,
                event: TestEvent::E0,
                to_state: TestState::S1,
                action: None,
                guard: None,
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContextForEmpty> =
            MachineDefinition::new(
                TEST_STATENODES_EMPTY_CTX_POPULATED,
                TEST_TRANSITIONS,
                TestState::S0,
            );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                DefaultContext::default(),
            );
        assert!(!runtime.send(TestEvent::E1)); // Different event
        assert_eq!(runtime.state().as_slice(), &[TestState::S0]);
    }

    #[test]
    fn no_transition_if_state_does_not_match() {
        const TEST_TRANSITIONS_ST_MATCH: &[Transition<
            TestState,
            TestEvent,
            TestContextForEmpty,
        >] = &[Transition {
            from_state: TestState::S0,
            event: TestEvent::E0,
            to_state: TestState::S1,
            action: None,
            guard: None,
        }];
        // This MachineDefinition is a const, so a reference to it is &'static
        const TEST_MACHINE_DEF_ST_MATCH: MachineDefinition<
            TestState,
            TestEvent,
            TestContextForEmpty,
        > = MachineDefinition::new(
            TEST_STATENODES_EMPTY_CTX_POPULATED,
            TEST_TRANSITIONS_ST_MATCH, // Use the locally defined const name
            TestState::S1,
        );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF_ST_MATCH, // Pass by reference
                DefaultContext::default(),
            );
        assert!(!runtime.send(TestEvent::E0));
        assert_eq!(runtime.state().as_slice(), &[TestState::S1]);
    }

    #[test]
    fn test_child_to_parent_transition() {
        static CHILD_TO_PARENT_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );

        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &CHILD_TO_PARENT_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerToParent);
        assert!(
            event_processed,
            "Event EventTriggerToParent should have been processed"
        );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_parent_to_child_transition() {
        static PARENT_TO_CHILD_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARENT_TO_CHILD_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerP1ToC1B);
        assert!(
            event_processed,
            "Event EventTriggerP1ToC1B should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildOneBravo]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneBravo").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_grandchild_to_grandparent_reentry() {
        static GC_TO_GP_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &GC_TO_GP_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.send(TestHierarchyEvent::EventTriggerToSibling);
        runtime.send(TestHierarchyEvent::EventTriggerToCousinChild);
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerToGrandparent);
        assert!(
            event_processed,
            "Event EventTriggerToGrandparent should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaYankee").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterParentOne").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_cousin_child_transition() {
        static COUSIN_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &COUSIN_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.send(TestHierarchyEvent::EventTriggerToSibling);
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerToCousinChild);
        assert!(
            event_processed,
            "Event EventTriggerToCousinChild should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaYankee]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitChildOneBravo").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterGrandchildOneAlphaYankee").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_cross_top_level_parent_transition() {
        static CROSS_PARENT_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            TEST_HIERARCHY_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &CROSS_PARENT_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(TestHierarchyEvent::EventTriggerP1ToP2);
        assert!(
            event_processed,
            "Event EventTriggerP1ToP2 should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildTwoAlpha]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitParentOne").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterParentTwo").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildTwoAlpha").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    // --- Tests for Multiple Guard Selection ---

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum MultiGuardTestState {
        InitialState,
        TargetStateOne,
        TargetStateTwo,
        TargetStateThree,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum MultiGuardTestEvent {
        TriggerEvent,
    }

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct MultiGuardContext {
        selector_value: i32,
        action_taken_for: Option<MultiGuardTestState>,
    }

    fn guard_for_target_one(context: &MultiGuardContext, _event: MultiGuardTestEvent) -> bool {
        context.selector_value == 1
    }
    fn action_for_target_one(context: &mut MultiGuardContext) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateOne);
    }

    fn guard_for_target_two(context: &MultiGuardContext, _event: MultiGuardTestEvent) -> bool {
        context.selector_value == 2
    }
    fn action_for_target_two(context: &mut MultiGuardContext) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateTwo);
    }

    fn guard_for_target_three(context: &MultiGuardContext, _event: MultiGuardTestEvent) -> bool {
        context.selector_value == 3
    }
    fn action_for_target_three(context: &mut MultiGuardContext) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateThree);
    }

    const MULTI_GUARD_STATENODES: &[StateNode<MultiGuardTestState, MultiGuardContext>] = &[
        StateNode {
            id: MultiGuardTestState::InitialState,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateOne,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateTwo,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateThree,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    const MULTI_GUARD_TRANSITIONS: &[Transition<
        MultiGuardTestState,
        MultiGuardTestEvent,
        MultiGuardContext,
    >] = &[
        Transition {
            from_state: MultiGuardTestState::InitialState,
            event: MultiGuardTestEvent::TriggerEvent,
            to_state: MultiGuardTestState::TargetStateOne,
            action: Some(action_for_target_one),
            guard: Some(guard_for_target_one),
        },
        Transition {
            from_state: MultiGuardTestState::InitialState,
            event: MultiGuardTestEvent::TriggerEvent,
            to_state: MultiGuardTestState::TargetStateTwo,
            action: Some(action_for_target_two),
            guard: Some(guard_for_target_two),
        },
        Transition {
            from_state: MultiGuardTestState::InitialState,
            event: MultiGuardTestEvent::TriggerEvent,
            to_state: MultiGuardTestState::TargetStateThree,
            action: Some(action_for_target_three),
            guard: Some(guard_for_target_three),
        },
    ];

    #[test]
    fn test_multiple_guards_selects_correct_transition() {
        static MULTI_GUARD_MACHINE_DEF: MachineDefinition<
            MultiGuardTestState,
            MultiGuardTestEvent,
            MultiGuardContext,
        > = MachineDefinition::new(
            MULTI_GUARD_STATENODES,
            MULTI_GUARD_TRANSITIONS,
            MultiGuardTestState::InitialState,
        );

        let mut runtime1 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 1,
                    action_taken_for: None,
                },
            );
        assert!(runtime1.send(MultiGuardTestEvent::TriggerEvent));
        assert_eq!(
            runtime1.state().as_slice(),
            &[MultiGuardTestState::TargetStateOne]
        );
        assert_eq!(
            runtime1.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateOne)
        );

        let mut runtime2 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 2,
                    action_taken_for: None,
                },
            );
        assert!(runtime2.send(MultiGuardTestEvent::TriggerEvent));
        assert_eq!(
            runtime2.state().as_slice(),
            &[MultiGuardTestState::TargetStateTwo]
        );
        assert_eq!(
            runtime2.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateTwo)
        );

        let mut runtime3 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 3,
                    action_taken_for: None,
                },
            );
        assert!(runtime3.send(MultiGuardTestEvent::TriggerEvent));
        assert_eq!(
            runtime3.state().as_slice(),
            &[MultiGuardTestState::TargetStateThree]
        );
        assert_eq!(
            runtime3.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateThree)
        );

        let mut runtime4 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 4,
                    action_taken_for: None,
                },
            );
        assert!(!runtime4.send(MultiGuardTestEvent::TriggerEvent));
        assert_eq!(
            runtime4.state().as_slice(),
            &[MultiGuardTestState::InitialState]
        );
        assert_eq!(runtime4.context().action_taken_for, None);

        let mut runtime5 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 1,
                    action_taken_for: None,
                },
            );
        assert!(runtime5.send(MultiGuardTestEvent::TriggerEvent));
        assert_eq!(
            runtime5.state().as_slice(),
            &[MultiGuardTestState::TargetStateOne],
            "Expected TargetStateOne due to transition order"
        );
        assert_eq!(
            runtime5.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateOne)
        );
    }

    // --- New Test Setup for Parallel State Transitions ---

    const PARALLEL_LOG_ENTRIES: usize = 32;
    const PARALLEL_LOG_STRING_LEN: usize = 64;

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct ParallelActionLogContext {
        log: heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>,
    }

    impl ParallelActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String in ParallelActionLogContext");
            self.log.push(s).unwrap_or_else(|_val| {
                panic!(
                    "ParallelActionLogContext log overflow (capacity {PARALLEL_LOG_ENTRIES}). Could not log: {action_description}"
                );
            });
        }
        // Helper to create expected log Vec more easily in tests
        #[allow(dead_code)] // May not be used by all tests initially
        fn expected_log(
            entries: &[&str],
        ) -> heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>
        {
            let mut v = heapless::Vec::new();
            for entry in entries {
                let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
                s.push_str(entry).unwrap();
                v.push(s).unwrap();
            }
            v
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash, PartialOrd, Ord)]
    enum ParallelTestState {
        P,
        R1,
        R1A,
        R1B,
        R2,
        R2X,
        R2Y,
        SOuter,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum ParallelTestEvent {
        E1,
        E2,
        EventParallelSelf,    // Was E_P_Self
        EventRegion1Self,     // Was E_R1_Self
        EventRegion2Self,     // Was E_R2_Self
        EventParallelToOuter, // Was E_P_To_SOuter
        EventOuterToParallel, // Was E_SOuter_To_P
        EventRegion1Only,     // Was E_R1_Only
    }

    // Action and Guard functions for parallel tests (renamed for clarity)
    fn pt_log_enter_parallel(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterP");
    }
    fn pt_log_exit_parallel(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitP");
    }
    fn pt_log_event_parallel_self_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("P_SelfAction");
    }

    fn pt_log_enter_region1(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR1");
    }
    fn pt_log_exit_region1(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR1");
    }
    fn pt_log_enter_region1_state_a(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR1A");
    }
    fn pt_log_exit_region1_state_a(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR1A");
    }
    fn pt_log_region1_state_a_event_e1_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R1A_E1_Action");
    }
    fn pt_log_region1_state_a_event_region1_self_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R1A_SelfAction");
    }
    fn pt_log_enter_region1_state_b(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR1B");
    }
    fn pt_log_exit_region1_state_b(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR1B");
    }
    fn pt_log_region1_state_b_event_e2_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R1B_E2_Action");
    }
    fn pt_log_region1_state_a_event_region1_only_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R1A_E_R1_Only_Action");
    }

    fn pt_log_enter_region2(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR2");
    }
    fn pt_log_exit_region2(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR2");
    }
    fn pt_log_enter_region2_state_x(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR2X");
    }
    fn pt_log_exit_region2_state_x(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR2X");
    }
    fn pt_log_region2_state_x_event_e1_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R2X_E1_Action");
    }
    fn pt_log_region2_state_x_event_region2_self_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R2X_SelfAction");
    }
    fn pt_log_enter_region2_state_y(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterR2Y");
    }
    fn pt_log_exit_region2_state_y(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitR2Y");
    }
    fn pt_log_region2_state_y_event_e2_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("R2Y_E2_Action");
    }

    fn pt_log_enter_state_outer(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("EnterSOuter");
    }
    fn pt_log_exit_state_outer(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("ExitSOuter");
    }
    fn pt_log_event_parallel_to_outer_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("P_E2_SOuter_Action");
    }
    fn pt_log_event_outer_to_parallel_action(ctx: &mut ParallelActionLogContext) {
        ctx.log_action("SOuter_E1_P_Action");
    }

    const PARALLEL_TEST_STATENODES: &[StateNode<ParallelTestState, ParallelActionLogContext>] = &[
        StateNode {
            id: ParallelTestState::P,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_parallel),
            exit_action: Some(pt_log_exit_parallel),
            is_parallel: true,
        },
        StateNode {
            id: ParallelTestState::R1,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R1A),
            entry_action: Some(pt_log_enter_region1),
            exit_action: Some(pt_log_exit_region1),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1A,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_a),
            exit_action: Some(pt_log_exit_region1_state_a),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1B,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_b),
            exit_action: Some(pt_log_exit_region1_state_b),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R2X),
            entry_action: Some(pt_log_enter_region2),
            exit_action: Some(pt_log_exit_region2),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2X,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_x),
            exit_action: Some(pt_log_exit_region2_state_x),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2Y,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_y),
            exit_action: Some(pt_log_exit_region2_state_y),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::SOuter,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_state_outer),
            exit_action: Some(pt_log_exit_state_outer),
            is_parallel: false,
        },
    ];

    const PARALLEL_TEST_TRANSITIONS: &[Transition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    >] = &[
        Transition {
            from_state: ParallelTestState::P,
            event: ParallelTestEvent::EventParallelSelf,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_parallel_self_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::P,
            event: ParallelTestEvent::EventParallelToOuter,
            to_state: ParallelTestState::SOuter,
            action: Some(pt_log_event_parallel_to_outer_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R1A,
            event: ParallelTestEvent::E1,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_e1_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R1A,
            event: ParallelTestEvent::EventRegion1Self,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_a_event_region1_self_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R1A,
            event: ParallelTestEvent::EventRegion1Only,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_region1_only_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R1B,
            event: ParallelTestEvent::E2,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_b_event_e2_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R2X,
            event: ParallelTestEvent::E1,
            to_state: ParallelTestState::R2Y,
            action: Some(pt_log_region2_state_x_event_e1_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R2X,
            event: ParallelTestEvent::EventRegion2Self,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_x_event_region2_self_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::R2Y,
            event: ParallelTestEvent::E2,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_y_event_e2_action),
            guard: None,
        },
        Transition {
            from_state: ParallelTestState::SOuter,
            event: ParallelTestEvent::EventOuterToParallel,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_outer_to_parallel_action),
            guard: None,
        },
    ];

    static PARALLEL_MACHINE_DEF: MachineDefinition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    > = MachineDefinition::new(
        PARALLEL_TEST_STATENODES,
        PARALLEL_TEST_TRANSITIONS,
        ParallelTestState::P,
    );

    // Helper function for checking subsequences in logs
    fn check_subsequence(
        log: &heapless::Vec<&str, PARALLEL_LOG_ENTRIES>,
        expected_sub: &[&str],
    ) -> bool {
        if expected_sub.is_empty() {
            return true;
        }
        let mut log_idx = 0;
        let mut sub_idx = 0;
        while log_idx < log.len() && sub_idx < expected_sub.len() {
            if log[log_idx] == expected_sub[sub_idx] {
                sub_idx += 1;
            }
            log_idx += 1;
        }
        sub_idx == expected_sub.len()
    }

    #[test]
    fn test_parallel_initial_activation_and_entry_order() {
        let initial_context = ParallelActionLogContext::default(); // unused_mut: removed mut
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "EnterP", "EnterR1", "EnterR1A", "EnterR2", "EnterR2X",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Entry action log mismatch"
        );
    }

    #[test]
    fn test_parallel_independent_region_transitions() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::E1);
        assert!(event_processed, "Event E1 should have been processed");

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2Y).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let actual_log = runtime.context().log.clone();
        let actual_log_strs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect();

        let r1_actions_expected_slice = &["ExitR1A", "R1A_E1_Action", "EnterR1B"];
        let r2_actions_expected_slice = &["ExitR2X", "R2X_E1_Action", "EnterR2Y"];

        assert!(
            check_subsequence(&actual_log_strs, r1_actions_expected_slice),
            "R1 action block {r1_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );
        assert!(
            check_subsequence(&actual_log_strs, r2_actions_expected_slice),
            "R2 action block {r2_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );

        // The sum of lengths of individual blocks should be the total log length if no other actions occurred.
        assert_eq!(
            actual_log_strs.len(),
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            "Log has incorrect total number of entries. Expected {}, got {}. Log: {actual_log_strs:?}",
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            actual_log_strs.len()
        );
    }

    #[test]
    fn test_parallel_transition_one_region_no_effect_on_other() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::EventRegion1Only);
        assert!(
            event_processed,
            "Event EventRegion1Only should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "ExitR1A",
            "R1A_E_R1_Only_Action",
            "EnterR1B",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Only"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_region_leaf() {
        let initial_context = ParallelActionLogContext::default(); // Needs mut for clear()
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::EventRegion1Self);
        assert!(
            event_processed,
            "Event EventRegion1Self should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log =
            ParallelActionLogContext::expected_log(&["ExitR1A", "R1A_SelfAction", "EnterR1A"]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Self"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_parallel_state_itself() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::EventParallelSelf);
        assert!(
            event_processed,
            "Event EventParallelSelf should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch after P self-transition. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let actual_log = runtime.context().log.clone();
        let log_str_refs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect(); // redundant_closure: fixed

        let expected_log_sequence = [
            "ExitR1A",
            "ExitR1",
            "ExitR2X",
            "ExitR2",
            "ExitP",
            "P_SelfAction",
            "EnterP",
            "EnterR1",
            "EnterR1A",
            "EnterR2",
            "EnterR2X",
        ];
        let expected_h_log = ParallelActionLogContext::expected_log(&expected_log_sequence);
        assert_eq!(
            actual_log, expected_h_log,
            "Log for P self-transition mismatch. Log: {log_str_refs:?}"
        ); // uninlined_format_args: fixed
    }

    #[test]
    fn test_parallel_transition_from_parallel_to_outer() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::EventParallelToOuter);
        assert!(
            event_processed,
            "Event EventParallelToOuter should have been processed"
        );

        let active_states = runtime.state();
        assert_eq!(
            active_states.len(),
            1,
            "Should have one active state after transitioning to SOuter"
        );
        assert_eq!(
            active_states[0],
            ParallelTestState::SOuter,
            "Active state should be SOuter"
        );

        let expected_log_sequence = [
            "ExitR1A",
            "ExitR1",
            "ExitR2X",
            "ExitR2",
            "ExitP",
            "P_E2_SOuter_Action",
            "EnterSOuter",
        ];
        let expected_h_log = ParallelActionLogContext::expected_log(&expected_log_sequence);
        let actual_log = runtime.context().log.clone();
        let log_str_refs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect(); // redundant_closure: fixed
        assert_eq!(
            actual_log, expected_h_log,
            "Log for P to SOuter transition mismatch. Log: {log_str_refs:?}"
        ); // uninlined_format_args: fixed
    }

    static PARALLEL_MACHINE_DEF_INIT_SOUTER: MachineDefinition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    > = MachineDefinition::new(
        PARALLEL_TEST_STATENODES,
        PARALLEL_TEST_TRANSITIONS,
        ParallelTestState::SOuter,
    );

    #[test]
    fn test_parallel_transition_from_outer_to_parallel() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF_INIT_SOUTER,
                initial_context,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(ParallelTestEvent::EventOuterToParallel);
        assert!(
            event_processed,
            "Event EventOuterToParallel should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch after SOuter to P. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log_sequence = [
            "ExitSOuter",
            "SOuter_E1_P_Action",
            "EnterP",
            "EnterR1",
            "EnterR1A",
            "EnterR2",
            "EnterR2X",
        ];
        let expected_h_log = ParallelActionLogContext::expected_log(&expected_log_sequence);
        let actual_log = runtime.context().log.clone();
        let log_str_refs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect(); // redundant_closure: fixed
        assert_eq!(
            actual_log, expected_h_log,
            "Log for SOuter to P transition mismatch. Log: {log_str_refs:?}"
        ); // uninlined_format_args: fixed
    }

    // ... existing tests ...
}
