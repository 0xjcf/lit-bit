// src/core/mod.rs
// This module will house core state machine logic and types.

#[macro_use]
mod tracing {
    #[macro_export]
    macro_rules! trace {
        ($($arg:tt)*) => {
            #[cfg(feature = "debug-log")]
            {
                use std::io::{self, Write};
                println!($($arg)*);
                io::stdout().flush().unwrap();
            }
        };
    }
}

#[cfg(feature = "std")]
use std::io::{self, Write};

#[allow(unused_imports)]
use heapless::Vec;

// Re-export the StateMachine trait for easier use if core types implement it.
// Potentially, the macro-generated machine would be in a submodule of `core` or a user module.
pub use crate::StateMachine;

// --- Basic Type Placeholders (will be generic/generated by macro later) ---

// Using simple u8 for IDs as placeholders. Macro would generate enums.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateId(pub u8);

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EventId(pub u8);

// Placeholder for context data. Macro would use the user-defined struct.
#[derive(Debug, Clone, Default)]
pub struct DefaultContext {/* ... fields ... */}

// Define function pointer types for actions and guards
pub type ActionFn<ContextType, EventType> = fn(context: &mut ContextType, event: &EventType);
pub type GuardFn<ContextType, EventType> = fn(context: &ContextType, event: &EventType) -> bool;
pub type EntryExitActionFn<ContextType, EventType> =
    fn(context: &mut ContextType, event: &EventType);

// Add near ActionFn / GuardFn
type MatchFn<EventType> = fn(&EventType) -> bool;

// --- Flat State Machine Definition ---

/// Represents a simple transition for a flat state machine.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct Transition<StateType, EventType, ContextType> {
    pub from_state: StateType,
    pub to_state: StateType,
    pub action: Option<ActionFn<ContextType, EventType>>,
    pub guard: Option<GuardFn<ContextType, EventType>>,
    /// Pattern matching function that determines if an event matches this transition
    pub match_fn: Option<MatchFn<EventType>>,
}

/// Defines the structure of a simple, flat state machine.
/// This would be largely generated by the `statechart!` macro.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateNode<StateType, ContextType, EventType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static,
{
    pub id: StateType, // The unique ID of this state (a variant of the generated StateId enum)
    pub parent: Option<StateType>, // ID of the parent state, if any
    pub initial_child: Option<StateType>, // ID of the initial child state, if this is a composite state
    pub entry_action: Option<EntryExitActionFn<ContextType, EventType>>,
    pub exit_action: Option<EntryExitActionFn<ContextType, EventType>>,
    pub is_parallel: bool, // New field
}

#[derive(Clone)]
pub struct MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static, // This will be the generated StateId enum
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy, kept Clone
    ContextType: Clone + 'static,
{
    pub states: &'static [StateNode<StateType, ContextType, EventType>],
    pub transitions: &'static [Transition<StateType, EventType, ContextType>],
    pub initial_leaf_state: StateType,
}

// Manual Debug impl to avoid requiring StateType, EventType, ContextType to be Debug for MachineDefinition itself to be Debug
impl<StateType, EventType, ContextType> core::fmt::Debug
    for MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + core::fmt::Debug + 'static,
{
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        f.debug_struct("MachineDefinition")
            .field("states", &self.states) // StateNode needs Debug for this to be useful
            .field("transitions", &self.transitions)
            .field("initial_leaf_state", &self.initial_leaf_state)
            .finish()
    }
}

impl<StateType, EventType, ContextType> MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    pub const fn new(
        states: &'static [StateNode<StateType, ContextType, EventType>],
        transitions: &'static [Transition<StateType, EventType, ContextType>],
        initial_leaf_state: StateType,
    ) -> Self {
        MachineDefinition {
            states,
            transitions,
            initial_leaf_state,
        }
    }

    // Helper to find a state node by its ID
    pub fn get_state_node(
        &self,
        state_id: StateType,
    ) -> Option<&'static StateNode<StateType, ContextType, EventType>> {
        self.states.iter().find(|s_node| s_node.id == state_id)
    }

    // Helper to get the parent of a state, if it exists
    pub fn get_parent_of(&self, state_id: StateType) -> Option<StateType> {
        self.get_state_node(state_id)
            .and_then(|s_node| s_node.parent)
    }
}

// --- Runtime Instance ---

// Placeholder for hierarchy depth, make configurable or detect via macro later.
// const MAX_HIERARCHY_DEPTH: usize = 8; // Will be replaced by const generic M
// Make MAX_ACTIVE_REGIONS public so it can be accessed by lib.rs
pub const MAX_ACTIVE_REGIONS: usize = 4; // Max parallel regions/active states we can track

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum ProcessingError {
    PathTooLong,        // Replaces PathTooLongError struct
    CapacityExceeded,   // For various vector overflows during processing
    ArbitrationFailure, // If arbitration logic fails unexpectedly
    EntryLogicFailure, // If entry logic (execute_entry_actions_from_lca or enter_state_recursive_logic) has issues
}

impl core::fmt::Display for ProcessingError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            ProcessingError::PathTooLong => write!(f, "Maximum hierarchy path depth exceeded."),
            ProcessingError::CapacityExceeded => {
                write!(f, "Internal capacity exceeded during event processing.")
            }
            ProcessingError::ArbitrationFailure => {
                write!(f, "State transition arbitration failed.")
            }
            ProcessingError::EntryLogicFailure => {
                write!(f, "State entry logic failed after transition.")
            }
        }
    }
}

#[cfg(feature = "std")]
impl std::error::Error for ProcessingError {}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum EntryErrorKind {
    CycleDetected,
    CapacityExceeded, // For visited_during_entry vector
    StateNotFound,
    // AccumulatorFull, // If we decide to make accumulator push return an error
}

impl core::fmt::Display for EntryErrorKind {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            EntryErrorKind::CycleDetected => write!(f, "State entry cycle detected."),
            EntryErrorKind::CapacityExceeded => write!(
                f,
                "Capacity exceeded during state entry (e.g., visited path too long)."
            ),
            EntryErrorKind::StateNotFound => write!(f, "State not found during entry process."),
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EntryError {
    pub kind: EntryErrorKind,
    // pub state_id: Option<StateType> // Could add this later if specific state context is needed for errors
}

impl core::fmt::Display for EntryError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        write!(f, "Entry Error: {}", self.kind)
    }
}

#[cfg(feature = "std")]
impl std::error::Error for EntryError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        None // No underlying source error for these simple error types
    }
}

/// Result type for the `send_internal` method.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum SendResult {
    /// A transition was successfully processed.
    Transitioned,
    /// No matching transition was found for the event.
    NoMatch,
    /// An error occurred during event processing.
    Error(ProcessingError),
}

/// Runtime instance of a state machine.
///
/// Generic Parameters:
/// - `StateType`: The type representing state IDs (usually an enum).
/// - `EventType`: The type representing event IDs (usually an enum).
/// - `ContextType`: The user-defined context struct.
/// - `M`: Const generic for maximum hierarchy depth of a single state path.
/// - `MAX_NODES_FOR_COMPUTATION`: Const generic for buffer sizes needed for computations involving
///   multiple hierarchy branches, typically `M * MAX_ACTIVE_REGIONS`. This is used for temporary
///   collections during transition processing (e.g. exit sets).
#[derive(Debug)]
pub struct Runtime<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
    pub active_leaf_states: heapless::Vec<StateType, MAX_ACTIVE_REGIONS>,
    context: ContextType,
}

// --- ⛳ 1. Helper scratch struct (place just after Runtime<T> definition) ---------
struct Scratch<'a, StateType, const M: usize>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
{
    /// Tracks which states *already* had their entry action executed during the
    /// current `send_internal` cycle.  This is cleared at the end of the call.
    entry_actions_run: &'a mut heapless::Vec<StateType, M>,
}

// Helper function, can be outside impl Runtime or a static method if preferred.
// Making it a free function for now to ensure no `self` issues initially.
fn enter_state_recursive_logic<StateType, EventType, ContextType, const M: usize>(
    machine_def: &MachineDefinition<StateType, EventType, ContextType>,
    context: &mut ContextType,
    state_id_to_enter: StateType,
    accumulator: &mut heapless::Vec<StateType, MAX_ACTIVE_REGIONS>,
    visited_during_entry: &mut heapless::Vec<StateType, M>,
    scratch: &mut Scratch<'_, StateType, M>, // ← NEW
    event: &EventType,
) -> Result<(), EntryError>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    if visited_during_entry.contains(&state_id_to_enter) {
        return Ok(());
    }
    if visited_during_entry.push(state_id_to_enter).is_err() {
        debug_assert!(
            false,
            "Visited entry path too long for state: {state_id_to_enter:?}"
        );
        return Err(EntryError {
            kind: EntryErrorKind::CapacityExceeded,
        });
    }
    let result: Result<(), EntryError> = (|| {
        let Some(node) = machine_def.get_state_node(state_id_to_enter) else {
            assert!(
                !cfg!(debug_assertions),
                "State ID ({state_id_to_enter:?}) not found in MachineDefinition."
            );
            return Err(EntryError {
                kind: EntryErrorKind::StateNotFound,
            });
        };
        // --- ENTRY ACTION (dedup) ---
        if !scratch.entry_actions_run.contains(&state_id_to_enter) {
            if let Some(entry_fn) = node.entry_action {
                entry_fn(context, event);
            }
            scratch
                .entry_actions_run
                .push(state_id_to_enter)
                .map_err(|_| EntryError {
                    kind: EntryErrorKind::CapacityExceeded,
                })?;
        }
        if node.is_parallel {
            for s_node_in_def in machine_def.states {
                if s_node_in_def.parent == Some(state_id_to_enter) {
                    if let Some(region_entry_fn) = s_node_in_def.entry_action {
                        if !scratch.entry_actions_run.contains(&s_node_in_def.id) {
                            region_entry_fn(context, event);
                            scratch
                                .entry_actions_run
                                .push(s_node_in_def.id)
                                .map_err(|_| EntryError {
                                    kind: EntryErrorKind::CapacityExceeded,
                                })?;
                        }
                    }
                    let initial_child_of_region = s_node_in_def.initial_child.ok_or_else(|| {
                        debug_assert!(
                            false,
                            "Parallel region {:?} is missing an initial child.",
                            s_node_in_def.id
                        );
                        EntryError {
                            kind: EntryErrorKind::StateNotFound,
                        }
                    })?;
                    enter_state_recursive_logic::<_, _, _, M>(
                        machine_def,
                        context,
                        initial_child_of_region,
                        accumulator,
                        visited_during_entry,
                        scratch,
                        event,
                    )?;
                }
            }
        } else if let Some(initial_child_id) = node.initial_child {
            enter_state_recursive_logic::<_, _, _, M>(
                machine_def,
                context,
                initial_child_id,
                accumulator,
                visited_during_entry,
                scratch,
                event,
            )?;
        } else if !accumulator.contains(&state_id_to_enter)
            && accumulator.push(state_id_to_enter).is_err()
        {
            panic!(
                "MAX_ACTIVE_REGIONS ({}) exceeded while accumulating leaf states for {:?}.",
                accumulator.capacity(),
                state_id_to_enter
            );
        }

        Ok(())
    })();
    let _ = visited_during_entry.pop();
    result
}

// Define PotentialTransition struct at the module level
#[derive(Debug, Clone, Copy)]
struct PotentialTransition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    source_leaf_id: StateType,
    #[allow(dead_code)] // Will be used in full send() logic for arbitration
    transition_from_state_id: StateType,
    target_state_id: StateType,
    transition_ref: &'static Transition<StateType, EventType, ContextType>,
}

impl<StateType, EventType, ContextType, const M: usize, const MAX_NODES_FOR_COMPUTATION: usize>
    Runtime<StateType, EventType, ContextType, M, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    // Removed old fn enter_state_recursive(&mut self, ...) here

    /// Creates a new runtime instance for the given machine definition and initial context.
    ///
    /// # Panics
    ///
    /// This function may panic under the following conditions:
    /// - If the `initial_leaf_state` specified in the `MachineDefinition` is not found in the `STATES` array.
    /// - If `MAX_ACTIVE_REGIONS` is exceeded while trying to push initial leaf states (e.g. for a parallel initial state).
    /// - If `M` (formerly `MAX_HIERARCHY_DEPTH`) is exceeded during internal path calculations (via `expect` calls).
    pub fn new(
        machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
        initial_context: ContextType,
        initial_event: &EventType,
    ) -> Self {
        let mut mutable_context = initial_context;
        let mut active_states_vec = heapless::Vec::new();
        let mut visited_for_initial_entry: heapless::Vec<StateType, M> = heapless::Vec::new();

        let top_level_initial_state_id = machine_def.initial_leaf_state;

        // Pass M explicitly if needed, or let it be inferred from the type of visited_for_initial_entry
        if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M>(
            machine_def,
            &mut mutable_context,
            top_level_initial_state_id,
            &mut active_states_vec,
            &mut visited_for_initial_entry,
            &mut Scratch::<StateType, M> {
                entry_actions_run: &mut heapless::Vec::new(),
            },
            initial_event,
        ) {
            panic!("Failed to initialize state machine due to entry error: {entry_error:?}");
        }

        assert!(
            !active_states_vec.is_empty(),
            "Initial state ID specified in MachineDefinition not found in STATES array, or initial state setup resulted in no active states (after successful entry logic completion implies this should not happen)."
        );

        Runtime {
            machine_def, // Assign the reference
            active_leaf_states: active_states_vec,
            context: mutable_context,
        }
    }

    pub fn state(&self) -> heapless::Vec<StateType, MAX_ACTIVE_REGIONS> {
        self.active_leaf_states.clone()
    }
    pub fn context(&self) -> &ContextType {
        &self.context
    }
    pub fn context_mut(&mut self) -> &mut ContextType {
        &mut self.context
    }

    // --- Helper methods for hierarchical transitions ---

    /// Collects the path from a leaf state up to the root, including the leaf itself.
    /// The path is returned with the leaf state at index 0 and ancestors following.
    fn get_path_to_root(
        &self,
        leaf_state_id: StateType,
    ) -> Result<heapless::Vec<StateType, M>, ProcessingError> {
        // Changed error type
        // Changed return type
        let mut path: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut current_id = Some(leaf_state_id);
        while let Some(id) = current_id {
            if path.push(id).is_err() {
                // Changed from expect to check Result
                return Err(ProcessingError::PathTooLong);
            }
            current_id = self.machine_def.get_parent_of(id);
        }
        Ok(path)
    }

    /// Finds the Least Common Ancestor (LCA) of two states.
    fn find_lca(
        &self,
        state1_id: StateType,
        state2_id: StateType,
    ) -> Result<Option<StateType>, ProcessingError> {
        // Changed error type
        if state1_id == state2_id {
            return Ok(Some(state1_id));
        }

        let path1 = self.get_path_to_root(state1_id)?; // Path from state1 up to root
        let path2 = self.get_path_to_root(state2_id)?; // Path from state2 up to root

        // Iterate through path1 (from state1 towards root).
        // The first element of path1 also found in path2 is the LCA.
        for &id1_ancestor in &path1 {
            if path2.contains(&id1_ancestor) {
                return Ok(Some(id1_ancestor));
            }
        }

        Ok(None) // Should not happen if both states are in the same tree (i.e. have a common root)
        // but as a fallback if they somehow aren't (e.g. disconnected components, though our model assumes one tree).
    }

    fn is_proper_ancestor(
        &self,
        ancestor_candidate_id: StateType,
        descendant_candidate_id: StateType,
    ) -> Result<bool, ProcessingError> {
        // Changed error type
        // Changed return type
        if ancestor_candidate_id == descendant_candidate_id {
            return Ok(false);
        }
        match self.get_path_to_root(descendant_candidate_id) {
            Ok(path_from_descendant) => Ok(path_from_descendant
                .iter()
                .skip(1)
                .any(|&p_state| p_state == ancestor_candidate_id)),
            Err(e) => {
                // Propagate ProcessingError
                Err(e)
            }
        }
    }

    // Helper to find the direct child of parent_id that is currently active or an ancestor of an active leaf.
    fn get_active_child_of(
        &self,
        parent_id: StateType,
    ) -> Result<Option<StateType>, ProcessingError> {
        for &leaf_id in &self.active_leaf_states {
            if leaf_id == parent_id {
                continue;
            }
            let path_from_leaf_to_root = self.get_path_to_root(leaf_id)?;
            for i in 1..path_from_leaf_to_root.len() {
                if path_from_leaf_to_root[i] == parent_id {
                    return Ok(Some(path_from_leaf_to_root[i - 1]));
                }
            }
        }
        Ok(None)
    }

    // Helper to compute the ordered list of states to exit.
    fn compute_ordered_exit_set(
        &self,
        leaf_state_id_being_exited: StateType,
        lca_id: Option<StateType>,
    ) -> Result<heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>, ProcessingError> {
        // Changed error type
        // Return type uses new name

        let mut states_to_potentially_exit: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut collected_for_exit: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();

        // 1. Collect all states on the direct path from the active leaf up to (but not including) the LCA.
        let mut current_id_on_path = Some(leaf_state_id_being_exited);
        while let Some(id) = current_id_on_path {
            if lca_id == Some(id) {
                break;
            }
            // Check capacity before pushing to states_to_potentially_exit
            if states_to_potentially_exit.push(id).is_err() {
                // This implies M is too small for the hierarchy depth of this branch.
                return Err(ProcessingError::PathTooLong);
            }
            current_id_on_path = self.machine_def.get_parent_of(id);
        }
        // states_to_potentially_exit is now [leaf, p1, p2, ..., child_of_lca]

        // 2. For each state collected, recursively add its active children (for composite/parallel) first, then itself, to ensure post-order.
        //    Use a helper that ensures each state is added to `collected_for_exit` only once.
        let mut already_added_to_final_list: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut recursion_guard_vec: heapless::Vec<StateType, M> = heapless::Vec::new(); // Declare vec for recursion guard

        for &state_to_process_for_exit in states_to_potentially_exit.iter().rev() {
            // Process from child_of_lca down to leaf
            self.collect_states_for_exit_post_order(
                state_to_process_for_exit,
                lca_id,
                &mut collected_for_exit,
                &mut already_added_to_final_list,
                &mut recursion_guard_vec, // Pass the new guard
            )?; // Propagate error
        }
        Ok(collected_for_exit)
    }

    // Recursive helper for compute_ordered_exit_set
    fn collect_states_for_exit_post_order(
        &self,
        current_state_id: StateType,
        lca_id: Option<StateType>,
        ordered_exit_list: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        already_added: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        recursion_guard: &mut heapless::Vec<StateType, M>, // M should be sufficient for path depth
    ) -> Result<(), ProcessingError> {
        // Changed error type
        // Changed return type
        if Some(current_state_id) == lca_id || already_added.contains(&current_state_id) {
            return Ok(()); // Changed
        }

        let is_cycle_in_exit = recursion_guard.contains(&current_state_id);
        debug_assert!(
            !is_cycle_in_exit,
            "Cycle detected during collect_states_for_exit_post_order for state: {current_state_id:?}"
        );
        if is_cycle_in_exit {
            return Ok(()); // Changed
        }

        if recursion_guard.push(current_state_id).is_err() {
            // Check push failure
            debug_assert!(
                false, // This assertion will now always fail if the push fails.
                "Recursion depth exceeded in collect_states_for_exit_post_order (capacity {}) for state: {current_state_id:?}",
                recursion_guard.capacity()
            );
            return Err(ProcessingError::PathTooLong); // Return error
        }

        let Some(current_node) = self.machine_def.get_state_node(current_state_id) else {
            let _ = recursion_guard.pop(); // Pop before returning if node not found
            return Ok(()); // Changed
        };

        // Mark as visited for *this specific traversal context* to avoid issues if it's an ancestor of another part of main path.
        // The main `already_added` list prevents adding to `ordered_exit_list` multiple times.

        if current_node.is_parallel {
            for region_node in self
                .machine_def
                .states
                .iter()
                .filter(|n| n.parent == Some(current_state_id))
            {
                // Check if region is active (has a descendant in active_leaf_states)
                let mut region_active_leaf: Option<StateType> = None;
                for &leaf in &self.active_leaf_states {
                    match self.is_descendant_or_self(leaf, region_node.id) {
                        // Handle Result
                        Ok(is_desc) => {
                            if is_desc {
                                region_active_leaf = Some(leaf);
                                break;
                            }
                        }
                        Err(e) => return Err(e), // Propagate ProcessingError
                    }
                }
                if let Some(active_leaf_in_region) = region_active_leaf {
                    // Recurse from the active leaf of the region, stopping at the region itself (as region will be added later)
                    self.collect_states_for_exit_post_order(
                        active_leaf_in_region,
                        Some(region_node.id),
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
                // After region's children, add region itself (if not already added)
                if !already_added.contains(&region_node.id) {
                    self.collect_states_for_exit_post_order(
                        region_node.id,
                        lca_id,
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
            }
        } else if current_node.initial_child.is_some() {
            // Composite non-parallel
            if let Some(active_direct_child) = self.get_active_child_of(current_state_id)? {
                // This might need to handle Error
                self.collect_states_for_exit_post_order(
                    active_direct_child,
                    lca_id,
                    ordered_exit_list,
                    already_added,
                    recursion_guard,
                )?; // Propagate error
            }
        }

        // Add current_state_id to the list *after* its children have been processed and added.
        if !already_added.contains(&current_state_id) {
            // Ensure it's added only once. If these critical lists overflow, it's a fatal error.
            if ordered_exit_list.push(current_state_id).is_err() {
                let _ = recursion_guard.pop(); // Ensure guard is popped before panic or error return
                return Err(ProcessingError::CapacityExceeded);
            }
            if already_added.push(current_state_id).is_err() {
                let _ = recursion_guard.pop();
                return Err(ProcessingError::CapacityExceeded);
            }
        }
        let _ = recursion_guard.pop(); // Pop after processing this node and its children
        Ok(()) // Changed
    }

    // is_descendant_or_self method from before
    fn is_descendant_or_self(
        &self,
        candidate_id: StateType,
        ancestor_id: StateType,
    ) -> Result<bool, ProcessingError> {
        // Changed error type
        // Changed return type
        if candidate_id == ancestor_id {
            return Ok(true);
        }
        self.is_proper_ancestor(ancestor_id, candidate_id) // Propagate error
    }

    /// Returns the region root for a given state (the nearest ancestor whose parent is a parallel state), or None if not found.
    #[allow(dead_code)]
    fn get_region_root(&self, state_id: StateType) -> Option<StateType> {
        let mut current = state_id;
        while let Some(parent) = self.machine_def.get_parent_of(current) {
            if let Some(parent_node) = self.machine_def.get_state_node(parent) {
                if parent_node.is_parallel {
                    return Some(current);
                }
            }
            current = parent;
        }
        None
    }

    /// Sends an event to the state machine for processing.
    ///
    /// This is a **TEMPORARY IMPLEMENTATION** and will be significantly refactored
    /// to support parallel states.
    ///
    /// # Panics
    /// Contains `expect` and `panic` calls that might trigger if `MAX_ACTIVE_REGIONS` or
    /// `M` (formerly `MAX_HIERARCHY_DEPTH`) are too small, or if internal logic errors occur.
    // TODO: Refactor this function into smaller pieces.
    #[allow(clippy::too_many_lines)]
    pub fn send_internal(&mut self, event: &EventType) -> SendResult {
        #[cfg(feature = "debug-log")]
        {
            println!("COMPILE-TIME DEBUG-LOG FEATURE IS ACTIVE");
        }
        trace!(
            "[TRACE] send_internal START for event: {:?}, active_leaf_states: {:?}",
            event, self.active_leaf_states
        );
        #[cfg(feature = "std")]
        {
            println!("send_internal() called with event: {event:?}");
            io::stdout().flush().unwrap();
        }
        // Error type is now ProcessingError by default
        // Phase 0: Collect potential transitions (read-only on context for guards)
        let mut potential_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();
        let current_active_leaves_snapshot = self.active_leaf_states.clone();
        let mut potential_transitions_overflow = false;

        for &active_leaf_id in &current_active_leaves_snapshot {
            let mut check_state_id_opt = Some(active_leaf_id);
            'hierarchy_search: while let Some(check_state_id) = check_state_id_opt {
                if self.machine_def.get_state_node(check_state_id).is_some() {
                    for t_def in self.machine_def.transitions {
                        if t_def.from_state == check_state_id {
                            // Check if event matches using match_fn if available
                            if let Some(match_fn) = t_def.match_fn {
                                if !match_fn(event) {
                                    continue; // Skip this transition if event doesn't match
                                }
                            }
                            // Now check the guard if any
                            if let Some(guard_fn) = t_def.guard {
                                if !guard_fn(&self.context, event) {
                                    trace!(
                                        "[GUARD FAILED] From {:?} on {:?} → {:?}",
                                        t_def.from_state, event, t_def.to_state
                                    );
                                    continue;
                                }
                            }
                            trace!(
                                "[MATCH] From {:?} on {:?} → {:?}",
                                t_def.from_state, event, t_def.to_state
                            );
                            let pot_trans = PotentialTransition {
                                source_leaf_id: active_leaf_id,
                                transition_from_state_id: check_state_id,
                                target_state_id: t_def.to_state,
                                transition_ref: t_def,
                            };
                            if potential_transitions.push(pot_trans).is_err() {
                                potential_transitions_overflow = true;
                                break 'hierarchy_search;
                            }
                            break 'hierarchy_search;
                        }
                    }
                }
                check_state_id_opt = self.machine_def.get_parent_of(check_state_id);
            }
            if potential_transitions_overflow {
                break;
            }
        }

        if potential_transitions_overflow {
            return SendResult::Error(ProcessingError::CapacityExceeded);
        }

        if potential_transitions.is_empty() {
            return SendResult::NoMatch;
        }

        // Phase 0.5: Arbitrate and de-duplicate transitions (still read-only on context)
        let mut arbitrated_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();
        // ... (arbitration logic using self.is_proper_ancestor, which reads self.machine_def)
        // Ensure errors from is_proper_ancestor are handled (e.g., return SendResult::Error)
        'candidate_loop: for pt_candidate in &potential_transitions {
            for other_pt in &potential_transitions {
                if core::ptr::eq(pt_candidate, other_pt) {
                    continue;
                }
                match self.is_proper_ancestor(
                    pt_candidate.transition_from_state_id,
                    other_pt.transition_from_state_id,
                ) {
                    Ok(is_ancestor) => {
                        if is_ancestor {
                            continue 'candidate_loop;
                        }
                    }
                    Err(e) => return SendResult::Error(e), // Propagate ProcessingError from is_proper_ancestor
                }
            }
            if arbitrated_transitions.push(pt_candidate.clone()).is_err() {
                return SendResult::Error(ProcessingError::CapacityExceeded);
            }
        }

        if arbitrated_transitions.is_empty() {
            return SendResult::NoMatch;
        }

        let mut final_transitions_to_execute: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();
        let mut processed_transition_pointers: heapless::Vec<
            *const Transition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();

        for trans_to_consider in &arbitrated_transitions {
            let current_ref_ptr = trans_to_consider.transition_ref as *const _;
            let mut already_processed = false;
            for &seen_ptr in &processed_transition_pointers {
                if seen_ptr == current_ref_ptr {
                    already_processed = true;
                    break;
                }
            }
            if !already_processed {
                if final_transitions_to_execute
                    .push(trans_to_consider.clone())
                    .is_ok()
                {
                    if processed_transition_pointers.push(current_ref_ptr).is_err() {
                        return SendResult::Error(ProcessingError::CapacityExceeded);
                    }
                } else {
                    return SendResult::Error(ProcessingError::CapacityExceeded);
                }
            }
        }

        if final_transitions_to_execute.is_empty() {
            return SendResult::NoMatch;
        }

        // --- Context and State Commit Logic ---
        // Clone context here before any mutations by actions/entry/exit handlers.
        let mut temp_context = self.context.clone();
        let mut overall_transition_occurred = false;
        let mut states_exited_this_step: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut entry_execution_list: heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        > = heapless::Vec::new();

        // Phase 1: Process exits and actions for all transitions first (use temp_context)
        for trans_info in &final_transitions_to_execute {
            let source_state_id = trans_info.transition_from_state_id;
            let target_state_id = trans_info.target_state_id;
            let active_leaf_for_this_trans = trans_info.source_leaf_id;
            overall_transition_occurred = true;
            trace!(
                "[TRANSITION] {:?} → {:?} via {:?}",
                source_state_id, target_state_id, event
            );

            #[cfg(feature = "std")]
            {
                println!(
                    "[TRACE] Active before: {prev:?}",
                    prev = self.active_leaf_states
                );
                io::stdout().flush().unwrap();
                println!(
                    "[TRACE] Processing transition: {source_state_id:?} → {target_state_id:?}"
                );
            }

            let is_desc_result =
                self.is_descendant_or_self(active_leaf_for_this_trans, source_state_id);
            let is_simple_leaf_self_transition = source_state_id == target_state_id
                && match is_desc_result {
                    Ok(is_desc) => is_desc,
                    Err(e) => return SendResult::Error(e),
                }
                && self
                    .machine_def
                    .get_state_node(source_state_id)
                    .is_some_and(|n| !n.is_parallel && n.initial_child.is_none());

            if is_simple_leaf_self_transition {
                if let Some(node) = self.machine_def.get_state_node(source_state_id) {
                    if !states_exited_this_step.contains(&source_state_id) {
                        if let Some(exit_fn) = node.exit_action {
                            trace!("[EXIT] {:?} (exit_fn = true)", source_state_id);
                            exit_fn(&mut temp_context, event);
                        } else {
                            trace!("[EXIT] {:?} (exit_fn = false)", source_state_id);
                        }
                        if states_exited_this_step.push(source_state_id).is_err() {
                            return SendResult::Error(ProcessingError::CapacityExceeded);
                        }
                    }
                }
                if let Some(action_fn) = trans_info.transition_ref.action {
                    trace!(
                        "[ACTION] Running action for {:?} → {:?} on {:?}",
                        source_state_id, target_state_id, event
                    );
                    action_fn(&mut temp_context, event);
                }
                if entry_execution_list
                    .push((
                        source_state_id,
                        Some(source_state_id),
                        active_leaf_for_this_trans,
                    ))
                    .is_err()
                {
                    return SendResult::Error(ProcessingError::CapacityExceeded);
                }
            } else if source_state_id == target_state_id {
                let node_being_self_transitioned =
                    self.machine_def.get_state_node(source_state_id).unwrap();
                let parent_of_source = node_being_self_transitioned.parent;
                for &current_active_leaf in &current_active_leaves_snapshot {
                    // Use original snapshot for active leaves
                    if self
                        .is_descendant_or_self(current_active_leaf, source_state_id)
                        .unwrap_or(false)
                    {
                        let states_to_exit_for_this_leaf_branch = match self
                            .compute_ordered_exit_set(current_active_leaf, parent_of_source)
                        {
                            Ok(s) => s,
                            Err(e) => return SendResult::Error(e),
                        };
                        for &state_to_exit_id in &states_to_exit_for_this_leaf_branch {
                            if !states_exited_this_step.contains(&state_to_exit_id) {
                                if let Some(node) =
                                    self.machine_def.get_state_node(state_to_exit_id)
                                {
                                    if let Some(exit_fn) = node.exit_action {
                                        trace!("[EXIT] {:?} (exit_fn = true)", state_to_exit_id);
                                        exit_fn(&mut temp_context, event);
                                    } else {
                                        trace!("[EXIT] {:?} (exit_fn = false)", state_to_exit_id);
                                    }
                                }
                                if states_exited_this_step.push(state_to_exit_id).is_err() {
                                    return SendResult::Error(ProcessingError::CapacityExceeded);
                                }
                            }
                        }
                    }
                }
                if let Some(action_fn) = trans_info.transition_ref.action {
                    trace!(
                        "[ACTION] Running action for {:?} → {:?} on {:?}",
                        source_state_id, target_state_id, event
                    );
                    action_fn(&mut temp_context, event);
                }
                if entry_execution_list
                    .push((
                        source_state_id,
                        Some(source_state_id),
                        active_leaf_for_this_trans,
                    ))
                    .is_err()
                {
                    return SendResult::Error(ProcessingError::CapacityExceeded);
                }
            } else {
                let lca_id = match self.find_lca(active_leaf_for_this_trans, target_state_id) {
                    Ok(l) => l,
                    Err(e) => return SendResult::Error(e),
                };
                let states_to_exit_for_branch =
                    match self.compute_ordered_exit_set(active_leaf_for_this_trans, lca_id) {
                        Ok(s) => s,
                        Err(e) => return SendResult::Error(e),
                    };
                for &state_to_exit_id in &states_to_exit_for_branch {
                    if !states_exited_this_step.contains(&state_to_exit_id) {
                        if let Some(node) = self.machine_def.get_state_node(state_to_exit_id) {
                            if let Some(exit_fn) = node.exit_action {
                                trace!("[EXIT] {:?} (exit_fn = true)", state_to_exit_id);
                                exit_fn(&mut temp_context, event);
                            } else {
                                trace!("[EXIT] {:?} (exit_fn = false)", state_to_exit_id);
                            }
                        }
                        if states_exited_this_step.push(state_to_exit_id).is_err() {
                            return SendResult::Error(ProcessingError::CapacityExceeded);
                        }
                    }
                }
                if source_state_id == target_state_id
                    && !states_exited_this_step.contains(&source_state_id)
                {
                    if let Some(node) = self.machine_def.get_state_node(source_state_id) {
                        if let Some(exit_fn) = node.exit_action {
                            trace!("[EXIT] {:?} (exit_fn = true)", source_state_id);
                            exit_fn(&mut temp_context, event);
                        } else {
                            trace!("[EXIT] {:?} (exit_fn = false)", source_state_id);
                        }
                    }
                    if states_exited_this_step.push(source_state_id).is_err() {
                        return SendResult::Error(ProcessingError::CapacityExceeded);
                    }
                }
                if let Some(action_fn) = trans_info.transition_ref.action {
                    trace!(
                        "[ACTION] Running action for {:?} → {:?} on {:?}",
                        source_state_id, target_state_id, event
                    );
                    action_fn(&mut temp_context, event);
                }
                let lca_for_entry = lca_id; // always use real LCA so ancestors stay suppressed
                if entry_execution_list
                    .push((target_state_id, lca_for_entry, active_leaf_for_this_trans))
                    .is_err()
                {
                    return SendResult::Error(ProcessingError::CapacityExceeded);
                }
            }
        }
        #[cfg(feature = "std")]
        dbg!(&states_exited_this_step);

        // Phase 2: Update active leaf states based on global exits (use current_active_leaves_snapshot)
        let mut retained_leaves = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        if overall_transition_occurred {
            for &leaf in &current_active_leaves_snapshot {
                // Strict check: remove leaves that are self or descendant of any exited state
                let should_remove = states_exited_this_step
                    .iter()
                    .any(|&exited| self.is_descendant_or_self(leaf, exited).unwrap_or(false));
                if !should_remove && retained_leaves.push(leaf).is_err() {
                    return SendResult::Error(ProcessingError::CapacityExceeded);
                }
            }
            #[cfg(feature = "std")]
            dbg!(&states_exited_this_step, &retained_leaves);
            trace!("🧬 Retained leaves before merge: {:?}", retained_leaves);
        }

        // Phase 3: Process entries and add new leaves (use temp_context)
        let mut new_leaves = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        for &(target_id, lca_id, source_id) in &entry_execution_list {
            trace!(
                "[TRACE] ENTRY EXEC: target_state_id = {:?}, lca_id = {:?}, ancestry = {:?}",
                target_id,
                lca_id,
                self.get_ancestry(target_id)
            );
            match self.execute_entry_actions_from_lca_with_context(
                target_id,
                lca_id,
                source_id, // Use source_id from the tuple
                event,
                &mut Scratch::<StateType, M> {
                    entry_actions_run: &mut heapless::Vec::new(),
                },
                &mut temp_context,
            ) {
                Ok(leaves_from_entry) => {
                    for new_leaf in leaves_from_entry {
                        if new_leaves.push(new_leaf).is_err() {
                            return SendResult::Error(ProcessingError::CapacityExceeded);
                        }
                    }
                }
                Err(processing_error) => return SendResult::Error(processing_error),
            }
        }

        // Filter: Only keep true leaves (not parents of any other in the set)
        let mut only_leaves = heapless::Vec::<StateType, MAX_ACTIVE_REGIONS>::new();
        'outer: for &candidate in &new_leaves {
            for &other in &new_leaves {
                if candidate != other && self.machine_def.get_parent_of(other) == Some(candidate) {
                    continue 'outer; // candidate is a parent, not a leaf
                }
            }
            only_leaves
                .push(candidate)
                .unwrap_or_else(|_| panic!("Failed to push leaf {candidate:?}"));
        }

        // --- Refactored atomic update of active_leaf_states ---
        let entry_execution_list_fallback = entry_execution_list.clone();
        let mut next_active_leaves = heapless::Vec::<StateType, MAX_ACTIVE_REGIONS>::new();

        // --- Parallel-safe merge logic: retain unaffected, add new, fallback if empty ---
        next_active_leaves.clear();

        // Step 1: Retain active leaves that were not exited
        for &leaf in &current_active_leaves_snapshot {
            if !states_exited_this_step
                .iter()
                .any(|&exited| self.is_descendant_or_self(leaf, exited).unwrap_or(false))
                && !next_active_leaves.contains(&leaf)
            {
                next_active_leaves.push(leaf).unwrap();
            }
        }
        trace!(
            "[TRACE] PATCH: Retained leaves after exit: {:?}",
            next_active_leaves
        );

        // Step 2: Overwrite if all old leaves exited and new ones exist
        if next_active_leaves.is_empty() && !only_leaves.is_empty() {
            for &leaf in &only_leaves {
                let resolved_leaf = self.resolve_to_leaf(leaf);
                if !next_active_leaves.contains(&resolved_leaf) {
                    next_active_leaves.push(resolved_leaf).unwrap();
                }
            }
            trace!(
                "[TRACE] PATCH: All old leaves exited, overwriting with only_leaves: {:?}",
                next_active_leaves
            );
        } else {
            // Step 3: Merge new leaves into retained ones
            for &leaf in &only_leaves {
                let resolved_leaf = self.resolve_to_leaf(leaf);
                if !next_active_leaves.contains(&resolved_leaf) {
                    next_active_leaves.push(resolved_leaf).unwrap();
                }
            }
            trace!(
                "[TRACE] PATCH: Added only_leaves to retained, next_active_leaves: {:?}",
                next_active_leaves
            );
        }

        // Step 4: Fallback to entry fallback state if necessary
        if next_active_leaves.is_empty() && !entry_execution_list_fallback.is_empty() {
            let (target_state_id, _, _) = entry_execution_list_fallback[0];
            let fallback_leaf = self.resolve_to_leaf(target_state_id);
            trace!(
                "[TRACE] Fallback triggered for event {:?}: fallback_leaf = {:?}",
                event, fallback_leaf
            );
            next_active_leaves.push(fallback_leaf).unwrap();
        }

        trace!(
            "[TRACE] FINAL next_active_leaves to assign: {:?}",
            next_active_leaves
        );
        self.active_leaf_states.clear();
        self.active_leaf_states
            .extend(next_active_leaves.iter().copied());
        trace!(
            "[TRACE] self.active_leaf_states AFTER extend: {:?}",
            self.active_leaf_states
        );

        // ... rest of send_internal ...
        // Return SendResult as before
        if overall_transition_occurred {
            self.context = temp_context;
            SendResult::Transitioned
        } else {
            SendResult::NoMatch
        }
        // ... existing code ...
    }

    // Cloned and modified version of execute_entry_actions_from_lca to accept context
    // This is a temporary measure; ideally, the original would be refactored.
    #[allow(clippy::too_many_lines)]
    fn execute_entry_actions_from_lca_with_context(
        &self,
        target_state_id: StateType,
        lca_id: Option<StateType>,
        source_state_id: StateType, // NEW
        event: &EventType,
        scratch: &mut Scratch<'_, StateType, M>,
        context: &mut ContextType,
    ) -> Result<heapless::Vec<StateType, MAX_ACTIVE_REGIONS>, ProcessingError> {
        trace!(
            "[TRACE] ENTER execute_entry_actions_from_lca_with_context: target_state_id = {:?}, lca_id = {:?}",
            target_state_id, lca_id
        );
        let mut new_active_leaf_states = heapless::Vec::new();
        let path_from_target_to_root = self.get_path_to_root(target_state_id)?;
        trace!(
            "[TRACE] path_from_target_to_root for {:?}: {:?}",
            target_state_id, path_from_target_to_root
        );
        let mut entry_path_segment: heapless::Vec<StateType, M> = heapless::Vec::new();

        trace!(
            "[TRACE] lca_id BEFORE entry_path_segment construction: {:?}",
            lca_id
        );
        if let Some(lca) = lca_id {
            // Clear & rebuild so patch is idempotent in case of multiple compilations
            entry_path_segment.clear();

            // Iterate from root‑wards (reverse) but SKIP the LCA itself.
            // Push every state *below* the LCA (i.e., the part that is NOT already active).
            let mut found_lca = false;
            for &state in path_from_target_to_root.iter().rev() {
                if state == lca {
                    found_lca = true;
                    continue; // <-- skip LCA
                }
                if found_lca {
                    entry_path_segment
                        .push(state)
                        .map_err(|_| ProcessingError::PathTooLong)?;
                }
            }
        } else {
            // (unchanged) full push when there is no LCA or LCA == target.
            entry_path_segment.clear();
            for &state in path_from_target_to_root.iter().rev() {
                entry_path_segment
                    .push(state)
                    .map_err(|_| ProcessingError::PathTooLong)?;
            }
        }
        trace!(
            "[TRACE] Calculated entry_path_segment: {:?}",
            entry_path_segment
        );
        for &state_to_enter in &entry_path_segment {
            let node = self
                .machine_def
                .get_state_node(state_to_enter)
                .ok_or(ProcessingError::EntryLogicFailure)?;
            // --- ENTRY ACTION (dedup) ---
            if !scratch.entry_actions_run.contains(&state_to_enter) {
                if let Some(entry_fn) = node.entry_action {
                    entry_fn(context, event);
                }
                scratch
                    .entry_actions_run
                    .push(state_to_enter)
                    .map_err(|_| ProcessingError::CapacityExceeded)?;
            }
            // Recursion into children always happens for parallel states
            if node.is_parallel && state_to_enter != target_state_id {
                if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M>(
                    self.machine_def,
                    context,
                    state_to_enter,
                    &mut new_active_leaf_states,
                    &mut heapless::Vec::new(), // visited_during_entry, not used for dedup now
                    scratch,
                    event,
                ) {
                    return Err(match entry_error.kind {
                        EntryErrorKind::CycleDetected | EntryErrorKind::StateNotFound => {
                            ProcessingError::EntryLogicFailure
                        }
                        EntryErrorKind::CapacityExceeded => ProcessingError::CapacityExceeded,
                    });
                }
            }
        }
        // Now handle the target state itself (if not already processed)
        let is_self_transition =
            lca_id == Some(target_state_id) && target_state_id == source_state_id;
        if is_self_transition {
            // For self-transitions, always run the entry action (even if already in dedup set)
            if let Some(entry_fn) = self
                .machine_def
                .get_state_node(target_state_id)
                .and_then(|n| n.entry_action)
            {
                entry_fn(context, event);
            }
            // Still add to dedup set to prevent double entry in recursion
            if !scratch.entry_actions_run.contains(&target_state_id) {
                scratch
                    .entry_actions_run
                    .push(target_state_id)
                    .map_err(|_| ProcessingError::CapacityExceeded)?;
            }
        } else if lca_id != Some(target_state_id)
            && !scratch.entry_actions_run.contains(&target_state_id)
        {
            // For all other transitions, only run if not already entered
            if let Some(entry_fn) = self
                .machine_def
                .get_state_node(target_state_id)
                .and_then(|n| n.entry_action)
            {
                entry_fn(context, event);
            }
            scratch
                .entry_actions_run
                .push(target_state_id)
                .map_err(|_| ProcessingError::CapacityExceeded)?;
        }
        // Recursion into children always happens
        let node = self
            .machine_def
            .get_state_node(target_state_id)
            .ok_or(ProcessingError::EntryLogicFailure)?;
        if node.is_parallel || node.initial_child.is_some() {
            if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M>(
                self.machine_def,
                context,
                target_state_id,
                &mut new_active_leaf_states,
                &mut heapless::Vec::new(), // visited_during_entry, not used for dedup now
                scratch,
                event,
            ) {
                return Err(match entry_error.kind {
                    EntryErrorKind::CycleDetected | EntryErrorKind::StateNotFound => {
                        ProcessingError::EntryLogicFailure
                    }
                    EntryErrorKind::CapacityExceeded => ProcessingError::CapacityExceeded,
                });
            }
        } else {
            // Atomic state
            if !new_active_leaf_states.contains(&target_state_id)
                && new_active_leaf_states.push(target_state_id).is_err()
            {
                return Err(ProcessingError::CapacityExceeded);
            }
        }
        Ok(new_active_leaf_states)
    }

    /// Resolves a state to its true leaf by following `initial_child` recursively.
    fn resolve_to_leaf(&self, mut state: StateType) -> StateType {
        while let Some(child) = self
            .machine_def
            .get_state_node(state)
            .and_then(|n| n.initial_child)
        {
            state = child;
        }
        state
    }

    // Add this helper for ancestry tracing
    #[allow(dead_code)]
    fn get_ancestry(&self, mut state_id: StateType) -> heapless::Vec<StateType, M> {
        let mut ancestry = heapless::Vec::new();
        ancestry.push(state_id).ok();
        while let Some(parent) = self.machine_def.get_parent_of(state_id) {
            ancestry.push(parent).ok();
            state_id = parent;
        }
        ancestry
    }
}

impl<StateType, EventType, ContextType, const M: usize, const MAX_NODES_FOR_COMPUTATION: usize>
    StateMachine for Runtime<StateType, EventType, ContextType, M, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    type State = StateType;
    type Event = EventType;
    type Context = ContextType;

    fn send(&mut self, event: &EventType) -> SendResult {
        self.send_internal(event)
    }

    fn state(&self) -> heapless::Vec<Self::State, MAX_ACTIVE_REGIONS> {
        self.active_leaf_states.clone()
    }

    fn context(&self) -> &Self::Context {
        &self.context
    }

    fn context_mut(&mut self) -> &mut Self::Context {
        &mut self.context
    }
}

#[cfg(test)]
#[allow(clippy::trivially_copy_pass_by_ref)] // Allow for test events
mod tests {
    use super::*; //Imports S, E, C types from parent
    use crate::core::DefaultContext; // Ensure DefaultContext is in scope

    // Define const M for tests, e.g., 8, matching old MAX_HIERARCHY_DEPTH for compatibility.
    const TEST_HIERARCHY_DEPTH_M: usize = 8;
    const TEST_MAX_NODES_FOR_COMPUTATION: usize = TEST_HIERARCHY_DEPTH_M * MAX_ACTIVE_REGIONS; // Renamed from TEST_MTMAR

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestState {
        S0,
        S1,
        S2,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestEvent {
        E0,
        E1,
    }

    // Using the DefaultContext from the parent module for this alias
    type TestContextForEmpty = DefaultContext;

    // Define CounterContext at the module scope for tests
    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct TestContext {
        // Assuming this is the context for transition_action_for_increment
        val: i32, // Example field
    }

    // Action function for basic_machine_integration_test
    #[allow(clippy::trivially_copy_pass_by_ref)] // EventType is Copy
    fn transition_action_for_increment(context: &mut TestContext, _event: &TestEvent) {
        context.val += 1; // Example action
    }

    // Guard function for basic_machine_integration_test (example, ensure its signature is correct)
    #[allow(clippy::trivially_copy_pass_by_ref)] // EventType is Copy
    fn guard_for_increment(context: &TestContext, _event: &TestEvent) -> bool {
        context.val < 5 // Example guard
    }

    // Match functions for TestEvent transitions
    fn matches_test_event_e0(event: &TestEvent) -> bool {
        matches!(event, TestEvent::E0)
    }

    // Populated StateNode arrays for tests
    const TEST_STATENODES_EMPTY_CTX_POPULATED: &[StateNode<
        TestState,
        TestContextForEmpty,
        TestEvent,
    >] = &[
        StateNode {
            id: TestState::S0,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S1,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S2,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    const TEST_STATENODES_COUNTER_CTX_POPULATED: &[StateNode<TestState, TestContext, TestEvent>] =
        &[
            StateNode {
                id: TestState::S0,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
            StateNode {
                id: TestState::S1,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
            StateNode {
                id: TestState::S2,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
        ];

    // --- New Test Setup for Hierarchical Transitions ---

    const MAX_LOG_ENTRIES: usize = 64; // Increased from 32
    const MAX_LOG_STRING_LEN: usize = 64; // Max length for a logged action string

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct HierarchicalActionLogContext {
        log: Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES>,
    }

    impl HierarchicalActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<MAX_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String");
            self.log
                .push(s) // try_push not strictly necessary if MAX_LOG_ENTRIES is sufficient for tests and we expect it to succeed.
                .expect("Log vec full in HierarchicalActionLogContext");
        }
        fn get_log(&self) -> &Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> {
            &self.log
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum TestHierarchyState {
        ParentOne,
        ChildOneAlpha,            // Child of ParentOne
        GrandchildOneAlphaXray,   // Child of ChildOneAlpha
        GrandchildOneAlphaYankee, // Child of ChildOneAlpha
        ChildOneBravo,            // Child of ParentOne
        ParentTwo,
        ChildTwoAlpha, // Child of ParentTwo
    }

    #[derive(Debug, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum TestHierarchyEvent {
        EventTriggerP1ToP2,        // ParentOne to ParentTwo
        EventTriggerP1ToC1B,       // ParentOne to ChildOneBravo
        EventTriggerToSibling,     // ChildOneAlpha to ChildOneBravo
        EventTriggerToParent,      // GrandchildOneAlphaXray to ChildOneAlpha
        EventTriggerToGrandparent, // GrandchildOneAlphaYankee to ParentOne
        EventTriggerToCousinChild, // ChildOneBravo to GrandchildOneAlphaYankee
        EventTriggerParentReentry, // ChildOneBravo to ParentOne (expect re-entry logic)
        EventTriggerP2ToP1,        // ParentTwo to ParentOne
    }

    // Helper action functions for logging
    fn log_enter_parent_one(ctx: &mut HierarchicalActionLogContext, _event: &TestHierarchyEvent) {
        ctx.log_action("EnterParentOne");
    }
    fn log_exit_parent_one(ctx: &mut HierarchicalActionLogContext, _event: &TestHierarchyEvent) {
        ctx.log_action("ExitParentOne");
    }
    fn log_enter_child_one_alpha(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("EnterChildOneAlpha");
    }
    fn log_exit_child_one_alpha(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("ExitChildOneAlpha");
    }
    fn log_enter_grandchild_one_alpha_xray(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("EnterGrandchildOneAlphaXray");
    }
    fn log_exit_grandchild_one_alpha_xray(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("ExitGrandchildOneAlphaXray");
    }
    fn log_enter_grandchild_one_alpha_yankee(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("EnterGrandchildOneAlphaYankee");
    }
    fn log_exit_grandchild_one_alpha_yankee(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("ExitGrandchildOneAlphaYankee");
    }
    fn log_enter_child_one_bravo(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("EnterChildOneBravo");
    }
    fn log_exit_child_one_bravo(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("ExitChildOneBravo");
    }
    fn log_enter_parent_two(ctx: &mut HierarchicalActionLogContext, _event: &TestHierarchyEvent) {
        ctx.log_action("EnterParentTwo");
    }
    fn log_exit_parent_two(ctx: &mut HierarchicalActionLogContext, _event: &TestHierarchyEvent) {
        ctx.log_action("ExitParentTwo");
    }
    fn log_enter_child_two_alpha(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("EnterChildTwoAlpha");
    }
    fn log_exit_child_two_alpha(
        ctx: &mut HierarchicalActionLogContext,
        _event: &TestHierarchyEvent,
    ) {
        ctx.log_action("ExitChildTwoAlpha");
    }
    fn log_transition_action(ctx: &mut HierarchicalActionLogContext, _event: &TestHierarchyEvent) {
        // Added _event back
        ctx.log_action("TransitionAction");
    }

    // Match functions for TestHierarchyEvent transitions
    fn matches_event_trigger_p1_to_p2(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerP1ToP2)
    }

    fn matches_event_trigger_p1_to_c1b(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerP1ToC1B)
    }

    fn matches_event_trigger_to_sibling(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerToSibling)
    }

    fn matches_event_trigger_to_parent(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerToParent)
    }

    fn matches_event_trigger_to_grandparent(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerToGrandparent)
    }

    fn matches_event_trigger_to_cousin_child(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerToCousinChild)
    }

    fn matches_event_trigger_parent_reentry(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerParentReentry)
    }

    fn matches_event_trigger_p2_to_p1(event: &TestHierarchyEvent) -> bool {
        matches!(event, TestHierarchyEvent::EventTriggerP2ToP1)
    }

    const TEST_HIERARCHY_STATENODES: &[StateNode<
        TestHierarchyState,
        HierarchicalActionLogContext,
        TestHierarchyEvent,
    >] = &[
        // ParentOne level
        StateNode {
            id: TestHierarchyState::ParentOne,
            parent: None,
            initial_child: Some(TestHierarchyState::ChildOneAlpha),
            entry_action: Some(log_enter_parent_one),
            exit_action: Some(log_exit_parent_one),
            is_parallel: false,
        },
        // Children of ParentOne
        StateNode {
            id: TestHierarchyState::ChildOneAlpha,
            parent: Some(TestHierarchyState::ParentOne),
            initial_child: Some(TestHierarchyState::GrandchildOneAlphaXray),
            entry_action: Some(log_enter_child_one_alpha),
            exit_action: Some(log_exit_child_one_alpha),
            is_parallel: false,
        },
        StateNode {
            id: TestHierarchyState::ChildOneBravo,
            parent: Some(TestHierarchyState::ParentOne),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_child_one_bravo),
            exit_action: Some(log_exit_child_one_bravo),
            is_parallel: false,
        },
        // Grandchildren of ParentOne (children of ChildOneAlpha)
        StateNode {
            id: TestHierarchyState::GrandchildOneAlphaXray,
            parent: Some(TestHierarchyState::ChildOneAlpha),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_grandchild_one_alpha_xray),
            exit_action: Some(log_exit_grandchild_one_alpha_xray),
            is_parallel: false,
        },
        StateNode {
            id: TestHierarchyState::GrandchildOneAlphaYankee,
            parent: Some(TestHierarchyState::ChildOneAlpha),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_grandchild_one_alpha_yankee),
            exit_action: Some(log_exit_grandchild_one_alpha_yankee),
            is_parallel: false,
        },
        // ParentTwo level
        StateNode {
            id: TestHierarchyState::ParentTwo,
            parent: None,
            initial_child: Some(TestHierarchyState::ChildTwoAlpha),
            entry_action: Some(log_enter_parent_two),
            exit_action: Some(log_exit_parent_two),
            is_parallel: false,
        },
        // Children of ParentTwo
        StateNode {
            id: TestHierarchyState::ChildTwoAlpha,
            parent: Some(TestHierarchyState::ParentTwo),
            initial_child: None, // Leaf state
            entry_action: Some(log_enter_child_two_alpha),
            exit_action: Some(log_exit_child_two_alpha),
            is_parallel: false,
        },
    ];

    const HIERARCHY_TEST_TRANSITIONS: &[Transition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    >] = &[
        // EventTriggerP1ToP2: ParentOne to ParentTwo
        Transition {
            from_state: TestHierarchyState::ParentOne,
            to_state: TestHierarchyState::ParentTwo,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_p1_to_p2),
        },
        // New transition for ParentOne to ChildOneBravo
        Transition {
            from_state: TestHierarchyState::ParentOne,
            to_state: TestHierarchyState::ChildOneBravo,
            action: Some(log_transition_action), // Add a transition action
            guard: None,
            match_fn: Some(matches_event_trigger_p1_to_c1b),
        },
        // Transition from ChildOneAlpha to ChildOneBravo
        Transition {
            from_state: TestHierarchyState::ChildOneAlpha,
            to_state: TestHierarchyState::ChildOneBravo,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_to_sibling),
        },
        // Transition from GrandchildOneAlphaXray to ChildOneAlpha
        Transition {
            from_state: TestHierarchyState::GrandchildOneAlphaXray,
            to_state: TestHierarchyState::ChildOneAlpha,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_to_parent),
        },
        // Transition from GrandchildOneAlphaYankee to ParentOne
        Transition {
            from_state: TestHierarchyState::GrandchildOneAlphaYankee,
            to_state: TestHierarchyState::ParentOne,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_to_grandparent),
        },
        // ChildOneBravo to GrandchildOneAlphaYankee (Cousin transition)
        Transition {
            from_state: TestHierarchyState::ChildOneBravo,
            to_state: TestHierarchyState::GrandchildOneAlphaYankee,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_to_cousin_child),
        },
        // Parent-reentry transition (ChildOneBravo to ParentOne)
        Transition {
            from_state: TestHierarchyState::ChildOneBravo,
            to_state: TestHierarchyState::ParentOne,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_parent_reentry),
        },
        // EventTriggerP2ToP1: ParentTwo to ParentOne
        Transition {
            from_state: TestHierarchyState::ParentTwo,
            to_state: TestHierarchyState::ParentOne,
            action: Some(log_transition_action),
            guard: None,
            match_fn: Some(matches_event_trigger_p2_to_p1),
        },
    ];

    static PARENT_TO_CHILD_MACHINE_DEF: MachineDefinition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    > = MachineDefinition::new(
        TEST_HIERARCHY_STATENODES,
        HIERARCHY_TEST_TRANSITIONS,
        TestHierarchyState::ParentOne,
    );

    static COUSIN_MACHINE_DEF: MachineDefinition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    > = MachineDefinition::new(
        TEST_HIERARCHY_STATENODES,
        HIERARCHY_TEST_TRANSITIONS,
        TestHierarchyState::ParentOne,
    );

    static CROSS_PARENT_MACHINE_DEF: MachineDefinition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    > = MachineDefinition::new(
        TEST_HIERARCHY_STATENODES,
        HIERARCHY_TEST_TRANSITIONS,
        TestHierarchyState::ParentOne,
    );

    static MACHINE_DEF: MachineDefinition<
        TestHierarchyState,
        TestHierarchyEvent,
        HierarchicalActionLogContext,
    > = MachineDefinition::new(
        TEST_HIERARCHY_STATENODES,
        HIERARCHY_TEST_TRANSITIONS,
        TestHierarchyState::ParentOne, // Top-level initial state for the machine definition
    );

    #[test]
    fn hierarchical_machine_starts_in_correct_initial_leaf_with_entry_actions() {
        let initial_context = HierarchicalActionLogContext::default();
        let initial_event_for_test = TestHierarchyEvent::EventTriggerP1ToP2; // Example, choose any valid event
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );

        // Check final leaf state
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        // Check entry action log
        let mut expected_log_vec: heapless::Vec<
            heapless::String<MAX_LOG_STRING_LEN>,
            MAX_LOG_ENTRIES,
        > = heapless::Vec::new();
        expected_log_vec
            .push(heapless::String::try_from("EnterParentOne").unwrap())
            .expect("Log full");
        expected_log_vec
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log_vec
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log_vec);
    }

    #[test]
    fn test_sibling_transition_with_lca() {
        static SIBLING_LCA_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            HIERARCHY_TEST_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );

        let initial_event_for_test = TestHierarchyEvent::EventTriggerToSibling; // Example, choose any valid event
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &SIBLING_LCA_MACHINE_DEF, // <--- Uses the static definition
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        ); // Verify starting state
        runtime.context_mut().log.clear(); // Clear initial entry logs

        let event_processed = runtime.send(&TestHierarchyEvent::EventTriggerToSibling);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventTriggerToSibling should have been processed"
        );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildOneBravo]
        );

        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneBravo").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn machine_starts_in_initial_state() {
        const TEST_TRANSITIONS: &[Transition<TestState, TestEvent, TestContextForEmpty>] = &[];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContextForEmpty> =
            MachineDefinition::new(
                TEST_STATENODES_EMPTY_CTX_POPULATED,
                TEST_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = DefaultContext::default();
        let initial_event_for_test = TestEvent::E0; // Example
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );
        assert_eq!(runtime.state().as_slice(), &[TestState::S0]);
    }

    #[test]
    fn send_event_triggers_transition_and_action() {
        const ACTION_TRANSITIONS: &[Transition<TestState, TestEvent, TestContext>] =
            &[Transition {
                from_state: TestState::S0,
                to_state: TestState::S1,
                action: Some(transition_action_for_increment),
                guard: None,
                match_fn: Some(matches_test_event_e0),
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                ACTION_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = TestContext { val: 0 };
        let initial_event_for_test = TestEvent::E0; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );

        assert_eq!(runtime.send(&TestEvent::E0), SendResult::Transitioned);
        assert_eq!(runtime.state().as_slice(), &[TestState::S1]);
        assert_eq!(runtime.context().val, 1);
    }

    #[test]
    fn send_event_no_transition_if_guard_fails() {
        const GUARDED_TRANSITIONS: &[Transition<TestState, TestEvent, TestContext>] =
            &[Transition {
                from_state: TestState::S0,
                to_state: TestState::S1,
                action: Some(transition_action_for_increment),
                guard: Some(guard_for_increment),
                match_fn: Some(matches_test_event_e0),
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                GUARDED_TRANSITIONS,
                TestState::S0,
            );

        // Test case 1: Guard should fail
        let initial_context_guard_fails = TestContext { val: 5 }; // val is 5, so guard (val < 5) is false
        let initial_event_for_test = TestEvent::E0; // Example
        let mut runtime_guard_fails =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context_guard_fails,
                &initial_event_for_test,
            );
        assert_eq!(
            runtime_guard_fails.send(&TestEvent::E0),
            SendResult::NoMatch
        ); // Guard should fail, expect NoMatch
        assert_eq!(runtime_guard_fails.state().as_slice(), &[TestState::S0]);
        assert_eq!(runtime_guard_fails.context().val, 5); // Action should not run

        // Test case 2: Guard should pass
        let initial_context_guard_passes = TestContext { val: 4 }; // val is 4, so guard (val < 5) is true
        let mut runtime_guard_passes =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context_guard_passes,
                &initial_event_for_test,
            );
        assert_eq!(
            runtime_guard_passes.send(&TestEvent::E0),
            SendResult::Transitioned
        ); // Guard should pass, expect Transitioned
        assert_eq!(runtime_guard_passes.state().as_slice(), &[TestState::S1]);
        assert_eq!(runtime_guard_passes.context().val, 5); // Action should run
    }

    #[test]
    fn context_mut_provides_mutable_access() {
        const NO_TRANSITIONS: &[Transition<TestState, TestEvent, TestContext>] = &[];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContext> =
            MachineDefinition::new(
                TEST_STATENODES_COUNTER_CTX_POPULATED,
                NO_TRANSITIONS,
                TestState::S0,
            );

        let initial_context = TestContext { val: 42 };
        let initial_event_for_test = TestEvent::E0; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );

        runtime.context_mut().val += 1;
        assert_eq!(runtime.context().val, 43);
    }

    #[test]
    fn no_transition_if_event_does_not_match() {
        const TEST_TRANSITIONS: &[Transition<TestState, TestEvent, TestContextForEmpty>] =
            &[Transition {
                from_state: TestState::S0,
                to_state: TestState::S1,
                action: None,
                guard: None,
                match_fn: Some(matches_test_event_e0),
            }];
        const TEST_MACHINE_DEF: MachineDefinition<TestState, TestEvent, TestContextForEmpty> =
            MachineDefinition::new(
                TEST_STATENODES_EMPTY_CTX_POPULATED,
                TEST_TRANSITIONS,
                TestState::S0,
            );
        let initial_event_for_test = TestEvent::E1; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF,
                DefaultContext::default(),
                &initial_event_for_test,
            );
        assert_eq!(runtime.send(&TestEvent::E1), SendResult::NoMatch); // Different event
        assert_eq!(runtime.state().as_slice(), &[TestState::S0]);
    }

    #[test]
    fn no_transition_if_state_does_not_match() {
        const TEST_TRANSITIONS_ST_MATCH: &[Transition<
            TestState,
            TestEvent,
            TestContextForEmpty,
        >] = &[Transition {
            from_state: TestState::S0,
            to_state: TestState::S1,
            action: None,
            guard: None,
            match_fn: Some(matches_test_event_e0),
        }];
        // This MachineDefinition is a const, so a reference to it is &'static
        const TEST_MACHINE_DEF_ST_MATCH: MachineDefinition<
            TestState,
            TestEvent,
            TestContextForEmpty,
        > = MachineDefinition::new(
            TEST_STATENODES_EMPTY_CTX_POPULATED,
            TEST_TRANSITIONS_ST_MATCH, // Use the locally defined const name
            TestState::S1,
        );
        let initial_event_for_test = TestEvent::E0; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &TEST_MACHINE_DEF_ST_MATCH, // Pass by reference
                DefaultContext::default(),
                &initial_event_for_test,
            );
        assert_eq!(runtime.send(&TestEvent::E0), SendResult::NoMatch);
        assert_eq!(runtime.state().as_slice(), &[TestState::S1]);
    }

    #[test]
    fn test_child_to_parent_transition() {
        static CHILD_TO_PARENT_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            HIERARCHY_TEST_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );

        let initial_event_for_test = TestHierarchyEvent::EventTriggerToParent; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &CHILD_TO_PARENT_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&TestHierarchyEvent::EventTriggerToParent);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventTriggerToParent should have been processed"
        );

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_parent_to_child_transition() {
        #[cfg(feature = "std")]
        {
            println!(">>> test_parent_to_child_transition started");
            io::stdout().flush().unwrap();
        }

        let initial_event_for_test = TestHierarchyEvent::EventTriggerP1ToC1B;
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARENT_TO_CHILD_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );

        // Optional: Assert initial state
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        runtime.context_mut().log.clear();
        let event_processed = runtime.send(&TestHierarchyEvent::EventTriggerP1ToC1B);
        assert_eq!(event_processed, SendResult::Transitioned);
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildOneBravo]
        );
    }

    #[test]
    fn test_grandchild_to_grandparent_reentry() {
        static GC_TO_GP_MACHINE_DEF: MachineDefinition<
            TestHierarchyState,
            TestHierarchyEvent,
            HierarchicalActionLogContext,
        > = MachineDefinition::new(
            TEST_HIERARCHY_STATENODES,
            HIERARCHY_TEST_TRANSITIONS,
            TestHierarchyState::ParentOne,
        );
        let initial_event_for_test = TestHierarchyEvent::EventTriggerToGrandparent; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &GC_TO_GP_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.send(&TestHierarchyEvent::EventTriggerToSibling);
        runtime.send(&TestHierarchyEvent::EventTriggerToCousinChild);
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(&TestHierarchyEvent::EventTriggerToGrandparent);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventTriggerToGrandparent should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaYankee").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterParentOne").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    #[test]
    fn test_cousin_child_transition() {
        #[cfg(feature = "std")]
        {
            println!("DEBUG PLUMBING TEST");
        }
        trace!("[TRACE] test_cousin_child_transition running");
        #[cfg(feature = "std")]
        {
            println!(">>> test_cousin_child_transition started");
            io::stdout().flush().unwrap();
        }

        let initial_event_for_test = TestHierarchyEvent::EventTriggerToCousinChild;
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &COUSIN_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );

        // Optional: Assert initial state
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );

        let sibling_result = runtime.send(&TestHierarchyEvent::EventTriggerToSibling);
        #[cfg(feature = "std")]
        {
            println!(">>> After sibling transition: {0:?}", runtime.state());
            println!(">>> sibling_result: {sibling_result:?}");
            std::io::stdout().flush().unwrap();
        }
        let _ = sibling_result; // Mark as used to avoid warning

        let cousin_result = runtime.send(&TestHierarchyEvent::EventTriggerToCousinChild);
        #[cfg(feature = "std")]
        {
            println!(">>> After cousin transition: {0:?}", runtime.state());
            println!(">>> cousin_result: {cousin_result:?}");
            std::io::stdout().flush().unwrap();
        }
        let _ = cousin_result; // Mark as used to avoid warning

        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaYankee]
        );
    }

    #[test]
    fn test_cross_top_level_parent_transition() {
        #[cfg(feature = "std")]
        {
            println!("DEBUG PLUMBING TEST");
        }
        trace!("[TRACE] test_cross_top_level_parent_transition running");

        let initial_event_for_test = TestHierarchyEvent::EventTriggerP1ToP2; // Example
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &CROSS_PARENT_MACHINE_DEF,
                HierarchicalActionLogContext::default(),
                &initial_event_for_test,
            );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::GrandchildOneAlphaXray]
        );
        runtime.context_mut().log.clear();
        let event_processed = runtime.send(&TestHierarchyEvent::EventTriggerP1ToP2);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventTriggerP1ToP2 should have been processed"
        );
        assert_eq!(
            runtime.state().as_slice(),
            &[TestHierarchyState::ChildTwoAlpha]
        );
        let mut expected_log: heapless::Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> =
            heapless::Vec::new();
        expected_log
            .push(heapless::String::try_from("ExitGrandchildOneAlphaXray").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitChildOneAlpha").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("ExitParentOne").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("TransitionAction").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterParentTwo").unwrap())
            .expect("Log full");
        expected_log
            .push(heapless::String::try_from("EnterChildTwoAlpha").unwrap())
            .expect("Log full");
        assert_eq!(runtime.context().get_log(), &expected_log);
    }

    // --- Tests for Multiple Guard Selection ---

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum MultiGuardTestState {
        InitialState,
        TargetStateOne,
        TargetStateTwo,
        TargetStateThree,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    enum MultiGuardTestEvent {
        TriggerEvent,
    }

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct MultiGuardContext {
        selector_value: i32,
        action_taken_for: Option<MultiGuardTestState>,
    }

    fn guard_for_target_one(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 1
    }
    fn action_for_target_one(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        // Added _event back
        context.action_taken_for = Some(MultiGuardTestState::TargetStateOne);
    }

    fn guard_for_target_two(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 2
    }
    fn action_for_target_two(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        // Added _event back
        context.action_taken_for = Some(MultiGuardTestState::TargetStateTwo);
    }

    fn guard_for_target_three(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 3
    }
    fn action_for_target_three(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        // Added _event back
        context.action_taken_for = Some(MultiGuardTestState::TargetStateThree);
    }

    const MULTI_GUARD_STATENODES: &[StateNode<
        MultiGuardTestState,
        MultiGuardContext,
        MultiGuardTestEvent,
    >] = &[
        StateNode {
            id: MultiGuardTestState::InitialState,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateOne,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateTwo,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: MultiGuardTestState::TargetStateThree,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    const MULTI_GUARD_TRANSITIONS: &[Transition<
        MultiGuardTestState,
        MultiGuardTestEvent,
        MultiGuardContext,
    >] = &[
        Transition {
            from_state: MultiGuardTestState::InitialState,
            to_state: MultiGuardTestState::TargetStateOne,
            action: Some(action_for_target_one),
            guard: Some(guard_for_target_one),
            match_fn: Some(matches_multi_guard_trigger_event),
        },
        Transition {
            from_state: MultiGuardTestState::InitialState,
            to_state: MultiGuardTestState::TargetStateTwo,
            action: Some(action_for_target_two),
            guard: Some(guard_for_target_two),
            match_fn: Some(matches_multi_guard_trigger_event),
        },
        Transition {
            from_state: MultiGuardTestState::InitialState,
            to_state: MultiGuardTestState::TargetStateThree,
            action: Some(action_for_target_three),
            guard: Some(guard_for_target_three),
            match_fn: Some(matches_multi_guard_trigger_event),
        },
    ];

    #[allow(clippy::too_many_lines)]
    #[test]
    fn test_multiple_guards_selects_correct_transition() {
        static MULTI_GUARD_MACHINE_DEF: MachineDefinition<
            MultiGuardTestState,
            MultiGuardTestEvent,
            MultiGuardContext,
        > = MachineDefinition::new(
            MULTI_GUARD_STATENODES,
            MULTI_GUARD_TRANSITIONS,
            MultiGuardTestState::InitialState,
        );

        let initial_event_for_test = MultiGuardTestEvent::TriggerEvent; // Example
        let mut runtime1 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 1,
                    action_taken_for: None,
                },
                &initial_event_for_test,
            );
        assert_eq!(
            runtime1.send(&MultiGuardTestEvent::TriggerEvent),
            SendResult::Transitioned
        );
        assert_eq!(
            runtime1.state().as_slice(),
            &[MultiGuardTestState::TargetStateOne]
        );
        assert_eq!(
            runtime1.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateOne)
        );

        let mut runtime2 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 2,
                    action_taken_for: None,
                },
                &initial_event_for_test,
            );
        assert_eq!(
            runtime2.send(&MultiGuardTestEvent::TriggerEvent),
            SendResult::Transitioned
        );
        assert_eq!(
            runtime2.state().as_slice(),
            &[MultiGuardTestState::TargetStateTwo]
        );
        assert_eq!(
            runtime2.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateTwo)
        );

        let mut runtime3 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 3,
                    action_taken_for: None,
                },
                &initial_event_for_test,
            );
        assert_eq!(
            runtime3.send(&MultiGuardTestEvent::TriggerEvent),
            SendResult::Transitioned
        );
        assert_eq!(
            runtime3.state().as_slice(),
            &[MultiGuardTestState::TargetStateThree]
        );
        assert_eq!(
            runtime3.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateThree)
        );

        let mut runtime4 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 4,
                    action_taken_for: None,
                },
                &initial_event_for_test,
            );
        assert_eq!(
            runtime4.send(&MultiGuardTestEvent::TriggerEvent),
            SendResult::NoMatch
        );
        assert_eq!(
            runtime4.state().as_slice(),
            &[MultiGuardTestState::InitialState]
        );
        assert_eq!(runtime4.context().action_taken_for, None);

        let mut runtime5 =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &MULTI_GUARD_MACHINE_DEF,
                MultiGuardContext {
                    selector_value: 1,
                    action_taken_for: None,
                },
                &initial_event_for_test,
            );
        assert_eq!(
            runtime5.send(&MultiGuardTestEvent::TriggerEvent),
            SendResult::Transitioned
        );
        assert_eq!(
            runtime5.state().as_slice(),
            &[MultiGuardTestState::TargetStateOne],
            "Expected TargetStateOne due to transition order"
        );
        assert_eq!(
            runtime5.context().action_taken_for,
            Some(MultiGuardTestState::TargetStateOne)
        );
    }

    // --- New Test Setup for Parallel State Transitions ---

    const PARALLEL_LOG_ENTRIES: usize = 32;
    const PARALLEL_LOG_STRING_LEN: usize = 64;

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct ParallelActionLogContext {
        log: heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>,
    }

    impl ParallelActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String in ParallelActionLogContext");
            self.log.push(s).unwrap_or_else(|_val| {
                panic!(
                    "ParallelActionLogContext log overflow (capacity {PARALLEL_LOG_ENTRIES}). Could not log: {action_description}"
                );
            });
        }
        // Helper to create expected log Vec more easily in tests
        #[allow(dead_code)] // May not be used by all tests initially
        fn expected_log(
            entries: &[&str],
        ) -> heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>
        {
            let mut v = heapless::Vec::new();
            for entry in entries {
                let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
                s.push_str(entry).unwrap();
                v.push(s).unwrap();
            }
            v
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash, PartialOrd, Ord)]
    enum ParallelTestState {
        P,
        R1,
        R1A,
        R1B,
        R2,
        R2X,
        R2Y,
        SOuter,
    }

    #[derive(Debug, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum ParallelTestEvent {
        E1,
        E2,
        EventR1ToR2,          // Was E_R1_To_R2
        EventRegion1Self,     // Was E_R1_Self
        EventRegion2Self,     // Was E_R2_Self
        EventParallelSelf,    // Was E_P_Self
        EventParallelToOuter, // Was E_P_To_SOuter
        EventOuterToParallel, // Was E_SOuter_To_P
        EventRegion1Only,     // Was E_R1_Only
    }

    // Action and Guard functions for parallel tests (renamed for clarity)
    fn pt_log_enter_parallel(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterP");
    }
    fn pt_log_exit_parallel(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitP");
    }
    fn pt_log_event_parallel_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("P_SelfAction");
    }

    fn pt_log_enter_region1(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterR1");
    }
    fn pt_log_exit_region1(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1");
    }
    fn pt_log_enter_region1_state_a(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR1A");
    }
    fn pt_log_exit_region1_state_a(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1A");
    }
    fn pt_log_region1_state_a_event_e1_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_E1_Action");
    }
    fn pt_log_region1_state_a_event_region1_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_SelfAction");
    }
    fn pt_log_enter_region1_state_b(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR1B");
    }
    fn pt_log_exit_region1_state_b(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1B");
    }
    fn pt_log_region1_state_b_event_e2_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1B_E2_Action");
    }
    fn pt_log_region1_state_a_event_region1_only_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_E_R1_Only_Action");
    }

    fn pt_log_enter_region2(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterR2");
    }
    fn pt_log_exit_region2(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2");
    }
    fn pt_log_enter_region2_state_x(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR2X");
    }
    fn pt_log_exit_region2_state_x(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2X");
    }
    fn pt_log_region2_state_x_event_e1_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2X_E1_Action");
    }
    fn pt_log_region2_state_x_event_region2_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2X_SelfAction");
    }
    fn pt_log_enter_region2_state_y(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR2Y");
    }
    fn pt_log_exit_region2_state_y(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2Y");
    }
    fn pt_log_region2_state_y_event_e2_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2Y_E2_Action");
    }

    fn pt_log_enter_state_outer(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterSOuter");
    }
    fn pt_log_exit_state_outer(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitSOuter");
    }
    fn pt_log_event_parallel_to_outer_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("P_E2_SOuter_Action");
    }
    fn pt_log_event_outer_to_parallel_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("SOuter_E1_P_Action");
    }

    const PARALLEL_TEST_STATENODES: &[StateNode<
        ParallelTestState,
        ParallelActionLogContext,
        ParallelTestEvent,
    >] = &[
        StateNode {
            id: ParallelTestState::P,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_parallel),
            exit_action: Some(pt_log_exit_parallel),
            is_parallel: true,
        },
        StateNode {
            id: ParallelTestState::R1,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R1A),
            entry_action: Some(pt_log_enter_region1),
            exit_action: Some(pt_log_exit_region1),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1A,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_a),
            exit_action: Some(pt_log_exit_region1_state_a),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1B,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_b),
            exit_action: Some(pt_log_exit_region1_state_b),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R2X),
            entry_action: Some(pt_log_enter_region2),
            exit_action: Some(pt_log_exit_region2),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2X,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_x),
            exit_action: Some(pt_log_exit_region2_state_x),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2Y,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_y),
            exit_action: Some(pt_log_exit_region2_state_y),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::SOuter,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_state_outer),
            exit_action: Some(pt_log_exit_state_outer),
            is_parallel: false,
        },
    ];

    const PARALLEL_TEST_TRANSITIONS: &[Transition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    >] = &[
        Transition {
            from_state: ParallelTestState::P,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_parallel_self_action),
            guard: None,
            match_fn: Some(matches_parallel_self),
        },
        Transition {
            from_state: ParallelTestState::P,
            to_state: ParallelTestState::SOuter,
            action: Some(pt_log_event_parallel_to_outer_action),
            guard: None,
            match_fn: Some(matches_parallel_to_outer),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_e1_action),
            guard: None,
            match_fn: Some(matches_parallel_e1),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_a_event_region1_self_action),
            guard: None,
            match_fn: Some(matches_parallel_region1_self),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_region1_only_action),
            guard: None,
            match_fn: Some(matches_region1_only),
        },
        Transition {
            from_state: ParallelTestState::R1B,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_b_event_e2_action),
            guard: None,
            match_fn: Some(matches_parallel_e2),
        },
        Transition {
            from_state: ParallelTestState::R2X,
            to_state: ParallelTestState::R2Y,
            action: Some(pt_log_region2_state_x_event_e1_action),
            guard: None,
            match_fn: Some(matches_parallel_e1),
        },
        Transition {
            from_state: ParallelTestState::R2X,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_x_event_region2_self_action),
            guard: None,
            match_fn: Some(matches_parallel_region2_self),
        },
        Transition {
            from_state: ParallelTestState::R2Y,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_y_event_e2_action),
            guard: None,
            match_fn: Some(matches_parallel_e2),
        },
        Transition {
            from_state: ParallelTestState::SOuter,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_outer_to_parallel_action),
            guard: None,
            match_fn: Some(matches_outer_to_parallel),
        },
    ];

    static PARALLEL_MACHINE_DEF: MachineDefinition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    > = MachineDefinition::new(
        PARALLEL_TEST_STATENODES,
        PARALLEL_TEST_TRANSITIONS,
        ParallelTestState::P,
    );

    // Helper function for checking subsequences in logs
    fn check_subsequence(
        log: &heapless::Vec<&str, PARALLEL_LOG_ENTRIES>,
        expected_sub: &[&str],
    ) -> bool {
        if expected_sub.is_empty() {
            return true;
        }
        let mut log_idx = 0;
        let mut sub_idx = 0;
        while log_idx < log.len() && sub_idx < expected_sub.len() {
            if log[log_idx] == expected_sub[sub_idx] {
                sub_idx += 1;
            }
            log_idx += 1;
        }
        sub_idx == expected_sub.len()
    }

    #[test]
    fn test_parallel_initial_activation_and_entry_order() {
        let initial_context = ParallelActionLogContext::default(); // unused_mut: removed mut
        let initial_event_for_test = ParallelTestEvent::E1; // Corrected to ParallelTestEvent
        let runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "EnterP", "EnterR1", "EnterR1A", "EnterR2", "EnterR2X",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Entry action log mismatch"
        );
    }

    #[test]
    fn test_parallel_independent_region_transitions() {
        let initial_context = ParallelActionLogContext::default();
        let initial_event_for_test = ParallelTestEvent::E1; // Corrected to ParallelTestEvent
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
                &initial_event_for_test,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::E1);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event E1 should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2Y).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let actual_log = runtime.context().log.clone();
        let actual_log_strs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect();

        let r1_actions_expected_slice = &["ExitR1A", "R1A_E1_Action", "EnterR1B"];
        let r2_actions_expected_slice = &["ExitR2X", "R2X_E1_Action", "EnterR2Y"];

        assert!(
            check_subsequence(&actual_log_strs, r1_actions_expected_slice),
            "R1 action block {r1_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );
        assert!(
            check_subsequence(&actual_log_strs, r2_actions_expected_slice),
            "R2 action block {r2_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );

        // The sum of lengths of individual blocks should be the total log length if no other actions occurred.
        assert_eq!(
            actual_log_strs.len(),
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            "Log has incorrect total number of entries. Expected {}, got {}. Log: {:?}",
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            actual_log_strs.len(),
            actual_log_strs
        );
    }

    #[test]
    fn test_parallel_transition_one_region_no_effect_on_other() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
                &ParallelTestEvent::EventRegion1Only,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::EventRegion1Only);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventRegion1Only should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "ExitR1A",
            "R1A_E_R1_Only_Action",
            "EnterR1B",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Only"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_region_leaf() {
        let initial_context = ParallelActionLogContext::default(); // Needs mut for clear()
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
                &ParallelTestEvent::EventRegion1Self,
            );
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::EventRegion1Self);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventRegion1Self should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log =
            ParallelActionLogContext::expected_log(&["ExitR1A", "R1A_SelfAction", "EnterR1A"]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Self"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_parallel_state_itself() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime =
            Runtime::<_, _, _, TEST_HIERARCHY_DEPTH_M, TEST_MAX_NODES_FOR_COMPUTATION>::new(
                &PARALLEL_MACHINE_DEF,
                initial_context,
                &ParallelTestEvent::EventParallelSelf,
            );
        runtime.context_mut().log.clear();

        let send_result = runtime.send(&ParallelTestEvent::EventParallelSelf);
        assert_eq!(
            send_result,
            SendResult::Transitioned,
            "Expected self-transition on parallel state to be processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch after parallel self-transition. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "ExitR1A",
            "ExitR1",
            "ExitR2X",
            "ExitR2",
            "ExitP",
            "P_SelfAction",
            "EnterP",
            "EnterR1",
            "EnterR1A",
            "EnterR2",
            "EnterR2X",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for parallel self-transition. Expected: {:?}, Got: {:?}",
            expected_log,
            runtime.context().log
        );
    }

    // Match function for MultiGuardTestEvent
    fn matches_multi_guard_trigger_event(event: &MultiGuardTestEvent) -> bool {
        matches!(event, MultiGuardTestEvent::TriggerEvent)
    }

    // Match functions for ParallelTestEvent
    fn matches_parallel_e1(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::E1)
    }

    fn matches_parallel_e2(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::E2)
    }

    fn matches_parallel_region1_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion1Self)
    }

    fn matches_parallel_region2_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion2Self)
    }

    fn matches_parallel_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventParallelSelf)
    }

    fn matches_parallel_to_outer(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventParallelToOuter)
    }

    fn matches_outer_to_parallel(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventOuterToParallel)
    }

    fn matches_region1_only(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion1Only)
    }
}
