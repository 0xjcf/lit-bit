// src/core/mod.rs
// This module will house core state machine logic and types.

#[macro_use]
mod tracing {
    #[macro_export]
    macro_rules! trace {
        ($($arg:tt)*) => {
            #[cfg(all(feature = "debug-log", feature = "std"))]
            {
                use std::io::{self, Write};
                println!($($arg)*);
                io::stdout().flush().unwrap();
            }
        };
    }
}

#[cfg(feature = "std")]
use std::io::{self, Write};

#[allow(unused_imports)]
use heapless::Vec;

// Re-export the StateMachine trait for easier use if core types implement it.
// Potentially, the macro-generated machine would be in a submodule of `core` or a user module.
pub use crate::StateMachine;

// --- Basic Type Placeholders (will be generic/generated by macro later) ---

// Using simple u8 for IDs as placeholders. Macro would generate enums.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateId(pub u8);

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EventId(pub u8);

// Placeholder for context data. Macro would use the user-defined struct.
#[derive(Debug, Clone, Default)]
pub struct DefaultContext {/* ... fields ... */}

// Define function pointer types for actions and guards
pub type ActionFn<ContextType, EventType> = fn(context: &mut ContextType, event: &EventType);
pub type GuardFn<ContextType, EventType> = fn(context: &ContextType, event: &EventType) -> bool;
pub type EntryExitActionFn<ContextType, EventType> =
    fn(context: &mut ContextType, event: &EventType);

// Add near ActionFn / GuardFn
type MatchFn<EventType> = fn(&EventType) -> bool;

// --- Flat State Machine Definition ---

/// Represents a simple transition for a flat state machine.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct Transition<StateType, EventType, ContextType> {
    pub from_state: StateType,
    pub to_state: StateType,
    pub action: Option<ActionFn<ContextType, EventType>>,
    pub guard: Option<GuardFn<ContextType, EventType>>,
    /// Pattern matching function that determines if an event matches this transition
    pub match_fn: Option<MatchFn<EventType>>,
}

/// Defines the structure of a simple, flat state machine.
/// This would be largely generated by the `statechart!` macro.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct StateNode<StateType, ContextType, EventType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    ContextType: Clone + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static,
{
    pub id: StateType, // The unique ID of this state (a variant of the generated StateId enum)
    pub parent: Option<StateType>, // ID of the parent state, if any
    pub initial_child: Option<StateType>, // ID of the initial child state, if this is a composite state
    pub entry_action: Option<EntryExitActionFn<ContextType, EventType>>,
    pub exit_action: Option<EntryExitActionFn<ContextType, EventType>>,
    pub is_parallel: bool, // New field
}

#[derive(Clone)]
pub struct MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static, // This will be the generated StateId enum
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy, kept Clone
    ContextType: Clone + 'static,
{
    pub states: &'static [StateNode<StateType, ContextType, EventType>],
    pub transitions: &'static [Transition<StateType, EventType, ContextType>],
    pub initial_leaf_state: StateType,
}

// Manual Debug impl to avoid requiring StateType, EventType, ContextType to be Debug for MachineDefinition itself to be Debug
impl<StateType, EventType, ContextType> core::fmt::Debug
    for MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + core::fmt::Debug + 'static,
{
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        f.debug_struct("MachineDefinition")
            .field("states", &self.states) // StateNode needs Debug for this to be useful
            .field("transitions", &self.transitions)
            .field("initial_leaf_state", &self.initial_leaf_state)
            .finish()
    }
}

impl<StateType, EventType, ContextType> MachineDefinition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    pub const fn new(
        states: &'static [StateNode<StateType, ContextType, EventType>],
        transitions: &'static [Transition<StateType, EventType, ContextType>],
        initial_leaf_state: StateType,
    ) -> Self {
        MachineDefinition {
            states,
            transitions,
            initial_leaf_state,
        }
    }

    // Helper to find a state node by its ID
    pub fn get_state_node(
        &self,
        state_id: StateType,
    ) -> Option<&'static StateNode<StateType, ContextType, EventType>> {
        self.states.iter().find(|s_node| s_node.id == state_id)
    }

    // Helper to get the parent of a state, if it exists
    pub fn get_parent_of(&self, state_id: StateType) -> Option<StateType> {
        self.get_state_node(state_id)
            .and_then(|s_node| s_node.parent)
    }
}

// --- Runtime Instance ---

// Placeholder for hierarchy depth, make configurable or detect via macro later.
// const MAX_HIERARCHY_DEPTH: usize = 8; // Will be replaced by const generic M
// Make MAX_ACTIVE_REGIONS public so it can be accessed by lib.rs
pub const MAX_ACTIVE_REGIONS: usize = 4; // Max parallel regions/active states we can track

/// Type alias for Runtime with default active regions capacity
pub type DefaultRuntime<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> = Runtime<StateType, EventType, ContextType, M, MAX_ACTIVE_REGIONS, MAX_NODES_FOR_COMPUTATION>;

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum ProcessingError {
    PathTooLong,        // Replaces PathTooLongError struct
    CapacityExceeded,   // For various vector overflows during processing
    ArbitrationFailure, // If arbitration logic fails unexpectedly
    EntryLogicFailure, // If entry logic (execute_entry_actions_from_lca or enter_state_recursive_logic) has issues
}

impl core::fmt::Display for ProcessingError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            ProcessingError::PathTooLong => write!(f, "Maximum hierarchy path depth exceeded."),
            ProcessingError::CapacityExceeded => {
                write!(f, "Internal capacity exceeded during event processing.")
            }
            ProcessingError::ArbitrationFailure => {
                write!(f, "State transition arbitration failed.")
            }
            ProcessingError::EntryLogicFailure => {
                write!(f, "State entry logic failed after transition.")
            }
        }
    }
}

#[cfg(feature = "std")]
impl std::error::Error for ProcessingError {}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum EntryErrorKind {
    CycleDetected,
    CapacityExceeded, // For visited_during_entry vector
    StateNotFound,
    // AccumulatorFull, // If we decide to make accumulator push return an error
}

impl core::fmt::Display for EntryErrorKind {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            EntryErrorKind::CycleDetected => write!(f, "State entry cycle detected."),
            EntryErrorKind::CapacityExceeded => write!(
                f,
                "Capacity exceeded during state entry (e.g., visited path too long)."
            ),
            EntryErrorKind::StateNotFound => write!(f, "State not found during entry process."),
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct EntryError {
    pub kind: EntryErrorKind,
    // pub state_id: Option<StateType> // Could add this later if specific state context is needed for errors
}

impl core::fmt::Display for EntryError {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        write!(f, "Entry Error: {}", self.kind)
    }
}

#[cfg(feature = "std")]
impl std::error::Error for EntryError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        None // No underlying source error for these simple error types
    }
}

/// Result type for the `send_internal` method.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum SendResult {
    /// A transition was successfully processed.
    Transitioned,
    /// No matching transition was found for the event.
    NoMatch,
    /// An error occurred during event processing.
    Error(ProcessingError),
}

/// Runtime instance of a state machine.
///
/// Generic Parameters:
/// - `StateType`: The type representing state IDs (usually an enum).
/// - `EventType`: The type representing event IDs (usually an enum).
/// - `ContextType`: The user-defined context struct.
/// - `M`: Const generic for maximum hierarchy depth of a single state path.
/// - `N_ACTIVE`: Const generic for maximum number of active parallel regions/states.
/// - `MAX_NODES_FOR_COMPUTATION`: Const generic for buffer sizes needed for computations involving
///   multiple hierarchy branches, typically `M * N_ACTIVE`. This is used for temporary
///   collections during transition processing (e.g. exit sets).
#[derive(Debug)]
pub struct Runtime<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const N_ACTIVE: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
    pub active_leaf_states: heapless::Vec<StateType, N_ACTIVE>,
    context: ContextType,
}

// --- ⛳ 1. Helper scratch struct (place just after Runtime<T> definition) ---------
struct Scratch<'a, StateType, const M: usize>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + 'static,
{
    /// Tracks which states *already* had their entry action executed during the
    /// current `send_internal` cycle.  This is cleared at the end of the call.
    entry_actions_run: &'a mut heapless::Vec<StateType, M>,
}

// Helper function, can be outside impl Runtime or a static method if preferred.
// Making it a free function for now to ensure no `self` issues initially.
fn enter_state_recursive_logic<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const N_ACTIVE: usize,
>(
    machine_def: &MachineDefinition<StateType, EventType, ContextType>,
    context: &mut ContextType,
    state_id_to_enter: StateType,
    accumulator: &mut heapless::Vec<StateType, N_ACTIVE>,
    visited_during_entry: &mut heapless::Vec<StateType, M>,
    scratch: &mut Scratch<'_, StateType, M>, // ← NEW
    event: &EventType,
) -> Result<(), EntryError>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    if visited_during_entry.contains(&state_id_to_enter) {
        return Ok(());
    }
    if visited_during_entry.push(state_id_to_enter).is_err() {
        debug_assert!(
            false,
            "Visited entry path too long for state: {state_id_to_enter:?}"
        );
        return Err(EntryError {
            kind: EntryErrorKind::CapacityExceeded,
        });
    }
    let result: Result<(), EntryError> = (|| {
        let Some(node) = machine_def.get_state_node(state_id_to_enter) else {
            assert!(
                !cfg!(debug_assertions),
                "State ID ({state_id_to_enter:?}) not found in MachineDefinition."
            );
            return Err(EntryError {
                kind: EntryErrorKind::StateNotFound,
            });
        };
        // --- ENTRY ACTION (dedup) ---
        if !scratch.entry_actions_run.contains(&state_id_to_enter) {
            if let Some(entry_fn) = node.entry_action {
                entry_fn(context, event);
            }
            scratch
                .entry_actions_run
                .push(state_id_to_enter)
                .map_err(|_| EntryError {
                    kind: EntryErrorKind::CapacityExceeded,
                })?;
        }
        if node.is_parallel {
            for s_node_in_def in machine_def.states {
                if s_node_in_def.parent == Some(state_id_to_enter) {
                    #[allow(clippy::collapsible_if)]
                    if let Some(region_entry_fn) = s_node_in_def.entry_action {
                        if !scratch.entry_actions_run.contains(&s_node_in_def.id) {
                            region_entry_fn(context, event);
                            scratch
                                .entry_actions_run
                                .push(s_node_in_def.id)
                                .map_err(|_| EntryError {
                                    kind: EntryErrorKind::CapacityExceeded,
                                })?;
                        }
                    }
                    let initial_child_of_region = s_node_in_def.initial_child.ok_or_else(|| {
                        debug_assert!(
                            false,
                            "Parallel region {:?} is missing an initial child.",
                            s_node_in_def.id
                        );
                        EntryError {
                            kind: EntryErrorKind::StateNotFound,
                        }
                    })?;
                    enter_state_recursive_logic::<_, _, _, M, N_ACTIVE>(
                        machine_def,
                        context,
                        initial_child_of_region,
                        accumulator,
                        visited_during_entry,
                        scratch,
                        event,
                    )?;
                }
            }
        } else if let Some(initial_child_id) = node.initial_child {
            enter_state_recursive_logic::<_, _, _, M, N_ACTIVE>(
                machine_def,
                context,
                initial_child_id,
                accumulator,
                visited_during_entry,
                scratch,
                event,
            )?;
        } else if !accumulator.contains(&state_id_to_enter)
            && accumulator.push(state_id_to_enter).is_err()
        {
            return Err(EntryError {
                kind: EntryErrorKind::CapacityExceeded,
            });
        }

        Ok(())
    })();
    let _ = visited_during_entry.pop();
    result
}

// Define PotentialTransition struct at the module level
#[derive(Debug, Clone, Copy)]
pub(crate) struct PotentialTransition<StateType, EventType, ContextType>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    source_leaf_id: StateType,
    #[allow(dead_code)] // Will be used in full send() logic for arbitration
    transition_from_state_id: StateType,
    target_state_id: StateType,
    transition_ref: &'static Transition<StateType, EventType, ContextType>,
}

impl<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const N_ACTIVE: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> Runtime<StateType, EventType, ContextType, M, N_ACTIVE, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    // Removed old fn enter_state_recursive(&mut self, ...) here

    /// Creates a new runtime instance for the given machine definition and initial context.
    ///
    /// # Errors
    ///
    /// This function returns an error under the following conditions:
    /// - If the `initial_leaf_state` specified in the `MachineDefinition` is not found in the `STATES` array.
    /// - If `MAX_ACTIVE_REGIONS` is exceeded while trying to push initial leaf states (e.g. for a parallel initial state).
    /// - If `M` (max hierarchy depth) is exceeded during internal path calculations.
    /// - If entry logic fails due to cycles, state not found, or capacity exceeded.
    pub fn new(
        machine_def: &'static MachineDefinition<StateType, EventType, ContextType>,
        initial_context: ContextType,
        initial_event: &EventType,
    ) -> Result<Self, ProcessingError> {
        let mut mutable_context = initial_context;
        let mut active_states_vec = heapless::Vec::new();
        let mut visited_for_initial_entry: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut entry_actions_run_vec: heapless::Vec<StateType, M> = heapless::Vec::new();

        let top_level_initial_state_id = machine_def.initial_leaf_state;

        // Pass M explicitly if needed, or let it be inferred from the type of visited_for_initial_entry
        enter_state_recursive_logic::<_, _, _, M, N_ACTIVE>(
            machine_def,
            &mut mutable_context,
            top_level_initial_state_id,
            &mut active_states_vec,
            &mut visited_for_initial_entry,
            &mut Scratch::<StateType, M> {
                entry_actions_run: &mut entry_actions_run_vec,
            },
            initial_event,
        )
        .map_err(|entry_error| match entry_error.kind {
            EntryErrorKind::CycleDetected | EntryErrorKind::StateNotFound => {
                ProcessingError::EntryLogicFailure
            }
            EntryErrorKind::CapacityExceeded => ProcessingError::CapacityExceeded,
        })?;

        if active_states_vec.is_empty() {
            return Err(ProcessingError::EntryLogicFailure);
        }

        Ok(Runtime {
            machine_def, // Assign the reference
            active_leaf_states: active_states_vec,
            context: mutable_context,
        })
    }

    pub fn state(&self) -> heapless::Vec<StateType, N_ACTIVE> {
        self.active_leaf_states.clone()
    }
    pub fn context(&self) -> &ContextType {
        &self.context
    }
    pub fn context_mut(&mut self) -> &mut ContextType {
        &mut self.context
    }

    // --- Helper methods for hierarchical transitions ---

    /// Collects the path from a leaf state up to the root, including the leaf itself.
    /// The path is filled in the provided buffer with the leaf state at index 0 and ancestors following.
    /// The buffer is cleared before filling.
    fn fill_path_to_root(
        &self,
        leaf_state_id: StateType,
        path_buffer: &mut heapless::Vec<StateType, M>,
    ) -> Result<(), ProcessingError> {
        path_buffer.clear();
        let mut current_id = Some(leaf_state_id);
        while let Some(id) = current_id {
            if path_buffer.push(id).is_err() {
                return Err(ProcessingError::PathTooLong);
            }
            current_id = self.machine_def.get_parent_of(id);
        }
        Ok(())
    }

    /// Finds the Least Common Ancestor (LCA) of two states.
    fn find_lca(
        &self,
        state1_id: StateType,
        state2_id: StateType,
    ) -> Result<Option<StateType>, ProcessingError> {
        // Changed error type
        if state1_id == state2_id {
            return Ok(Some(state1_id));
        }

        let mut path1: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut path2: heapless::Vec<StateType, M> = heapless::Vec::new();

        self.fill_path_to_root(state1_id, &mut path1)?; // Path from state1 up to root
        self.fill_path_to_root(state2_id, &mut path2)?; // Path from state2 up to root

        // Iterate through path1 (from state1 towards root).
        // The first element of path1 also found in path2 is the LCA.
        for &id1_ancestor in &path1 {
            if path2.contains(&id1_ancestor) {
                return Ok(Some(id1_ancestor));
            }
        }

        Ok(None) // Should not happen if both states are in the same tree (i.e. have a common root)
        // but as a fallback if they somehow aren't (e.g. disconnected components, though our model assumes one tree).
    }

    fn is_proper_ancestor(
        &self,
        ancestor_candidate_id: StateType,
        descendant_candidate_id: StateType,
    ) -> Result<bool, ProcessingError> {
        // Changed error type
        // Changed return type
        if ancestor_candidate_id == descendant_candidate_id {
            return Ok(false);
        }
        let mut path_from_descendant: heapless::Vec<StateType, M> = heapless::Vec::new();
        self.fill_path_to_root(descendant_candidate_id, &mut path_from_descendant)?;
        Ok(path_from_descendant
            .iter()
            .skip(1)
            .any(|&p_state| p_state == ancestor_candidate_id))
    }

    // Helper to find the direct child of parent_id that is currently active or an ancestor of an active leaf.
    fn get_active_child_of(
        &self,
        parent_id: StateType,
    ) -> Result<Option<StateType>, ProcessingError> {
        let mut path_buffer: heapless::Vec<StateType, M> = heapless::Vec::new();
        for &leaf_id in &self.active_leaf_states {
            if leaf_id == parent_id {
                continue;
            }
            self.fill_path_to_root(leaf_id, &mut path_buffer)?;
            for i in 1..path_buffer.len() {
                if path_buffer[i] == parent_id {
                    return Ok(Some(path_buffer[i - 1]));
                }
            }
        }
        Ok(None)
    }

    // Helper to compute the ordered list of states to exit.
    fn compute_ordered_exit_set(
        &self,
        leaf_state_id_being_exited: StateType,
        lca_id: Option<StateType>,
    ) -> Result<heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>, ProcessingError> {
        // Changed error type
        // Return type uses new name

        let mut states_to_potentially_exit: heapless::Vec<StateType, M> = heapless::Vec::new();
        let mut collected_for_exit: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();

        // 1. Collect all states on the direct path from the active leaf up to (but not including) the LCA.
        let mut current_id_on_path = Some(leaf_state_id_being_exited);
        while let Some(id) = current_id_on_path {
            if lca_id == Some(id) {
                break;
            }
            // Check capacity before pushing to states_to_potentially_exit
            if states_to_potentially_exit.push(id).is_err() {
                // This implies M is too small for the hierarchy depth of this branch.
                return Err(ProcessingError::PathTooLong);
            }
            current_id_on_path = self.machine_def.get_parent_of(id);
        }
        // states_to_potentially_exit is now [leaf, p1, p2, ..., child_of_lca]

        // 2. For each state collected, recursively add its active children (for composite/parallel) first, then itself, to ensure post-order.
        //    Use a helper that ensures each state is added to `collected_for_exit` only once.
        let mut already_added_to_final_list: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut recursion_guard_vec: heapless::Vec<StateType, M> = heapless::Vec::new(); // Declare vec for recursion guard

        for &state_to_process_for_exit in states_to_potentially_exit.iter().rev() {
            // Process from child_of_lca down to leaf
            self.collect_states_for_exit_post_order(
                state_to_process_for_exit,
                lca_id,
                &mut collected_for_exit,
                &mut already_added_to_final_list,
                &mut recursion_guard_vec, // Pass the new guard
            )?; // Propagate error
        }
        Ok(collected_for_exit)
    }

    // Recursive helper for compute_ordered_exit_set
    fn collect_states_for_exit_post_order(
        &self,
        current_state_id: StateType,
        lca_id: Option<StateType>,
        ordered_exit_list: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        already_added: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        recursion_guard: &mut heapless::Vec<StateType, M>, // M should be sufficient for path depth
    ) -> Result<(), ProcessingError> {
        // Changed error type
        // Changed return type
        if Some(current_state_id) == lca_id || already_added.contains(&current_state_id) {
            return Ok(()); // Changed
        }

        let is_cycle_in_exit = recursion_guard.contains(&current_state_id);
        debug_assert!(
            !is_cycle_in_exit,
            "Cycle detected during collect_states_for_exit_post_order for state: {current_state_id:?}"
        );
        if is_cycle_in_exit {
            return Ok(()); // Changed
        }

        if recursion_guard.push(current_state_id).is_err() {
            // Check push failure
            debug_assert!(
                false, // This assertion will now always fail if the push fails.
                "Recursion depth exceeded in collect_states_for_exit_post_order (capacity {}) for state: {current_state_id:?}",
                recursion_guard.capacity()
            );
            return Err(ProcessingError::PathTooLong); // Return error
        }

        let Some(current_node) = self.machine_def.get_state_node(current_state_id) else {
            let _ = recursion_guard.pop(); // Pop before returning if node not found
            return Ok(()); // Changed
        };

        // Mark as visited for *this specific traversal context* to avoid issues if it's an ancestor of another part of main path.
        // The main `already_added` list prevents adding to `ordered_exit_list` multiple times.

        if current_node.is_parallel {
            for region_node in self
                .machine_def
                .states
                .iter()
                .filter(|n| n.parent == Some(current_state_id))
            {
                // Check if region is active (has a descendant in active_leaf_states)
                let mut region_active_leaf: Option<StateType> = None;
                for &leaf in &self.active_leaf_states {
                    match self.is_descendant_or_self(leaf, region_node.id) {
                        // Handle Result
                        Ok(is_desc) => {
                            if is_desc {
                                region_active_leaf = Some(leaf);
                                break;
                            }
                        }
                        Err(e) => return Err(e), // Propagate ProcessingError
                    }
                }
                if let Some(active_leaf_in_region) = region_active_leaf {
                    // Recurse from the active leaf of the region, stopping at the region itself (as region will be added later)
                    self.collect_states_for_exit_post_order(
                        active_leaf_in_region,
                        Some(region_node.id),
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
                // After region's children, add region itself (if not already added)
                if !already_added.contains(&region_node.id) {
                    self.collect_states_for_exit_post_order(
                        region_node.id,
                        lca_id,
                        ordered_exit_list,
                        already_added,
                        recursion_guard,
                    )?; // Propagate error
                }
            }
        } else if current_node.initial_child.is_some() {
            // Composite non-parallel
            if let Some(active_direct_child) = self.get_active_child_of(current_state_id)? {
                // This might need to handle Error
                self.collect_states_for_exit_post_order(
                    active_direct_child,
                    lca_id,
                    ordered_exit_list,
                    already_added,
                    recursion_guard,
                )?; // Propagate error
            }
        }

        // Add current_state_id to the list *after* its children have been processed and added.
        if !already_added.contains(&current_state_id) {
            // Ensure it's added only once. If these critical lists overflow, it's a fatal error.
            if ordered_exit_list.push(current_state_id).is_err() {
                let _ = recursion_guard.pop(); // Ensure guard is popped before panic or error return
                return Err(ProcessingError::CapacityExceeded);
            }
            if already_added.push(current_state_id).is_err() {
                let _ = recursion_guard.pop();
                return Err(ProcessingError::CapacityExceeded);
            }
        }
        let _ = recursion_guard.pop(); // Pop after processing this node and its children
        Ok(()) // Changed
    }

    // is_descendant_or_self method from before
    fn is_descendant_or_self(
        &self,
        candidate_id: StateType,
        ancestor_id: StateType,
    ) -> Result<bool, ProcessingError> {
        // Changed error type
        // Changed return type
        if candidate_id == ancestor_id {
            return Ok(true);
        }
        self.is_proper_ancestor(ancestor_id, candidate_id) // Propagate error
    }

    /// Returns the region root for a given state (the nearest ancestor whose parent is a parallel state), or None if not found.
    #[allow(dead_code)]
    fn get_region_root(&self, state_id: StateType) -> Option<StateType> {
        let mut current = state_id;
        while let Some(parent) = self.machine_def.get_parent_of(current) {
            #[allow(clippy::collapsible_if)]
            if let Some(parent_node) = self.machine_def.get_state_node(parent) {
                if parent_node.is_parallel {
                    return Some(current);
                }
            }
            current = parent;
        }
        None
    }

    /// Collects potential transitions for the given event from all active leaf states
    #[allow(dead_code)]
    fn collect_potential_transitions(
        &self,
        event: &EventType,
        current_active_leaves_snapshot: &heapless::Vec<StateType, N_ACTIVE>,
    ) -> Result<
        heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        >,
        ProcessingError,
    > {
        let mut potential_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();

        for &active_leaf_id in current_active_leaves_snapshot {
            let mut check_state_id_opt = Some(active_leaf_id);
            'hierarchy_search: while let Some(check_state_id) = check_state_id_opt {
                if self.machine_def.get_state_node(check_state_id).is_some() {
                    for t_def in self.machine_def.transitions {
                        if t_def.from_state == check_state_id {
                            // Check if event matches using match_fn if available
                            #[allow(clippy::collapsible_if)]
                            if let Some(match_fn) = t_def.match_fn {
                                if !match_fn(event) {
                                    continue; // Skip this transition if event doesn't match
                                }
                            }
                            // Now check the guard if any
                            #[allow(clippy::collapsible_if)]
                            if let Some(guard_fn) = t_def.guard {
                                if !guard_fn(&self.context, event) {
                                    trace!(
                                        "[GUARD FAILED] From {:?} on {:?} → {:?}",
                                        t_def.from_state, event, t_def.to_state
                                    );
                                    continue;
                                }
                            }
                            trace!(
                                "[MATCH] From {:?} on {:?} → {:?}",
                                t_def.from_state, event, t_def.to_state
                            );
                            let pot_trans = PotentialTransition {
                                source_leaf_id: active_leaf_id,
                                transition_from_state_id: check_state_id,
                                target_state_id: t_def.to_state,
                                transition_ref: t_def,
                            };
                            if potential_transitions.push(pot_trans).is_err() {
                                return Err(ProcessingError::CapacityExceeded);
                            }
                            break 'hierarchy_search;
                        }
                    }
                }
                check_state_id_opt = self.machine_def.get_parent_of(check_state_id);
            }
        }

        Ok(potential_transitions)
    }

    /// Processes a simple leaf self-transition (exit, action, entry list update).
    pub(crate) fn process_simple_leaf_self_transition(
        &self,
        trans_info: &PotentialTransition<StateType, EventType, ContextType>,
        event: &EventType,
        states_exited_this_step: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        entry_execution_list: &mut heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        >,
        temp_context: &mut ContextType,
    ) -> Result<(), ProcessingError> {
        let source_state_id = trans_info.transition_from_state_id;
        let active_leaf_for_this_trans = trans_info.source_leaf_id;

        #[allow(clippy::collapsible_if)]
        if let Some(node) = self.machine_def.get_state_node(source_state_id) {
            if !states_exited_this_step.contains(&source_state_id) {
                if let Some(exit_fn) = node.exit_action {
                    trace!("[EXIT] {:?} (exit_fn = true)", source_state_id);
                    exit_fn(temp_context, event);
                } else {
                    trace!("[EXIT] {:?} (exit_fn = false)", source_state_id);
                }
                if states_exited_this_step.push(source_state_id).is_err() {
                    return Err(ProcessingError::CapacityExceeded);
                }
            }
        }
        if let Some(action_fn) = trans_info.transition_ref.action {
            trace!(
                "[ACTION] Running action for {:?} → {:?} on {:?}",
                source_state_id, trans_info.target_state_id, event
            );
            action_fn(temp_context, event);
        }
        if entry_execution_list
            .push((
                source_state_id,
                Some(source_state_id),
                active_leaf_for_this_trans,
            ))
            .is_err()
        {
            return Err(ProcessingError::CapacityExceeded);
        }
        Ok(())
    }

    /// Processes a self-transition (not simple leaf - handles hierarchical exits/re-entry).
    pub(crate) fn process_self_transition(
        &self,
        trans_info: &PotentialTransition<StateType, EventType, ContextType>,
        current_active_leaves_snapshot: &heapless::Vec<StateType, N_ACTIVE>,
        event: &EventType,
        states_exited_this_step: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        entry_execution_list: &mut heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        >,
        temp_context: &mut ContextType,
    ) -> Result<(), ProcessingError> {
        let source_state_id = trans_info.transition_from_state_id;
        let active_leaf_for_this_trans = trans_info.source_leaf_id;

        let node_being_self_transitioned =
            self.machine_def.get_state_node(source_state_id).unwrap();
        let parent_of_source = node_being_self_transitioned.parent;

        for &current_active_leaf in current_active_leaves_snapshot {
            // Use original snapshot for active leaves
            if self
                .is_descendant_or_self(current_active_leaf, source_state_id)
                .unwrap_or(false)
            {
                let states_to_exit_for_this_leaf_branch =
                    self.compute_ordered_exit_set(current_active_leaf, parent_of_source)?;
                for &state_to_exit_id in &states_to_exit_for_this_leaf_branch {
                    if !states_exited_this_step.contains(&state_to_exit_id) {
                        if let Some(node) = self.machine_def.get_state_node(state_to_exit_id) {
                            if let Some(exit_fn) = node.exit_action {
                                trace!("[EXIT] {:?} (exit_fn = true)", state_to_exit_id);
                                exit_fn(temp_context, event);
                            } else {
                                trace!("[EXIT] {:?} (exit_fn = false)", state_to_exit_id);
                            }
                        }
                        if states_exited_this_step.push(state_to_exit_id).is_err() {
                            return Err(ProcessingError::CapacityExceeded);
                        }
                    }
                }
            }
        }
        if let Some(action_fn) = trans_info.transition_ref.action {
            trace!(
                "[ACTION] Running action for {:?} → {:?} on {:?}",
                source_state_id, trans_info.target_state_id, event
            );
            action_fn(temp_context, event);
        }
        if entry_execution_list
            .push((
                source_state_id,
                Some(source_state_id),
                active_leaf_for_this_trans,
            ))
            .is_err()
        {
            return Err(ProcessingError::CapacityExceeded);
        }
        Ok(())
    }

    /// Processes a regular transition (different source and target states).
    pub(crate) fn process_regular_transition(
        &self,
        trans_info: &PotentialTransition<StateType, EventType, ContextType>,
        event: &EventType,
        states_exited_this_step: &mut heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        entry_execution_list: &mut heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        >,
        temp_context: &mut ContextType,
    ) -> Result<(), ProcessingError> {
        let source_state_id = trans_info.transition_from_state_id;
        let target_state_id = trans_info.target_state_id;
        let active_leaf_for_this_trans = trans_info.source_leaf_id;

        let lca_id = self.find_lca(active_leaf_for_this_trans, target_state_id)?;
        let states_to_exit_for_branch =
            self.compute_ordered_exit_set(active_leaf_for_this_trans, lca_id)?;

        for &state_to_exit_id in &states_to_exit_for_branch {
            if !states_exited_this_step.contains(&state_to_exit_id) {
                if let Some(node) = self.machine_def.get_state_node(state_to_exit_id) {
                    if let Some(exit_fn) = node.exit_action {
                        trace!("[EXIT] {:?} (exit_fn = true)", state_to_exit_id);
                        exit_fn(temp_context, event);
                    } else {
                        trace!("[EXIT] {:?} (exit_fn = false)", state_to_exit_id);
                    }
                }
                if states_exited_this_step.push(state_to_exit_id).is_err() {
                    return Err(ProcessingError::CapacityExceeded);
                }
            }
        }

        if source_state_id == target_state_id && !states_exited_this_step.contains(&source_state_id)
        {
            if let Some(node) = self.machine_def.get_state_node(source_state_id) {
                if let Some(exit_fn) = node.exit_action {
                    trace!("[EXIT] {:?} (exit_fn = true)", source_state_id);
                    exit_fn(temp_context, event);
                } else {
                    trace!("[EXIT] {:?} (exit_fn = false)", source_state_id);
                }
            }
            if states_exited_this_step.push(source_state_id).is_err() {
                return Err(ProcessingError::CapacityExceeded);
            }
        }

        if let Some(action_fn) = trans_info.transition_ref.action {
            trace!(
                "[ACTION] Running action for {:?} → {:?} on {:?}",
                source_state_id, target_state_id, event
            );
            action_fn(temp_context, event);
        }

        let lca_for_entry = lca_id; // always use real LCA so ancestors stay suppressed
        if entry_execution_list
            .push((target_state_id, lca_for_entry, active_leaf_for_this_trans))
            .is_err()
        {
            return Err(ProcessingError::CapacityExceeded);
        }
        Ok(())
    }

    /// Applies transition processing: exits, actions, and prepares entry execution list.
    ///
    /// Returns (`overall_transition_occurred`, `states_exited_this_step`, `entry_execution_list`, `temp_context`)
    #[allow(clippy::type_complexity)]
    pub(crate) fn apply_transitions(
        &self,
        final_transitions_to_execute: &[PotentialTransition<StateType, EventType, ContextType>],
        current_active_leaves_snapshot: &heapless::Vec<StateType, N_ACTIVE>,
        event: &EventType,
        mut temp_context: ContextType,
    ) -> Result<
        (
            bool,                                                // overall_transition_occurred
            heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>, // states_exited_this_step
            heapless::Vec<(StateType, Option<StateType>, StateType), MAX_ACTIVE_REGIONS>, // entry_execution_list
            ContextType, // updated temp_context
        ),
        ProcessingError,
    > {
        let mut overall_transition_occurred = false;
        let mut states_exited_this_step: heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION> =
            heapless::Vec::new();
        let mut entry_execution_list: heapless::Vec<
            (StateType, Option<StateType>, StateType),
            MAX_ACTIVE_REGIONS,
        > = heapless::Vec::new();

        // Phase 1: Process exits and actions for all transitions first (use temp_context)
        for trans_info in final_transitions_to_execute {
            let source_state_id = trans_info.transition_from_state_id;
            let target_state_id = trans_info.target_state_id;
            let active_leaf_for_this_trans = trans_info.source_leaf_id;
            overall_transition_occurred = true;

            trace!(
                "[TRANSITION] {:?} → {:?} via {:?}",
                source_state_id, target_state_id, event
            );

            #[cfg(feature = "std")]
            {
                println!(
                    "[TRACE] Active before: {prev:?}",
                    prev = self.active_leaf_states
                );
                io::stdout().flush().unwrap();
                println!(
                    "[TRACE] Processing transition: {source_state_id:?} → {target_state_id:?}"
                );
            }

            // Determine transition type and delegate to appropriate helper
            let is_desc_result =
                self.is_descendant_or_self(active_leaf_for_this_trans, source_state_id);
            let is_simple_leaf_self_transition = source_state_id == target_state_id
                && is_desc_result?
                && self
                    .machine_def
                    .get_state_node(source_state_id)
                    .is_some_and(|n| !n.is_parallel && n.initial_child.is_none());

            if is_simple_leaf_self_transition {
                self.process_simple_leaf_self_transition(
                    trans_info,
                    event,
                    &mut states_exited_this_step,
                    &mut entry_execution_list,
                    &mut temp_context,
                )?;
            } else if source_state_id == target_state_id {
                self.process_self_transition(
                    trans_info,
                    current_active_leaves_snapshot,
                    event,
                    &mut states_exited_this_step,
                    &mut entry_execution_list,
                    &mut temp_context,
                )?;
            } else {
                self.process_regular_transition(
                    trans_info,
                    event,
                    &mut states_exited_this_step,
                    &mut entry_execution_list,
                    &mut temp_context,
                )?;
            }
        }

        Ok((
            overall_transition_occurred,
            states_exited_this_step,
            entry_execution_list,
            temp_context,
        ))
    }

    /// Commits the entry plan by processing all entries and collecting new leaves.
    pub(crate) fn commit_entry_plan(
        &self,
        entry_execution_list: &[(StateType, Option<StateType>, StateType)],
        entry_actions_run_vec: &mut heapless::Vec<StateType, M>,
        event: &EventType,
        temp_context: &mut ContextType,
    ) -> Result<heapless::Vec<StateType, MAX_ACTIVE_REGIONS>, ProcessingError> {
        let mut new_leaves = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();

        // Phase 3: Process entries and add new leaves (use temp_context)
        for &(target_id, lca_id, source_id) in entry_execution_list {
            trace!(
                "[TRACE] ENTRY EXEC: target_state_id = {:?}, lca_id = {:?}, ancestry = {:?}",
                target_id,
                lca_id,
                self.get_ancestry(target_id)
            );
            match self.execute_entry_actions_from_lca_with_context(
                target_id,
                lca_id,
                source_id, // Use source_id from the tuple
                event,
                &mut Scratch::<StateType, M> {
                    entry_actions_run: entry_actions_run_vec,
                },
                temp_context,
            ) {
                Ok(leaves_from_entry) => {
                    for new_leaf in leaves_from_entry {
                        if new_leaves.push(new_leaf).is_err() {
                            return Err(ProcessingError::CapacityExceeded);
                        }
                    }
                }
                Err(processing_error) => return Err(processing_error),
            }
        }

        // Filter: Only keep true leaves (not parents of any other in the set)
        let mut only_leaves = heapless::Vec::<StateType, MAX_ACTIVE_REGIONS>::new();
        'outer: for &candidate in &new_leaves {
            for &other in &new_leaves {
                if candidate != other && self.machine_def.get_parent_of(other) == Some(candidate) {
                    continue 'outer; // candidate is a parent, not a leaf
                }
            }
            if only_leaves.push(candidate).is_err() {
                return Err(ProcessingError::CapacityExceeded);
            }
        }

        Ok(only_leaves)
    }

    /// Merges and reconciles active leaf states after transitions and entries.
    pub(crate) fn merge_active_sets(
        &self,
        current_active_leaves_snapshot: &heapless::Vec<StateType, N_ACTIVE>,
        states_exited_this_step: &heapless::Vec<StateType, MAX_NODES_FOR_COMPUTATION>,
        only_leaves: &heapless::Vec<StateType, MAX_ACTIVE_REGIONS>,
        entry_execution_list_fallback: &[(StateType, Option<StateType>, StateType)],
    ) -> Result<heapless::Vec<StateType, MAX_ACTIVE_REGIONS>, ProcessingError> {
        let mut next_active_leaves = heapless::Vec::<StateType, MAX_ACTIVE_REGIONS>::new();

        // Step 1: Retain active leaves that were not exited
        for &leaf in current_active_leaves_snapshot {
            if !states_exited_this_step
                .iter()
                .any(|&exited| self.is_descendant_or_self(leaf, exited).unwrap_or(false))
                && !next_active_leaves.contains(&leaf)
                && next_active_leaves.push(leaf).is_err()
            {
                return Err(ProcessingError::CapacityExceeded);
            }
        }
        trace!(
            "[TRACE] PATCH: Retained leaves after exit: {:?}",
            next_active_leaves
        );

        // Step 2: Overwrite if all old leaves exited and new ones exist
        if next_active_leaves.is_empty() && !only_leaves.is_empty() {
            for &leaf in only_leaves {
                let resolved_leaf = self.resolve_to_leaf(leaf)?;
                if !next_active_leaves.contains(&resolved_leaf)
                    && next_active_leaves.push(resolved_leaf).is_err()
                {
                    return Err(ProcessingError::CapacityExceeded);
                }
            }
            trace!(
                "[TRACE] PATCH: All old leaves exited, overwriting with only_leaves: {:?}",
                next_active_leaves
            );
        } else {
            // Step 3: Merge new leaves into retained ones
            for &leaf in only_leaves {
                let resolved_leaf = self.resolve_to_leaf(leaf)?;
                if !next_active_leaves.contains(&resolved_leaf)
                    && next_active_leaves.push(resolved_leaf).is_err()
                {
                    return Err(ProcessingError::CapacityExceeded);
                }
            }
            trace!(
                "[TRACE] PATCH: Added only_leaves to retained, next_active_leaves: {:?}",
                next_active_leaves
            );
        }

        // Step 4: Fallback to entry fallback state if necessary
        if next_active_leaves.is_empty() && !entry_execution_list_fallback.is_empty() {
            let (target_state_id, _, _) = entry_execution_list_fallback[0];
            let fallback_leaf = self.resolve_to_leaf(target_state_id)?;
            trace!(
                "[TRACE] Fallback triggered: fallback_leaf = {:?}",
                fallback_leaf
            );
            if next_active_leaves.push(fallback_leaf).is_err() {
                return Err(ProcessingError::CapacityExceeded);
            }
        }

        Ok(next_active_leaves)
    }

    /// Sends an event to the state machine for processing.
    ///
    /// Orchestrates the transition processing through multiple phases:
    /// 1. Collect potential transitions
    /// 2. Arbitrate and de-duplicate transitions
    /// 3. Apply transitions (exits and actions)  
    /// 4. Commit entry plans
    /// 5. Merge and reconcile active leaf states
    ///
    /// # Panics
    ///
    /// This function may panic if:
    /// - Output stream operations fail when `std` feature is enabled (due to `unwrap()` calls)
    pub fn send_internal(&mut self, event: &EventType) -> SendResult {
        #[cfg(feature = "debug-log")]
        {
            println!("COMPILE-TIME DEBUG-LOG FEATURE IS ACTIVE");
        }
        trace!(
            "[TRACE] send_internal START for event: {:?}, active_leaf_states: {:?}",
            event, self.active_leaf_states
        );
        #[cfg(feature = "std")]
        {
            println!("send_internal() called with event: {event:?}");
            io::stdout().flush().unwrap();
        }

        // Create a single entry_actions_run Vec to be reused throughout send_internal
        let mut entry_actions_run_vec: heapless::Vec<StateType, M> = heapless::Vec::new();

        // Phase 0: Collect potential transitions (read-only on context for guards)
        let current_active_leaves_snapshot = self.active_leaf_states.clone();

        let potential_transitions =
            match self.collect_potential_transitions(event, &current_active_leaves_snapshot) {
                Ok(transitions) => transitions,
                Err(e) => return SendResult::Error(e),
            };

        if potential_transitions.is_empty() {
            return SendResult::NoMatch;
        }

        // Phase 0.5: Arbitrate and de-duplicate transitions (still read-only on context)
        let final_transitions_to_execute = match self.arbitrate_transitions(&potential_transitions)
        {
            Ok(transitions) => transitions,
            Err(e) => return SendResult::Error(e),
        };

        if final_transitions_to_execute.is_empty() {
            return SendResult::NoMatch;
        }

        // --- Context and State Commit Logic ---
        // Phase 1: Apply transitions (exits and actions)
        // Clone context only when we're about to mutate it
        let (
            overall_transition_occurred,
            states_exited_this_step,
            entry_execution_list,
            mut temp_context,
        ) = match self.apply_transitions(
            &final_transitions_to_execute,
            &current_active_leaves_snapshot,
            event,
            self.context.clone(), // Clone here, right before mutations
        ) {
            Ok(result) => result,
            Err(e) => return SendResult::Error(e),
        };

        // Early return if no transitions actually occurred (avoids unnecessary work)
        if !overall_transition_occurred {
            return SendResult::NoMatch;
        }

        #[cfg(feature = "std")]
        dbg!(&states_exited_this_step);

        // Phase 2: Commit entry plan
        let only_leaves = match self.commit_entry_plan(
            &entry_execution_list,
            &mut entry_actions_run_vec,
            event,
            &mut temp_context,
        ) {
            Ok(leaves) => leaves,
            Err(e) => return SendResult::Error(e),
        };

        // Phase 3: Merge and reconcile active leaf states
        let entry_execution_list_fallback = entry_execution_list.clone();
        let next_active_leaves = match self.merge_active_sets(
            &current_active_leaves_snapshot,
            &states_exited_this_step,
            &only_leaves,
            &entry_execution_list_fallback,
        ) {
            Ok(leaves) => leaves,
            Err(e) => return SendResult::Error(e),
        };

        trace!(
            "[TRACE] FINAL next_active_leaves to assign: {:?}",
            next_active_leaves
        );
        self.active_leaf_states.clear();
        self.active_leaf_states
            .extend(next_active_leaves.iter().copied());
        trace!(
            "[TRACE] self.active_leaf_states AFTER extend: {:?}",
            self.active_leaf_states
        );

        // Commit the mutated context since we know transitions occurred
        self.context = temp_context;
        SendResult::Transitioned
    }

    // Cloned and modified version of execute_entry_actions_from_lca to accept context
    // This is a temporary measure; ideally, the original would be refactored.
    #[allow(clippy::too_many_lines)]
    fn execute_entry_actions_from_lca_with_context(
        &self,
        target_state_id: StateType,
        lca_id: Option<StateType>,
        source_state_id: StateType, // NEW
        event: &EventType,
        scratch: &mut Scratch<'_, StateType, M>,
        context: &mut ContextType,
    ) -> Result<heapless::Vec<StateType, N_ACTIVE>, ProcessingError> {
        trace!(
            "[TRACE] ENTER execute_entry_actions_from_lca_with_context: target_state_id = {:?}, lca_id = {:?}",
            target_state_id, lca_id
        );
        let mut new_active_leaf_states = heapless::Vec::new();
        let mut path_from_target_to_root: heapless::Vec<StateType, M> = heapless::Vec::new();
        self.fill_path_to_root(target_state_id, &mut path_from_target_to_root)?;
        trace!(
            "[TRACE] path_from_target_to_root for {:?}: {:?}",
            target_state_id, path_from_target_to_root
        );
        let mut entry_path_segment: heapless::Vec<StateType, M> = heapless::Vec::new();

        trace!(
            "[TRACE] lca_id BEFORE entry_path_segment construction: {:?}",
            lca_id
        );
        if let Some(lca) = lca_id {
            // Clear & rebuild so patch is idempotent in case of multiple compilations
            entry_path_segment.clear();

            // Iterate from root‑wards (reverse) but SKIP the LCA itself.
            // Push every state *below* the LCA (i.e., the part that is NOT already active).
            let mut found_lca = false;
            for &state in path_from_target_to_root.iter().rev() {
                if state == lca {
                    found_lca = true;
                    continue; // <-- skip LCA
                }
                if found_lca {
                    entry_path_segment
                        .push(state)
                        .map_err(|_| ProcessingError::PathTooLong)?;
                }
            }
        } else {
            // (unchanged) full push when there is no LCA or LCA == target.
            entry_path_segment.clear();
            for &state in path_from_target_to_root.iter().rev() {
                entry_path_segment
                    .push(state)
                    .map_err(|_| ProcessingError::PathTooLong)?;
            }
        }
        trace!(
            "[TRACE] Calculated entry_path_segment: {:?}",
            entry_path_segment
        );
        for &state_to_enter in &entry_path_segment {
            let node = self
                .machine_def
                .get_state_node(state_to_enter)
                .ok_or(ProcessingError::EntryLogicFailure)?;
            // --- ENTRY ACTION (dedup) ---
            if !scratch.entry_actions_run.contains(&state_to_enter) {
                if let Some(entry_fn) = node.entry_action {
                    entry_fn(context, event);
                }
                scratch
                    .entry_actions_run
                    .push(state_to_enter)
                    .map_err(|_| ProcessingError::CapacityExceeded)?;
            }
            // Recursion into children always happens for parallel states
            #[allow(clippy::collapsible_if)]
            if node.is_parallel && state_to_enter != target_state_id {
                if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M, N_ACTIVE>(
                    self.machine_def,
                    context,
                    state_to_enter,
                    &mut new_active_leaf_states,
                    &mut heapless::Vec::new(), // visited_during_entry, not used for dedup now
                    scratch,
                    event,
                ) {
                    return Err(match entry_error.kind {
                        EntryErrorKind::CycleDetected | EntryErrorKind::StateNotFound => {
                            ProcessingError::EntryLogicFailure
                        }
                        EntryErrorKind::CapacityExceeded => ProcessingError::CapacityExceeded,
                    });
                }
            }
        }
        // Now handle the target state itself (if not already processed)
        let is_self_transition =
            lca_id == Some(target_state_id) && target_state_id == source_state_id;
        if is_self_transition {
            // For self-transitions, always run the entry action (even if already in dedup set)
            if let Some(entry_fn) = self
                .machine_def
                .get_state_node(target_state_id)
                .and_then(|n| n.entry_action)
            {
                entry_fn(context, event);
            }
            // Still add to dedup set to prevent double entry in recursion
            if !scratch.entry_actions_run.contains(&target_state_id) {
                scratch
                    .entry_actions_run
                    .push(target_state_id)
                    .map_err(|_| ProcessingError::CapacityExceeded)?;
            }
        } else if lca_id != Some(target_state_id)
            && !scratch.entry_actions_run.contains(&target_state_id)
        {
            // For all other transitions, only run if not already entered
            if let Some(entry_fn) = self
                .machine_def
                .get_state_node(target_state_id)
                .and_then(|n| n.entry_action)
            {
                entry_fn(context, event);
            }
            scratch
                .entry_actions_run
                .push(target_state_id)
                .map_err(|_| ProcessingError::CapacityExceeded)?;
        }
        // Recursion into children always happens
        let node = self
            .machine_def
            .get_state_node(target_state_id)
            .ok_or(ProcessingError::EntryLogicFailure)?;
        if node.is_parallel || node.initial_child.is_some() {
            if let Err(entry_error) = enter_state_recursive_logic::<_, _, _, M, N_ACTIVE>(
                self.machine_def,
                context,
                target_state_id,
                &mut new_active_leaf_states,
                &mut heapless::Vec::new(), // visited_during_entry, not used for dedup now
                scratch,
                event,
            ) {
                return Err(match entry_error.kind {
                    EntryErrorKind::CycleDetected | EntryErrorKind::StateNotFound => {
                        ProcessingError::EntryLogicFailure
                    }
                    EntryErrorKind::CapacityExceeded => ProcessingError::CapacityExceeded,
                });
            }
        } else {
            // Atomic state
            if !new_active_leaf_states.contains(&target_state_id)
                && new_active_leaf_states.push(target_state_id).is_err()
            {
                return Err(ProcessingError::CapacityExceeded);
            }
        }
        Ok(new_active_leaf_states)
    }

    /// Resolves a state to its true leaf by following `initial_child` recursively.
    /// Returns an error if a cycle is detected in the `initial_child` references.
    fn resolve_to_leaf(&self, mut state: StateType) -> Result<StateType, ProcessingError> {
        let mut depth = 0;

        while let Some(child) = self
            .machine_def
            .get_state_node(state)
            .and_then(|n| n.initial_child)
        {
            depth += 1;
            if depth > M {
                // Cycle detected or hierarchy too deep
                return Err(ProcessingError::EntryLogicFailure);
            }
            state = child;
        }
        Ok(state)
    }

    // Add this helper for ancestry tracing
    #[allow(dead_code)]
    fn get_ancestry(&self, mut state_id: StateType) -> heapless::Vec<StateType, M> {
        let mut ancestry = heapless::Vec::new();
        ancestry.push(state_id).ok();
        while let Some(parent) = self.machine_def.get_parent_of(state_id) {
            ancestry.push(parent).ok();
            state_id = parent;
        }
        ancestry
    }

    /// Arbitrates and de-duplicates potential transitions, selecting the most specific ones
    #[allow(dead_code)]
    fn arbitrate_transitions(
        &self,
        potential_transitions: &[PotentialTransition<StateType, EventType, ContextType>],
    ) -> Result<
        heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        >,
        ProcessingError,
    > {
        let mut arbitrated_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();

        // Arbitration logic: prefer more specific (descendant) transition sources
        'candidate_loop: for pt_candidate in potential_transitions {
            for other_pt in potential_transitions {
                if core::ptr::eq(pt_candidate, other_pt) {
                    continue;
                }
                match self.is_proper_ancestor(
                    pt_candidate.transition_from_state_id,
                    other_pt.transition_from_state_id,
                ) {
                    Ok(is_ancestor) => {
                        if is_ancestor {
                            continue 'candidate_loop;
                        }
                    }
                    Err(e) => return Err(e),
                }
            }
            if arbitrated_transitions.push(pt_candidate.clone()).is_err() {
                return Err(ProcessingError::CapacityExceeded);
            }
        }

        // De-duplicate transitions by transition reference pointer
        let mut final_transitions: heapless::Vec<
            PotentialTransition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();
        let mut processed_transition_pointers: heapless::Vec<
            *const Transition<StateType, EventType, ContextType>,
            MAX_NODES_FOR_COMPUTATION,
        > = heapless::Vec::new();

        for trans_to_consider in &arbitrated_transitions {
            let current_ref_ptr = trans_to_consider.transition_ref as *const _;
            let mut already_processed = false;
            for &seen_ptr in &processed_transition_pointers {
                if seen_ptr == current_ref_ptr {
                    already_processed = true;
                    break;
                }
            }
            if !already_processed {
                if final_transitions.push(trans_to_consider.clone()).is_err() {
                    return Err(ProcessingError::CapacityExceeded);
                }
                if processed_transition_pointers.push(current_ref_ptr).is_err() {
                    return Err(ProcessingError::CapacityExceeded);
                }
            }
        }

        Ok(final_transitions)
    }
}

impl<
    StateType,
    EventType,
    ContextType,
    const M: usize,
    const N_ACTIVE: usize,
    const MAX_NODES_FOR_COMPUTATION: usize,
> StateMachine<N_ACTIVE>
    for Runtime<StateType, EventType, ContextType, M, N_ACTIVE, MAX_NODES_FOR_COMPUTATION>
where
    StateType: Copy + Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static,
    EventType: Clone + PartialEq + Eq + core::hash::Hash + core::fmt::Debug + 'static, // Removed Copy
    ContextType: Clone + 'static,
{
    type State = StateType;
    type Event = EventType;
    type Context = ContextType;

    fn send(&mut self, event: &EventType) -> SendResult {
        self.send_internal(event)
    }

    fn state(&self) -> heapless::Vec<Self::State, N_ACTIVE> {
        self.active_leaf_states.clone()
    }

    fn context(&self) -> &Self::Context {
        &self.context
    }

    fn context_mut(&mut self) -> &mut Self::Context {
        &mut self.context
    }
}

#[cfg(test)]
#[allow(clippy::trivially_copy_pass_by_ref)] // Allow for test events
mod tests {
    use super::*; //Imports S, E, C types from parent
    use crate::runtime::DefaultContext; // Ensure DefaultContext is in scope

    // Define const M for tests, e.g., 8, matching old MAX_HIERARCHY_DEPTH for compatibility.
    const TEST_HIERARCHY_DEPTH_M: usize = 8;
    const TEST_MAX_NODES_FOR_COMPUTATION: usize = TEST_HIERARCHY_DEPTH_M * MAX_ACTIVE_REGIONS; // Renamed from TEST_MTMAR

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum TestState {
        S0,
        S1,
        S2,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum TestEvent {
        E0,
        E1,
    }

    // Using the DefaultContext from the parent module for this alias
    #[allow(dead_code)]
    type TestContextForEmpty = DefaultContext;

    // Define CounterContext at the module scope for tests
    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    #[allow(dead_code)]
    struct TestContext {
        // Assuming this is the context for transition_action_for_increment
        val: i32, // Example field
    }

    // Action function for basic_machine_integration_test
    #[allow(clippy::trivially_copy_pass_by_ref)] // EventType is Copy
    #[allow(dead_code)]
    fn transition_action_for_increment(context: &mut TestContext, _event: &TestEvent) {
        context.val += 1; // Example action
    }

    // Guard function for basic_machine_integration_test (example, ensure its signature is correct)
    #[allow(clippy::trivially_copy_pass_by_ref)] // EventType is Copy
    #[allow(dead_code)]
    fn guard_for_increment(context: &TestContext, _event: &TestEvent) -> bool {
        context.val < 5 // Example guard
    }

    // Match functions for TestEvent transitions
    #[allow(dead_code)]
    fn matches_test_event_e0(event: &TestEvent) -> bool {
        matches!(event, TestEvent::E0)
    }

    // Populated StateNode arrays for tests
    #[allow(dead_code)]
    const TEST_STATENODES_EMPTY_CTX_POPULATED: &[StateNode<
        TestState,
        TestContextForEmpty,
        TestEvent,
    >] = &[
        StateNode {
            id: TestState::S0,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S1,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
        StateNode {
            id: TestState::S2,
            parent: None,
            initial_child: None,
            entry_action: None,
            exit_action: None,
            is_parallel: false,
        },
    ];

    #[allow(dead_code)]
    const TEST_STATENODES_COUNTER_CTX_POPULATED: &[StateNode<TestState, TestContext, TestEvent>] =
        &[
            StateNode {
                id: TestState::S0,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
            StateNode {
                id: TestState::S1,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
            StateNode {
                id: TestState::S2,
                parent: None,
                initial_child: None,
                entry_action: None,
                exit_action: None,
                is_parallel: false,
            },
        ];

    // --- New Test Setup for Hierarchical Transitions ---

    #[allow(dead_code)]
    const MAX_LOG_ENTRIES: usize = 64; // Increased from 32
    #[allow(dead_code)]
    const MAX_LOG_STRING_LEN: usize = 64; // Max length for a logged action string

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    #[allow(dead_code)]
    struct HierarchicalActionLogContext {
        log: Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES>,
    }

    #[allow(dead_code)]
    impl HierarchicalActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<MAX_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String");
            self.log
                .push(s) // try_push not strictly necessary if MAX_LOG_ENTRIES is sufficient for tests and we expect it to succeed.
                .expect("Log vec full in HierarchicalActionLogContext");
        }
        fn get_log(&self) -> &Vec<heapless::String<MAX_LOG_STRING_LEN>, MAX_LOG_ENTRIES> {
            &self.log
        }
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum TestHierarchyState {
        ParentOne,
        ChildOneAlpha,            // Child of ParentOne
        GrandchildOneAlphaXray,   // Child of ChildOneAlpha
        GrandchildOneAlphaYankee, // Child of ChildOneAlpha
        ChildOneBravo,            // Child of ParentOne
        ParentTwo,
        ChildTwoAlpha, // Child of ParentTwo
    }

    #[derive(Debug, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum TestHierarchyEvent {
        EventTriggerP1ToP2,        // ParentOne to ParentTwo
        EventTriggerP1ToC1B,       // ParentOne to ChildOneBravo
        EventTriggerToSibling,     // ChildOneAlpha to ChildOneBravo
        EventTriggerToParent,      // GrandchildOneAlphaXray to ChildOneAlpha
        EventTriggerToGrandparent, // GrandchildOneAlphaYankee to ParentOne
        EventTriggerToCousinChild, // ChildOneBravo to GrandchildOneAlphaYankee
        EventTriggerParentReentry, // ChildOneBravo to ParentOne (expect re-entry logic)
        EventTriggerP2ToP1,        // ParentTwo to ParentOne
    }

    // Add the missing constants for parallel tests
    const PARALLEL_LOG_ENTRIES: usize = 32;
    const PARALLEL_LOG_STRING_LEN: usize = 64;

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    struct ParallelActionLogContext {
        log: heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>,
    }

    impl ParallelActionLogContext {
        fn log_action(&mut self, action_description: &str) {
            let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
            s.push_str(action_description)
                .expect("Log string too long for heapless::String in ParallelActionLogContext");
            self.log.push(s).unwrap_or_else(|_val| {
                panic!(
                    "ParallelActionLogContext log overflow (capacity {PARALLEL_LOG_ENTRIES}). Could not log: {action_description}"
                );
            });
        }
        // Helper to create expected log Vec more easily in tests
        #[allow(dead_code)] // May not be used by all tests initially
        fn expected_log(
            entries: &[&str],
        ) -> heapless::Vec<heapless::String<PARALLEL_LOG_STRING_LEN>, PARALLEL_LOG_ENTRIES>
        {
            let mut v = heapless::Vec::new();
            for entry in entries {
                let mut s = heapless::String::<PARALLEL_LOG_STRING_LEN>::new();
                s.push_str(entry).unwrap();
                v.push(s).unwrap();
            }
            v
        }
    }

    // --- Tests for Multiple Guard Selection ---

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum MultiGuardTestState {
        InitialState,
        TargetStateOne,
        TargetStateTwo,
        TargetStateThree,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum MultiGuardTestEvent {
        TriggerEvent,
    }

    #[derive(Clone, Debug, Default, PartialEq, Eq)]
    #[allow(dead_code)]
    struct MultiGuardContext {
        selector_value: i32,
        action_taken_for: Option<MultiGuardTestState>,
    }

    #[allow(dead_code)]
    fn guard_for_target_one(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 1
    }
    #[allow(dead_code)]
    fn action_for_target_one(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateOne);
    }

    #[allow(dead_code)]
    fn guard_for_target_two(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 2
    }
    #[allow(dead_code)]
    fn action_for_target_two(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateTwo);
    }

    #[allow(dead_code)]
    fn guard_for_target_three(context: &MultiGuardContext, _event: &MultiGuardTestEvent) -> bool {
        context.selector_value == 3
    }
    #[allow(dead_code)]
    fn action_for_target_three(context: &mut MultiGuardContext, _event: &MultiGuardTestEvent) {
        context.action_taken_for = Some(MultiGuardTestState::TargetStateThree);
    }

    #[allow(dead_code)]
    fn matches_multi_guard_trigger_event(event: &MultiGuardTestEvent) -> bool {
        matches!(event, MultiGuardTestEvent::TriggerEvent)
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq, Hash, PartialOrd, Ord)]
    enum ParallelTestState {
        P,
        R1,
        R1A,
        R1B,
        R2,
        R2X,
        R2Y,
        SOuter,
    }

    #[derive(Debug, Clone, PartialEq, Eq, Hash)]
    #[allow(dead_code)]
    enum ParallelTestEvent {
        E1,
        E2,
        EventR1ToR2,          // Was E_R1_To_R2
        EventRegion1Self,     // Was E_R1_Self
        EventRegion2Self,     // Was E_R2_Self
        EventParallelSelf,    // Was E_P_Self
        EventParallelToOuter, // Was E_P_To_SOuter
        EventOuterToParallel, // Was E_SOuter_To_P
        EventRegion1Only,     // Was E_R1_Only
    }

    // Action and Guard functions for parallel tests (renamed for clarity)
    fn pt_log_enter_parallel(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterP");
    }
    fn pt_log_exit_parallel(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitP");
    }
    fn pt_log_event_parallel_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("P_SelfAction");
    }

    fn pt_log_enter_region1(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterR1");
    }
    fn pt_log_exit_region1(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1");
    }
    fn pt_log_enter_region1_state_a(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR1A");
    }
    fn pt_log_exit_region1_state_a(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1A");
    }
    fn pt_log_region1_state_a_event_e1_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_E1_Action");
    }
    fn pt_log_region1_state_a_event_region1_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_SelfAction");
    }
    fn pt_log_enter_region1_state_b(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR1B");
    }
    fn pt_log_exit_region1_state_b(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR1B");
    }
    fn pt_log_region1_state_b_event_e2_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1B_E2_Action");
    }
    fn pt_log_region1_state_a_event_region1_only_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R1A_E_R1_Only_Action");
    }

    fn pt_log_enter_region2(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterR2");
    }
    fn pt_log_exit_region2(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2");
    }
    fn pt_log_enter_region2_state_x(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR2X");
    }
    fn pt_log_exit_region2_state_x(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2X");
    }
    fn pt_log_region2_state_x_event_e1_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2X_E1_Action");
    }
    fn pt_log_region2_state_x_event_region2_self_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2X_SelfAction");
    }
    fn pt_log_enter_region2_state_y(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("EnterR2Y");
    }
    fn pt_log_exit_region2_state_y(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitR2Y");
    }
    fn pt_log_region2_state_y_event_e2_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("R2Y_E2_Action");
    }

    fn pt_log_enter_state_outer(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("EnterSOuter");
    }
    fn pt_log_exit_state_outer(ctx: &mut ParallelActionLogContext, _event: &ParallelTestEvent) {
        ctx.log_action("ExitSOuter");
    }
    fn pt_log_event_parallel_to_outer_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("P_E2_SOuter_Action");
    }
    fn pt_log_event_outer_to_parallel_action(
        ctx: &mut ParallelActionLogContext,
        _event: &ParallelTestEvent,
    ) {
        ctx.log_action("SOuter_E1_P_Action");
    }

    const PARALLEL_TEST_STATENODES: &[StateNode<
        ParallelTestState,
        ParallelActionLogContext,
        ParallelTestEvent,
    >] = &[
        StateNode {
            id: ParallelTestState::P,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_parallel),
            exit_action: Some(pt_log_exit_parallel),
            is_parallel: true,
        },
        StateNode {
            id: ParallelTestState::R1,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R1A),
            entry_action: Some(pt_log_enter_region1),
            exit_action: Some(pt_log_exit_region1),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1A,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_a),
            exit_action: Some(pt_log_exit_region1_state_a),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R1B,
            parent: Some(ParallelTestState::R1),
            initial_child: None,
            entry_action: Some(pt_log_enter_region1_state_b),
            exit_action: Some(pt_log_exit_region1_state_b),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2,
            parent: Some(ParallelTestState::P),
            initial_child: Some(ParallelTestState::R2X),
            entry_action: Some(pt_log_enter_region2),
            exit_action: Some(pt_log_exit_region2),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2X,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_x),
            exit_action: Some(pt_log_exit_region2_state_x),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::R2Y,
            parent: Some(ParallelTestState::R2),
            initial_child: None,
            entry_action: Some(pt_log_enter_region2_state_y),
            exit_action: Some(pt_log_exit_region2_state_y),
            is_parallel: false,
        },
        StateNode {
            id: ParallelTestState::SOuter,
            parent: None,
            initial_child: None,
            entry_action: Some(pt_log_enter_state_outer),
            exit_action: Some(pt_log_exit_state_outer),
            is_parallel: false,
        },
    ];

    const PARALLEL_TEST_TRANSITIONS: &[Transition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    >] = &[
        Transition {
            from_state: ParallelTestState::P,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_parallel_self_action),
            guard: None,
            match_fn: Some(matches_parallel_self),
        },
        Transition {
            from_state: ParallelTestState::P,
            to_state: ParallelTestState::SOuter,
            action: Some(pt_log_event_parallel_to_outer_action),
            guard: None,
            match_fn: Some(matches_parallel_to_outer),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_e1_action),
            guard: None,
            match_fn: Some(matches_parallel_e1),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_a_event_region1_self_action),
            guard: None,
            match_fn: Some(matches_parallel_region1_self),
        },
        Transition {
            from_state: ParallelTestState::R1A,
            to_state: ParallelTestState::R1B,
            action: Some(pt_log_region1_state_a_event_region1_only_action),
            guard: None,
            match_fn: Some(matches_region1_only),
        },
        Transition {
            from_state: ParallelTestState::R1B,
            to_state: ParallelTestState::R1A,
            action: Some(pt_log_region1_state_b_event_e2_action),
            guard: None,
            match_fn: Some(matches_parallel_e2),
        },
        Transition {
            from_state: ParallelTestState::R2X,
            to_state: ParallelTestState::R2Y,
            action: Some(pt_log_region2_state_x_event_e1_action),
            guard: None,
            match_fn: Some(matches_parallel_e1),
        },
        Transition {
            from_state: ParallelTestState::R2X,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_x_event_region2_self_action),
            guard: None,
            match_fn: Some(matches_parallel_region2_self),
        },
        Transition {
            from_state: ParallelTestState::R2Y,
            to_state: ParallelTestState::R2X,
            action: Some(pt_log_region2_state_y_event_e2_action),
            guard: None,
            match_fn: Some(matches_parallel_e2),
        },
        Transition {
            from_state: ParallelTestState::SOuter,
            to_state: ParallelTestState::P,
            action: Some(pt_log_event_outer_to_parallel_action),
            guard: None,
            match_fn: Some(matches_outer_to_parallel),
        },
    ];

    static PARALLEL_MACHINE_DEF: MachineDefinition<
        ParallelTestState,
        ParallelTestEvent,
        ParallelActionLogContext,
    > = MachineDefinition::new(
        PARALLEL_TEST_STATENODES,
        PARALLEL_TEST_TRANSITIONS,
        ParallelTestState::P,
    );

    // Helper function for checking subsequences in logs
    fn check_subsequence(
        log: &heapless::Vec<&str, PARALLEL_LOG_ENTRIES>,
        expected_sub: &[&str],
    ) -> bool {
        if expected_sub.is_empty() {
            return true;
        }
        let mut log_idx = 0;
        let mut sub_idx = 0;
        while log_idx < log.len() && sub_idx < expected_sub.len() {
            if log[log_idx] == expected_sub[sub_idx] {
                sub_idx += 1;
            }
            log_idx += 1;
        }
        sub_idx == expected_sub.len()
    }

    #[test]
    fn test_parallel_initial_activation_and_entry_order() {
        let initial_context = ParallelActionLogContext::default(); // unused_mut: removed mut
        let initial_event_for_test = ParallelTestEvent::E1; // Corrected to ParallelTestEvent
        let runtime = Runtime::<
            _,
            _,
            _,
            TEST_HIERARCHY_DEPTH_M,
            MAX_ACTIVE_REGIONS,
            TEST_MAX_NODES_FOR_COMPUTATION,
        >::new(
            &PARALLEL_MACHINE_DEF,
            initial_context,
            &initial_event_for_test,
        )
        .expect("Failed to create runtime for test");

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "EnterP", "EnterR1", "EnterR1A", "EnterR2", "EnterR2X",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Entry action log mismatch"
        );
    }

    #[test]
    fn test_parallel_independent_region_transitions() {
        let initial_context = ParallelActionLogContext::default();
        let initial_event_for_test = ParallelTestEvent::E1; // Corrected to ParallelTestEvent
        let mut runtime = Runtime::<
            _,
            _,
            _,
            TEST_HIERARCHY_DEPTH_M,
            MAX_ACTIVE_REGIONS,
            TEST_MAX_NODES_FOR_COMPUTATION,
        >::new(
            &PARALLEL_MACHINE_DEF,
            initial_context,
            &initial_event_for_test,
        )
        .expect("Failed to create runtime for test");
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::E1);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event E1 should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2Y).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let actual_log = runtime.context().log.clone();
        let actual_log_strs: heapless::Vec<&str, PARALLEL_LOG_ENTRIES> =
            actual_log.iter().map(heapless::String::as_str).collect();

        let r1_actions_expected_slice = &["ExitR1A", "R1A_E1_Action", "EnterR1B"];
        let r2_actions_expected_slice = &["ExitR2X", "R2X_E1_Action", "EnterR2Y"];

        assert!(
            check_subsequence(&actual_log_strs, r1_actions_expected_slice),
            "R1 action block {r1_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );
        assert!(
            check_subsequence(&actual_log_strs, r2_actions_expected_slice),
            "R2 action block {r2_actions_expected_slice:?} not found as a subsequence in log: {actual_log_strs:?}"
        );

        // The sum of lengths of individual blocks should be the total log length if no other actions occurred.
        assert_eq!(
            actual_log_strs.len(),
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            "Log has incorrect total number of entries. Expected {}, got {}. Log: {:?}",
            r1_actions_expected_slice.len() + r2_actions_expected_slice.len(),
            actual_log_strs.len(),
            actual_log_strs
        );
    }

    #[test]
    fn test_parallel_transition_one_region_no_effect_on_other() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime = Runtime::<
            _,
            _,
            _,
            TEST_HIERARCHY_DEPTH_M,
            MAX_ACTIVE_REGIONS,
            TEST_MAX_NODES_FOR_COMPUTATION,
        >::new(
            &PARALLEL_MACHINE_DEF,
            initial_context,
            &ParallelTestEvent::EventRegion1Only,
        )
        .expect("Failed to create runtime for test");
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::EventRegion1Only);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventRegion1Only should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1B).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "ExitR1A",
            "R1A_E_R1_Only_Action",
            "EnterR1B",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Only"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_region_leaf() {
        let initial_context = ParallelActionLogContext::default(); // Needs mut for clear()
        let mut runtime = Runtime::<
            _,
            _,
            _,
            TEST_HIERARCHY_DEPTH_M,
            MAX_ACTIVE_REGIONS,
            TEST_MAX_NODES_FOR_COMPUTATION,
        >::new(
            &PARALLEL_MACHINE_DEF,
            initial_context,
            &ParallelTestEvent::EventRegion1Self,
        )
        .expect("Failed to create runtime for test");
        runtime.context_mut().log.clear();

        let event_processed = runtime.send(&ParallelTestEvent::EventRegion1Self);
        assert_eq!(
            event_processed,
            SendResult::Transitioned,
            "Event EventRegion1Self should have been processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}" // uninlined_format_args: fixed
        );

        let expected_log =
            ParallelActionLogContext::expected_log(&["ExitR1A", "R1A_SelfAction", "EnterR1A"]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for EventRegion1Self"
        );
    }

    #[test]
    fn test_parallel_self_transition_on_parallel_state_itself() {
        let initial_context = ParallelActionLogContext::default();
        let mut runtime = Runtime::<
            _,
            _,
            _,
            TEST_HIERARCHY_DEPTH_M,
            MAX_ACTIVE_REGIONS,
            TEST_MAX_NODES_FOR_COMPUTATION,
        >::new(
            &PARALLEL_MACHINE_DEF,
            initial_context,
            &ParallelTestEvent::EventParallelSelf,
        )
        .expect("Failed to create runtime for test");
        runtime.context_mut().log.clear();

        let send_result = runtime.send(&ParallelTestEvent::EventParallelSelf);
        assert_eq!(
            send_result,
            SendResult::Transitioned,
            "Expected self-transition on parallel state to be processed"
        );

        let active_states = runtime.state();
        let mut sorted_active_states = active_states
            .into_iter()
            .collect::<heapless::Vec<_, MAX_ACTIVE_REGIONS>>();
        sorted_active_states.sort_unstable();

        let mut expected_active_states = heapless::Vec::<_, MAX_ACTIVE_REGIONS>::new();
        expected_active_states.push(ParallelTestState::R1A).unwrap();
        expected_active_states.push(ParallelTestState::R2X).unwrap();
        expected_active_states.sort_unstable();

        assert_eq!(
            sorted_active_states, expected_active_states,
            "Active states mismatch after parallel self-transition. Expected: {expected_active_states:?}, Got: {sorted_active_states:?}"
        );

        let expected_log = ParallelActionLogContext::expected_log(&[
            "ExitR1A",
            "ExitR1",
            "ExitR2X",
            "ExitR2",
            "ExitP",
            "P_SelfAction",
            "EnterP",
            "EnterR1",
            "EnterR1A",
            "EnterR2",
            "EnterR2X",
        ]);
        assert_eq!(
            runtime.context().log,
            expected_log,
            "Action log mismatch for parallel self-transition. Expected: {:?}, Got: {:?}",
            expected_log,
            runtime.context().log
        );
    }

    // Match functions for ParallelTestEvent
    fn matches_parallel_e1(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::E1)
    }

    fn matches_parallel_e2(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::E2)
    }

    fn matches_parallel_region1_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion1Self)
    }

    fn matches_parallel_region2_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion2Self)
    }

    fn matches_parallel_self(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventParallelSelf)
    }

    fn matches_parallel_to_outer(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventParallelToOuter)
    }

    fn matches_outer_to_parallel(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventOuterToParallel)
    }

    fn matches_region1_only(event: &ParallelTestEvent) -> bool {
        matches!(event, ParallelTestEvent::EventRegion1Only)
    }
}
